{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f492ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93adcda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "899bb579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Flatten,MaxPooling2D,Dropout,Dense,Activation,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9f729808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18d176ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70d34dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting random number of images from multiple folders and copying it to the destination folder\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "\n",
    "ctscan_covid_data = random.sample(glob.glob(\"Hamza_Custom_Data/CT_Scan/Covid/*.png\"), 330)\n",
    "ctscan_normal_data = random.sample(glob.glob(\"Hamza_Custom_Data/CT_Scan/Normal/*\"), 330)\n",
    "    \n",
    "ultrasound_covid_data = random.sample(glob.glob(\"Hamza_Custom_Data/Ultra_Sound/Covid/*\"), 330)\n",
    "ultrasound_normal_data = random.sample(glob.glob(\"Hamza_Custom_Data/Ultra_Sound/Normal/*.jpg\"), 330)\n",
    "\n",
    "xray_covid_data = random.sample(glob.glob(\"Hamza_Custom_Data/X_Ray/Covid/*.png\"), 330)\n",
    "xray_normal_data = random.sample(glob.glob(\"Hamza_Custom_Data/X_Ray/Normal/*.png\"), 330)\n",
    "\n",
    "    \n",
    "data_list = [ctscan_covid_data, ctscan_normal_data, ultrasound_covid_data, ultrasound_normal_data, xray_covid_data,\\\n",
    "             xray_normal_data]\n",
    "\n",
    "if os.path.isdir('Data/CT_Scan'):\n",
    "    shutil.rmtree('Data/CT_Scan')\n",
    "    \n",
    "if os.path.isdir('Data/Ultra_Sound'):\n",
    "    shutil.rmtree('Data/Ultra_Sound')\n",
    "    \n",
    "if os.path.isdir('Data/X_Ray'):\n",
    "    shutil.rmtree('Data/X_Ray')\n",
    "\n",
    "\n",
    "for data,label in zip(data_list,range(len(data_list))):\n",
    "    if label == 0:\n",
    "        dest = 'Data/CT_Scan/Covid'\n",
    "    elif label == 1:\n",
    "        dest = 'Data/CT_Scan/Normal'\n",
    "    elif label == 2:\n",
    "        dest = 'Data/Ultra_Sound/Covid'\n",
    "    elif label == 3:\n",
    "        dest = 'Data/Ultra_Sound/Normal'\n",
    "    elif label == 4:\n",
    "        dest = 'Data/X_Ray/Covid'\n",
    "    elif label == 5:\n",
    "        dest = 'Data/X_Ray/Normal'\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    os.makedirs(dest)\n",
    "    for imgs in data:\n",
    "        shutil.copy(imgs, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79011fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data_root: str, *, test_size: float, img_size: int, seed: int = 0) -> None:\n",
    "        self.label2index = {}\n",
    "        self.index2label = {}\n",
    "        \n",
    "        # Discover the class label names.\n",
    "        class_labels = os.listdir(data_root)\n",
    "        self.nclasses = len(class_labels)\n",
    "        X, y = [], []\n",
    "        \n",
    "        for label_index, label in enumerate(class_labels):\n",
    "            # Load the images for this class label.\n",
    "            self.label2index[label_index] = label\n",
    "            self.index2label[label] = label_index\n",
    "            \n",
    "            img_names = os.listdir(os.path.join(data_root, label))\n",
    "            for img_name in img_names:\n",
    "                img_path = os.path.join(data_root, label, img_name)\n",
    "                img = load_img(img_path, target_size=(img_size, img_size, 3))\n",
    "                X.append(img_to_array(img))\n",
    "                y.append(label_index)\n",
    "        \n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        one_hot_y = to_categorical(y, num_classes=self.nclasses)\n",
    "        \n",
    "        # Make a stratified split.\n",
    "        self.X, self.X_test, self.labels, self.labels_test, self.y, self.y_test = train_test_split(\n",
    "            X, y, one_hot_y, test_size=test_size, random_state=seed, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db7dea4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 224, 224, 3) (462, 2)\n",
      "(462, 224, 224, 3) (462, 2)\n",
      "(462, 224, 224, 3) (462, 2)\n"
     ]
    }
   ],
   "source": [
    "# 660 * 0.7 = 462 \n",
    "# X shape in 3 dimensions\n",
    "# Y has 2 classes (Covid, Normal)\n",
    "\n",
    "ctscan_data = Dataset(\"Data/CT_Scan\", test_size=0.3, img_size=224)\n",
    "print(ctscan_data.X.shape, ctscan_data.y.shape)\n",
    "\n",
    "ultrasound_data = Dataset(\"Data/Ultra_Sound\", test_size=0.3, img_size=224)\n",
    "print(ultrasound_data.X.shape, ultrasound_data.y.shape)\n",
    "\n",
    "xray_data = Dataset(\"Data/X_Ray\", test_size=0.3, img_size=224)\n",
    "print(xray_data.X.shape, xray_data.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adf177e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = [ctscan_data,ultrasound_data,xray_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f75d6355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 2048) (198, 2048)\n",
      "(462, 2048) (198, 2048)\n",
      "(462, 2048) (198, 2048)\n"
     ]
    }
   ],
   "source": [
    "# feature extractor model resnet 101 v2\n",
    "model = hub.KerasLayer(\"https://tfhub.dev/google/bit/m-r101x1/1\", trainable=False)\n",
    "\n",
    "for data,label in zip(final_data,range(len(final_data))):    \n",
    "    if label == 0:            \n",
    "        ctscan_embedding = model(data.X)\n",
    "        ctscan_test_embedding = model(data.X_test)\n",
    "        print(ctscan_embedding.shape, ctscan_test_embedding.shape)\n",
    "    \n",
    "    elif label == 1:        \n",
    "        ultrasound_embedding = model(data.X)\n",
    "        ultrasound_test_embedding = model(data.X_test)\n",
    "        print(ultrasound_embedding.shape, ultrasound_test_embedding.shape)\n",
    "    \n",
    "    elif label == 2:        \n",
    "        xray_embedding = model(data.X)\n",
    "        xray_test_embedding = model(data.X_test)\n",
    "        print(xray_embedding.shape, xray_test_embedding.shape)\n",
    "        \n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "783be627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(nclasses: int):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 16, kernel_size = (3,3), padding='same', input_shape=(2,2,512), activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(1,1))\n",
    "    model.add(Conv2D(24, (3,3), padding='same', activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(1,1))\n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(1,1))\n",
    "    model.add(Conv2D(48, (3,3), padding='same', activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(1,1))\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(1,1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128,activation=\"relu\"))\n",
    "    model.add(Dense(nclasses, activation=\"sigmoid\"))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4e539a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(nclasses, X, y, X_test, y_test, *, epochs: int, batch_size: int, learning_rate: float, \n",
    "                   **model_params) -> tuple:\n",
    "    \n",
    "    # Math to compute the learning rate schedule. We will divide our\n",
    "    # learning rate by a factor of 10 every 30% of the optimizer's\n",
    "    # total steps.\n",
    "    steps_per_epoch = math.ceil(len(X) / batch_size)\n",
    "    third_of_total_steps = math.floor(epochs * steps_per_epoch / 3)\n",
    "    \n",
    "    # Make and compile the model.\n",
    "    #model = model_maker(nclasses, **model_params)\n",
    "    model = make_model(nclasses)\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=ExponentialDecay(\n",
    "                learning_rate,\n",
    "                decay_steps=third_of_total_steps,\n",
    "                decay_rate=0.1,\n",
    "                staircase=True\n",
    "            )\n",
    "        ),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    # Train the model on the training set and evaluate it on the test set.\n",
    "    history = model.fit(X, y, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "    _, train_acc = model.evaluate(X, y, batch_size=batch_size, verbose=0)\n",
    "    _, test_acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "    return model, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c0f75511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_evaluate_model(\n",
    "    X, y, labels, *, nfolds: int, nrepeats: int, epochs: int, batch_size: int,\n",
    "    learning_rate: float, model_maker, verbose: bool = True, seed: int = 0,\n",
    "    **model_params\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Performs `nfolds` cross-validated training and evaluation of a\n",
    "    model hyperparameter configuration. Returns a dictionary of\n",
    "    statistics about the outcome of the cross-validated experiment.\n",
    "    \"\"\"\n",
    "    _, nclasses = y.shape\n",
    "    train_accs, test_accs = [], []\n",
    "    \n",
    "    # Train and evaluate the model for each fold.\n",
    "    for train_index, test_index in tqdm(\n",
    "        RepeatedStratifiedKFold(\n",
    "            n_splits=nfolds, n_repeats=nrepeats, random_state=seed\n",
    "        ).split(X, labels),\n",
    "        total=nfolds*nrepeats, disable=not verbose\n",
    "    ):\n",
    "        \n",
    "        # Select the data for this fold.\n",
    "        X_train_fold = tf.gather(X, train_index) \n",
    "        y_train_fold = tf.gather(y, train_index)\n",
    "        X_test_fold = tf.gather(X, test_index)\n",
    "        y_test_fold = tf.gather(y, test_index)\n",
    "        \n",
    "        # Train and evaluate the model.\n",
    "        _, train_acc, test_acc = evaluate_model(\n",
    "            nclasses,\n",
    "            X_train_fold,\n",
    "            y_train_fold,\n",
    "            X_test_fold,\n",
    "            y_test_fold,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            model_maker=model_maker,\n",
    "            **model_params\n",
    "        )\n",
    "        train_accs.append(train_acc)\n",
    "        test_accs.append(test_acc)\n",
    "    \n",
    "    # Aggregate.\n",
    "    results = {\n",
    "        \"train_mean\": np.mean(train_accs),\n",
    "        \"train_std\": np.std(train_accs),\n",
    "        \"test_mean\": np.mean(test_accs),\n",
    "        \"test_std\": np.std(test_accs)\n",
    "    }\n",
    "    \n",
    "    # Report.\n",
    "    if verbose:\n",
    "        print(\n",
    "            tabulate(\n",
    "                [\n",
    "                    [\"Train\", results[\"train_mean\"], results[\"train_std\"]],\n",
    "                    [\"Test\", results[\"test_mean\"], results[\"test_std\"]]\n",
    "                ],\n",
    "                headers=[\"Set\", \"Accuracy\", \"Standard Deviation\"]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b7202c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = [ctscan_embedding, ultrasound_embedding, xray_embedding]\n",
    "y_list = [ctscan_data.y, ultrasound_data.y, xray_data.y]\n",
    "data_labels = [ctscan_data.labels, ultrasound_data.labels, xray_data.label2index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dda8ae98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 2, 2, 512)\n"
     ]
    }
   ],
   "source": [
    "ctscan_embedding2d = tf.reshape(ctscan_embedding, [-1,2,2,512])\n",
    "ultrasound_embedding2d = tf.reshape(ultrasound_embedding, [-1,2,2,512])\n",
    "xray_embedding2d = tf.reshape(xray_embedding, [-1,2,2,512])\n",
    "print(ctscan_embedding2d.shape)\n",
    "\n",
    "X_list = [ctscan_embedding2d, ultrasound_embedding2d, xray_embedding2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "16b306bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cv_evaluate_params = {\n",
    "    \"X\": X_list[0],\n",
    "    \"y\": y_list[0],\n",
    "    \"labels\": data_labels[0],\n",
    "    \"nfolds\": 10,\n",
    "    \"nrepeats\": 3,\n",
    "    \"model_maker\": make_model,\n",
    "    \"epochs\": 200,\n",
    "    \"batch_size\": 32,\n",
    "    \"verbose\": False,\n",
    "    \"learning_rate\": 3e-3 #0.003\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411716b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_68 (Conv2D)           (None, 2, 2, 16)          73744     \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 2, 2, 16)          64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 2, 2, 24)          3480      \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 2, 2, 24)          96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling (None, 2, 2, 24)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 2, 2, 32)          6944      \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 2, 2, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 2, 2, 48)          13872     \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 2, 2, 48)          192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling (None, 2, 2, 48)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 2, 2, 64)          27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 176,154\n",
      "Trainable params: 175,786\n",
      "Non-trainable params: 368\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▋                                                                               | 1/30 [01:54<55:12, 114.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_73 (Conv2D)           (None, 2, 2, 16)          73744     \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 2, 2, 16)          64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 2, 2, 24)          3480      \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 2, 2, 24)          96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling (None, 2, 2, 24)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 2, 2, 32)          6944      \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 2, 2, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_72 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 2, 2, 48)          13872     \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 2, 2, 48)          192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_73 (MaxPooling (None, 2, 2, 48)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 2, 2, 64)          27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 176,154\n",
      "Trainable params: 175,786\n",
      "Non-trainable params: 368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "_ = cv_evaluate_model(\n",
    "    **{\n",
    "        **default_cv_evaluate_params,\n",
    "        \"verbose\": True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "672f5c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415, 2048)\n",
      "(47, 2048)\n",
      "(415, 2)\n",
      "(47, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/30 [00:06<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:229 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_15 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 2048)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-0c1182d19406>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m# Train the model on the training set and evaluate it on the test set.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 759\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    760\u001b[0m             *args, **kwds))\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:229 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_15 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 2048)\n"
     ]
    }
   ],
   "source": [
    "X = X_list[0]\n",
    "y = y_list[0]\n",
    "labels = data_labels[0]\n",
    "train_accs, test_accs = [], []\n",
    "history = []\n",
    "    \n",
    "# Train and evaluate the model for each fold.\n",
    "for train_index, test_index in tqdm(\n",
    "    RepeatedStratifiedKFold(\n",
    "        n_splits=10, n_repeats=3, random_state=0\n",
    "    ).split(X, labels),\n",
    "    total=10*3, disable = not True #(verbose - True)\n",
    "):\n",
    "\n",
    "    # Select the data for this fold.\n",
    "    X_train = tf.gather(X, train_index) \n",
    "    y_train = tf.gather(y, train_index)\n",
    "    X_test = tf.gather(X, test_index)\n",
    "    y_test = tf.gather(y, test_index)\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    #Define Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 16, kernel_size = (3,3), padding='same', input_shape=(2,2,512), activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(1,1))\n",
    "    model.add(Conv2D(24, (3,3), padding='same', activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(1,1))\n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(1,1))\n",
    "    model.add(Conv2D(48, (3,3), padding='same', activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(1,1))\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(1,1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128,activation=\"relu\"))\n",
    "    model.add(Dense(2, activation=\"sigmoid\"))\n",
    "\n",
    "    #Learning Rate\n",
    "    steps_per_epoch = math.ceil(len(X_train) / 64) #batch - 64\n",
    "    third_of_total_steps = math.floor(100 * steps_per_epoch / 3) #epoch - 100\n",
    "    \n",
    "    # Train and evaluate the model.\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=ExponentialDecay(\n",
    "                0.0003,\n",
    "                decay_steps=third_of_total_steps,\n",
    "                decay_rate=0.1,\n",
    "                staircase=True\n",
    "            )\n",
    "        ),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    # Train the model on the training set and evaluate it on the test set.\n",
    "    history = (model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1, validation_data=(X_test, y_test)))\n",
    "    train_loss, train_acc = model.evaluate(X_test, y_test, batch_size=64, verbose=0)\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, batch_size=64, verbose=0)\n",
    "    \n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "\n",
    "# Aggregate.\n",
    "results = {\n",
    "    \"Train_Acc\": np.mean(train_accs),\n",
    "    \"Train_std\": np.std(train_accs),\n",
    "    \"Test_Acc\": np.mean(test_accs),\n",
    "    \"Test_std\": np.std(test_accs)\n",
    "}\n",
    "\n",
    "# Report.\n",
    "if verbose:\n",
    "    print(\n",
    "        tabulate(\n",
    "            [\n",
    "                [\"Train\", results[\"Train_Acc\"], results[\"Train_std\"]],\n",
    "                [\"Test\", results[\"Test_Acc\"], results[\"Test_std\"]]\n",
    "            ],\n",
    "            headers=[\"Set\", \"Accuracy\", \"Standard Deviation\"]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd586ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
