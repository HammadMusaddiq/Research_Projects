{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86adf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/images/transfer_learning#data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5380d5df",
   "metadata": {
    "id": "5380d5df"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd10b90d",
   "metadata": {
    "id": "cd10b90d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a30730a",
   "metadata": {
    "id": "7a30730a"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Flatten,MaxPooling2D,Dropout,Dense,Activation,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bdede3d",
   "metadata": {
    "id": "1bdede3d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "84b09238",
   "metadata": {
    "id": "84b09238"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe0c3b7",
   "metadata": {
    "id": "cbe0c3b7"
   },
   "outputs": [],
   "source": [
    "# selecting random number of images from multiple folders and copying it to the destination folder\n",
    "# Combined Prediction (take new sample and make combine data)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "# ctscan_covid_data = random.sample(glob.glob(\"Custom_Data/CT_Scan/Covid/CT_COVID/*.png\"), 330)\n",
    "# ctscan_normal_data = random.sample(glob.glob(\"Custom_Data/CT_Scan/Normal/CT_nonCOVID/*\"), 330)\n",
    "\n",
    "# ultrasound_covid_data = random.sample(glob.glob(\"Custom_Data/ultrasound/Covid/*\"), 330)\n",
    "# ultrasound_normal_data = random.sample(glob.glob(\"Custom_Data/ultrasound/Normal/*.jpg\"), 330)\n",
    "\n",
    "# xray_covid_data = random.sample(glob.glob(\"Custom_Data/X_ray/Covid/*.png\"), 330)\n",
    "# xray_normal_data = random.sample(glob.glob(\"Custom_Data/X_ray/Normal/*.png\"), 330)\n",
    "\n",
    "ctscan_covid_data = random.sample(glob.glob(\"Hamza_Custom_Data/CT_Scan/Covid/*.png\"), 330)\n",
    "ctscan_normal_data = random.sample(glob.glob(\"Hamza_Custom_Data/CT_Scan/Normal/*\"), 330)   \n",
    "\n",
    "ultrasound_covid_data = random.sample(glob.glob(\"Hamza_Custom_Data/Ultra_Sound/Covid/*\"), 330)\n",
    "ultrasound_normal_data = random.sample(glob.glob(\"Hamza_Custom_Data/Ultra_Sound/Normal/*.jpg\"), 330)\n",
    "\n",
    "xray_covid_data = random.sample(glob.glob(\"Hamza_Custom_Data/X_Ray/Covid/*.png\"), 330)\n",
    "xray_normal_data = random.sample(glob.glob(\"Hamza_Custom_Data/X_Ray/Normal/*.png\"), 330)\n",
    "\n",
    "covid_list=[ctscan_covid_data,ultrasound_covid_data,xray_covid_data]\n",
    "\n",
    "normal_list = [ctscan_normal_data, ultrasound_normal_data,xray_normal_data]\n",
    "\n",
    "if os.path.isdir('Data/Covid'):\n",
    "    shutil.rmtree('Data/Covid')\n",
    "    \n",
    "if os.path.isdir('Data/Normal'):\n",
    "    shutil.rmtree('Data/Normal')\n",
    "\n",
    "for data in covid_list:\n",
    "    dest = 'Data/Covid'\n",
    "    if not os.path.isdir('Data/Covid'):\n",
    "        os.makedirs(dest)\n",
    "    for imgs in data:\n",
    "        shutil.copy(imgs, dest)\n",
    "\n",
    "for data in normal_list:\n",
    "    dest = 'Data/Normal' \n",
    "    if not os.path.isdir('Data/Normal'):\n",
    "          os.makedirs(dest)\n",
    "    for imgs in data:\n",
    "        shutil.copy(imgs, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7d589a7",
   "metadata": {
    "id": "f7d589a7"
   },
   "outputs": [],
   "source": [
    "# pre-processing (image shape)\n",
    "# X shape in 3 dimensions\n",
    "# Y has 2 classes (Covid, Normal)\n",
    "# make train and test data\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, data_root: str, *, test_size: float, img_size: int, seed: int = 0) -> None:\n",
    "        self.label2index = {}\n",
    "        self.index2label = {}\n",
    "        \n",
    "        # Discover the class label names.\n",
    "        class_labels = os.listdir(data_root)\n",
    "        self.nclasses = len(class_labels)\n",
    "        X, y = [], []\n",
    "        \n",
    "        for label_index, label in enumerate(class_labels):\n",
    "            # Load the images for this class label.\n",
    "            self.label2index[label_index] = label\n",
    "            self.index2label[label] = label_index\n",
    "            \n",
    "            img_names = os.listdir(os.path.join(data_root, label))\n",
    "            for img_name in img_names:\n",
    "                img_path = os.path.join(data_root, label, img_name)\n",
    "                img = load_img(img_path, target_size=(img_size, img_size, 3))\n",
    "                X.append(img_to_array(img))\n",
    "                y.append(label_index)\n",
    "        \n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        one_hot_y = to_categorical(y, num_classes=self.nclasses)\n",
    "        \n",
    "        # Make a stratified split.\n",
    "        self.X_train, self.X_test, self.labels_train, self.labels_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, one_hot_y, test_size=test_size, random_state=seed, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70ad25ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70ad25ed",
    "outputId": "ceebd03a-c68e-494f-8bb7-4d52bebfb574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1386, 224, 224, 3) (1386, 2)\n",
      "(594, 224, 224, 3) (594, 2)\n"
     ]
    }
   ],
   "source": [
    "# (660*3) * 0.7 = 1386\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "data = Dataset(\"Data/\", test_size=0.3, img_size=224)\n",
    "print(data.X_train.shape, data.y_train.shape)\n",
    "print(data.X_test.shape, data.y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9357c763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.X_train.shape[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90db7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobinet_model = tf.keras.applications.MobileNetV2(input_shape=data.X_train.shape[1:4], include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb6b3bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "171319296/171317808 [==============================] - 365s 2us/step\n",
      "171327488/171317808 [==============================] - 365s 2us/step\n"
     ]
    }
   ],
   "source": [
    "resnet_model = tf.keras.applications.ResNet101V2(input_shape=data.X_train.shape[1:4], include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f22597f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 188s 2us/step\n",
      "80150528/80134624 [==============================] - 188s 2us/step\n"
     ]
    }
   ],
   "source": [
    "vgg_model = tf.keras.applications.vgg19.VGG19(input_shape=data.X_train.shape[1:4], include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "FuhCijq7mxKy",
   "metadata": {
    "id": "FuhCijq7mxKy",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature extractor model resnet 101 v2\n",
    "# model = hub.KerasLayer(\"https://tfhub.dev/google/bit/m-r101x1/1\", trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b1dcb4c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "b1dcb4c7",
    "outputId": "4637b29a-a5fb-4a4a-d0e0-55b8a583f993",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-ec883affba6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcovid_train_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmobinet_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#covid_test_embedding = mobinet_model(data.X_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcovid_train_embedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m--> 414\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    415\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    756\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         \u001b[1;31m# Currently never reaches here since fused_batch_norm does not support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# pylint: enable=g-long-lambda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m     output, mean, variance = control_flow_util.smart_cond(\n\u001b[0m\u001b[0;32m    612\u001b[0m         training, train_op, _fused_batch_norm_inference)\n\u001b[0;32m    613\u001b[0m     \u001b[0mvariance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_add_or_remove_bessels_correction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremove\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\control_flow_util.py\u001b[0m in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m    103\u001b[0m     return tf.cond(\n\u001b[0;32m    104\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m--> 105\u001b[1;33m   return tf.__internal__.smart_cond.smart_cond(\n\u001b[0m\u001b[0;32m    106\u001b[0m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm_inference\u001b[1;34m()\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fused_batch_norm_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m       return tf.compat.v1.nn.fused_batch_norm(\n\u001b[0m\u001b[0;32m    594\u001b[0m           \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m           \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\u001b[0m in \u001b[0;36mfused_batch_norm\u001b[1;34m(x, scale, offset, mean, variance, epsilon, data_format, is_training, name, exponential_avg_factor)\u001b[0m\n\u001b[0;32m   1666\u001b[0m   \u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmin_epsilon\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmin_epsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1668\u001b[1;33m   y, running_mean, running_var, _, _, _ = gen_nn_ops.fused_batch_norm_v3(\n\u001b[0m\u001b[0;32m   1669\u001b[0m       \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1670\u001b[0m       \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mfused_batch_norm_v3\u001b[1;34m(x, scale, offset, mean, variance, epsilon, exponential_avg_factor, data_format, is_training, name)\u001b[0m\n\u001b[0;32m   4260\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4261\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4262\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   4263\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"FusedBatchNormV3\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariance\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4264\u001b[0m         \u001b[1;34m\"epsilon\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exponential_avg_factor\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexponential_avg_factor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "covid_train_embedding = mobinet_model(data.X_train)\n",
    "#covid_test_embedding = mobinet_model(data.X_test)\n",
    "print(covid_train_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88ebe407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_224\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobinet_model.trainable = False\n",
    "mobinet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aed4b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 32\n",
    "# IMG_SIZE = (224, 224)\n",
    "# dataset = tf.keras.utils.image_dataset_from_directory(\"Data\",\n",
    "#                                                       shuffle=True,\n",
    "#                                                       batch_size=BATCH_SIZE,\n",
    "#                                                       image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c04bf6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28b29054",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ada66f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1386, 1280)\n"
     ]
    }
   ],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(covid_train_embedding)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f9b51df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1386, 2)\n"
     ]
    }
   ],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(2)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fc173a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "inputs = tf.keras.Input(shape=(data.X_train.shape[1:4]))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = mobinet_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "32c7a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e95714b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv_1 (TFOpLambd (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLamb (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43b8e030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02843684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1386, 7, 7, 1280)\n",
      "(1386, 1280)\n"
     ]
    }
   ],
   "source": [
    "print(covid_train_embedding.shape)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3abc588",
   "metadata": {
    "id": "b3abc588"
   },
   "outputs": [],
   "source": [
    "# X_train_val = covid_train_embedding\n",
    "# y_train_val = data.y_train\n",
    "# data_train_labels = data.labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2fa74467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_val = covid_test_embedding\n",
    "# y_test_val = data.y_test\n",
    "# data_test_labels = data.labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0454dea",
   "metadata": {
    "id": "b0454dea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1386, 2, 2, 320)\n",
      "(1386, 2, 2, 320)\n"
     ]
    }
   ],
   "source": [
    "# # Chaning shape for CNN2D\n",
    "# # for 2048 - > [-1,2,2,512]\n",
    "# # for 1280 - > [-1,2,2,320]\n",
    "\n",
    "# covid_train_embedding2d = tf.reshape(feature_batch_average, [-1,2,2,320])\n",
    "# print(covid_train_embedding2d.shape)\n",
    "\n",
    "# covid_test_embedding2d = tf.reshape(feature_batch_average, [-1,2,2,320])\n",
    "# print(covid_test_embedding2d.shape)\n",
    "\n",
    "# X_train_val = covid_train_embedding2d\n",
    "# X_test_val = covid_test_embedding2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "621464f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.7700 - accuracy: 0.5281 - val_loss: 0.7218 - val_accuracy: 0.5303\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 76s 2s/step - loss: 0.7390 - accuracy: 0.5527 - val_loss: 0.6896 - val_accuracy: 0.5943\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 76s 2s/step - loss: 0.7067 - accuracy: 0.6053 - val_loss: 0.6668 - val_accuracy: 0.6313\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 73s 2s/step - loss: 0.7023 - accuracy: 0.6039 - val_loss: 0.6475 - val_accuracy: 0.6650\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 71s 2s/step - loss: 0.6617 - accuracy: 0.6623 - val_loss: 0.6292 - val_accuracy: 0.6919\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.6532 - accuracy: 0.6602 - val_loss: 0.6134 - val_accuracy: 0.7104\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 74s 2s/step - loss: 0.6516 - accuracy: 0.6674 - val_loss: 0.6026 - val_accuracy: 0.7189\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 76s 2s/step - loss: 0.6261 - accuracy: 0.6970 - val_loss: 0.5891 - val_accuracy: 0.7407\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 75s 2s/step - loss: 0.6164 - accuracy: 0.7020 - val_loss: 0.5799 - val_accuracy: 0.7374\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 85s 2s/step - loss: 0.6079 - accuracy: 0.7027 - val_loss: 0.5680 - val_accuracy: 0.7542\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid keyword arguments: {'validation_data': (array([[[[ 23.,  23.,  23.],\n         [ 28.,  28.,  28.],\n         [ 28.,  28.,  28.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[ 27.,  27.,  27.],\n         [ 33.,  33.,  33.],\n         [ 33.,  33.,  33.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[ 27.,  27.,  27.],\n         [ 32.,  32.,  32.],\n         [ 33.,  33.,  33.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        ...,\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]]],\n\n\n       [[[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        ...,\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]]],\n\n\n       [[[ 59.,  59.,  59.],\n         [ 53.,  53.,  53.],\n         [ 50.,  50.,  50.],\n         ...,\n         [ 49.,  49.,  49.],\n         [ 56.,  56.,  56.],\n         [185., 185., 185.]],\n\n        [[ 49.,  49.,  49.],\n         [ 50.,  50.,  50.],\n         [ 45.,  45.,  45.],\n         ...,\n         [ 43.,  43.,  43.],\n         [ 40.,  40.,  40.],\n         [183., 183., 183.]],\n\n        [[ 48.,  48.,  48.],\n         [ 47.,  47.,  47.],\n         [ 46.,  46.,  46.],\n         ...,\n         [ 45.,  45.,  45.],\n         [ 49.,  49.,  49.],\n         [186., 186., 186.]],\n\n        ...,\n\n        [[ 41.,  41.,  41.],\n         [ 35.,  35.,  35.],\n         [ 44.,  44.,  44.],\n         ...,\n         [ 45.,  45.,  45.],\n         [ 39.,  39.,  39.],\n         [182., 182., 182.]],\n\n        [[ 35.,  35.,  35.],\n         [ 38.,  38.,  38.],\n         [ 32.,  32.,  32.],\n         ...,\n         [ 35.,  35.,  35.],\n         [ 40.,  40.,  40.],\n         [177., 177., 177.]],\n\n        [[ 14.,  14.,  14.],\n         [ 10.,  10.,  10.],\n         [ 10.,  10.,  10.],\n         ...,\n         [ 12.,  12.,  12.],\n         [ 13.,  13.,  13.],\n         [169., 169., 169.]]],\n\n\n       ...,\n\n\n       [[[190., 190., 190.],\n         [181., 181., 181.],\n         [177., 177., 177.],\n         ...,\n         [199., 199., 199.],\n         [204., 204., 204.],\n         [189., 189., 189.]],\n\n        [[164., 164., 164.],\n         [125., 125., 125.],\n         [111., 111., 111.],\n         ...,\n         [173., 173., 173.],\n         [179., 179., 179.],\n         [167., 167., 167.]],\n\n        [[129., 129., 129.],\n         [ 63.,  63.,  63.],\n         [ 45.,  45.,  45.],\n         ...,\n         [110., 110., 110.],\n         [118., 118., 118.],\n         [119., 119., 119.]],\n\n        ...,\n\n        [[ 10.,  10.,  10.],\n         [  9.,   9.,   9.],\n         [  9.,   9.,   9.],\n         ...,\n         [  9.,   9.,   9.],\n         [  1.,   1.,   1.],\n         [  0.,   0.,   0.]],\n\n        [[ 10.,  10.,  10.],\n         [  9.,   9.,   9.],\n         [  9.,   9.,   9.],\n         ...,\n         [  5.,   5.,   5.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[ 10.,  10.,  10.],\n         [  9.,   9.,   9.],\n         [  9.,   9.,   9.],\n         ...,\n         [  1.,   1.,   1.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]]],\n\n\n       [[[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        ...,\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]]],\n\n\n       [[[  5.,   5.,   5.],\n         [  5.,   5.,   5.],\n         [  5.,   5.,   5.],\n         ...,\n         [  9.,   9.,   9.],\n         [ 13.,  13.,  13.],\n         [  9.,   9.,   9.]],\n\n        [[  6.,   6.,   6.],\n         [  5.,   5.,   5.],\n         [  5.,   5.,   5.],\n         ...,\n         [  5.,   5.,   5.],\n         [  5.,   5.,   5.],\n         [  7.,   7.,   7.]],\n\n        [[  6.,   6.,   6.],\n         [  6.,   6.,   6.],\n         [  6.,   6.,   6.],\n         ...,\n         [  5.,   5.,   5.],\n         [  6.,   6.,   6.],\n         [  8.,   8.,   8.]],\n\n        ...,\n\n        [[  4.,   4.,   4.],\n         [  6.,   6.,   6.],\n         [  6.,   6.,   6.],\n         ...,\n         [  7.,   7.,   7.],\n         [  7.,   7.,   7.],\n         [  7.,   7.,   7.]],\n\n        [[  4.,   4.,   4.],\n         [  6.,   6.,   6.],\n         [  6.,   6.,   6.],\n         ...,\n         [  7.,   7.,   7.],\n         [  7.,   7.,   7.],\n         [  7.,   7.,   7.]],\n\n        [[  5.,   5.,   5.],\n         [  6.,   6.,   6.],\n         [  6.,   6.,   6.],\n         ...,\n         [  7.,   7.,   7.],\n         [  7.,   7.,   7.],\n         [  6.,   6.,   6.]]]], dtype=float32), array([[0., 1.],\n       [0., 1.],\n       [0., 1.],\n       ...,\n       [0., 1.],\n       [0., 1.],\n       [1., 0.]], dtype=float32))}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-978678ee86f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minitial_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mloss0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1451\u001b[0m     \u001b[0muse_cached_eval_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_use_cached_eval_dataset'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1452\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1453\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid keyword arguments: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1455\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_use_with_coordinator\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid keyword arguments: {'validation_data': (array([[[[ 23.,  23.,  23.],\n         [ 28.,  28.,  28.],\n         [ 28.,  28.,  28.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[ 27.,  27.,  27.],\n         [ 33.,  33.,  33.],\n         [ 33.,  33.,  33.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[ 27.,  27.,  27.],\n         [ 32.,  32.,  32.],\n         [ 33.,  33.,  33.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        ...,\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]]],\n\n\n       [[[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        ...,\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]]],\n\n\n       [[[ 59.,  59.,  59.],\n         [ 53.,  53.,  53.],\n         [ 50.,  50.,  50.],\n         ...,\n         [ 49.,  49.,  49.],\n         [ 56.,  56.,  56.],\n         [185., 185., 185.]],\n\n        [[ 49.,  49.,  49.],\n         [ 50.,  50.,  50.],\n         [ 45.,  45.,  45.],\n         ...,\n         [ 43.,  43.,  43.],\n         [ 40.,  40.,  40.],\n         [183., 183., 183.]],\n\n        [[ 48.,  48.,  48.],\n         [ 47.,  47.,  47.],\n         [ 46.,  46.,  46.],\n         ...,\n         [ 45.,  45.,  45.],\n         [ 49.,  49.,  49.],\n         [186., 186., 186.]],\n\n        ...,\n\n        [[ 41.,  41.,  41.],\n         [ 35.,  35.,  35.],\n         [ 44.,  44.,  44.],\n         ...,\n         [ 45.,  45.,  45.],\n         [ 39.,  39.,  39.],\n         [182., 182., 182.]],\n\n        [[ 35.,  35.,  35.],\n         [ 38.,  38.,  38.],\n         [ 32.,  32.,  32.],\n         ...,\n         [ 35.,  35.,  35.],\n         [ 40.,  40.,  40.],\n         [177., 177., 177.]],\n\n        [[ 14.,  14.,  14.],\n         [ 10.,  10.,  10.],\n         [ 10.,  10.,  10.],\n         ...,\n         [ 12.,  12.,  12.],\n         [ 13.,  13.,  13.],\n         [169., 169., 169.]]],\n\n\n       ...,\n\n\n       [[[190., 190., 190.],\n         [181., 181., 181.],\n         [177., 177., 177.],\n         ...,\n         [199., 199., 199.],\n         [204., 204., 204.],\n         [189., 189., 189.]],\n\n        [[164., 164., 164.],\n         [125., 125., 125.],\n         [111., 111., 111.],\n         ...,\n         [173., 173., 173.],\n         [179., 179., 179.],\n         [167., 167., 167.]],\n\n        [[129., 129., 129.],\n         [ 63.,  63.,  63.],\n         [ 45.,  45.,  45.],\n         ...,\n         [110., 110., 110.],\n         [118., 118., 118.],\n         [119., 119., 119.]],\n\n        ...,\n\n        [[ 10.,  10.,  10.],\n         [  9.,   9.,   9.],\n         [  9.,   9.,   9.],\n         ...,\n         [  9.,   9.,   9.],\n         [  1.,   1.,   1.],\n         [  0.,   0.,   0.]],\n\n        [[ 10.,  10.,  10.],\n         [  9.,   9.,   9.],\n         [  9.,   9.,   9.],\n         ...,\n         [  5.,   5.,   5.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[ 10.,  10.,  10.],\n         [  9.,   9.,   9.],\n         [  9.,   9.,   9.],\n         ...,\n         [  1.,   1.,   1.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]]],\n\n\n       [[[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        ...,\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]],\n\n        [[  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         ...,\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.],\n         [  0.,   0.,   0.]]],\n\n\n       [[[  5.,   5.,   5.],\n         [  5.,   5.,   5.],\n         [  5.,   5.,   5.],\n         ...,\n         [  9.,   9.,   9.],\n         [ 13.,  13.,  13.],\n         [  9.,   9.,   9.]],\n\n        [[  6.,   6.,   6.],\n         [  5.,   5.,   5.],\n         [  5.,   5.,   5.],\n         ...,\n         [  5.,   5.,   5.],\n         [  5.,   5.,   5.],\n         [  7.,   7.,   7.]],\n\n        [[  6.,   6.,   6.],\n         [  6.,   6.,   6.],\n         [  6.,   6.,   6.],\n         ...,\n         [  5.,   5.,   5.],\n         [  6.,   6.,   6.],\n         [  8.,   8.,   8.]],\n\n        ...,\n\n        [[  4.,   4.,   4.],\n         [  6.,   6.,   6.],\n         [  6.,   6.,   6.],\n         ...,\n         [  7.,   7.,   7.],\n         [  7.,   7.,   7.],\n         [  7.,   7.,   7.]],\n\n        [[  4.,   4.,   4.],\n         [  6.,   6.,   6.],\n         [  6.,   6.,   6.],\n         ...,\n         [  7.,   7.,   7.],\n         [  7.,   7.,   7.],\n         [  7.,   7.,   7.]],\n\n        [[  5.,   5.,   5.],\n         [  6.,   6.,   6.],\n         [  6.,   6.,   6.],\n         ...,\n         [  7.,   7.,   7.],\n         [  7.,   7.,   7.],\n         [  6.,   6.,   6.]]]], dtype=float32), array([[0., 1.],\n       [0., 1.],\n       [0., 1.],\n       ...,\n       [0., 1.],\n       [0., 1.],\n       [1., 0.]], dtype=float32))}"
     ]
    }
   ],
   "source": [
    "initial_epochs = 10\n",
    "history = model.fit(data.X_train, data.y_train, epochs=initial_epochs, validation_data=(data.X_test, data.y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6711d165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(594, 2)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "29cb7811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 19s 971ms/step - loss: 0.5680 - accuracy: 0.7542\n"
     ]
    }
   ],
   "source": [
    "loss0, accuracy0 = model.evaluate(data.X_test, data.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b9c3de1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss: 0.57\n",
      "initial accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bc777765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e0f59b",
   "metadata": {},
   "source": [
    "### Fine Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bb813a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobinet_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4ab336ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  154\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(mobinet_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in mobinet_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d4cb50ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "444300df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv_2 (TFOpLambd (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_2 (TFOpLamb (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 1,864,002\n",
      "Non-trainable params: 396,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5889cbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e6743b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "44/44 [==============================] - 93s 2s/step - loss: 0.5654 - accuracy: 0.7244 - val_loss: 0.4948 - val_accuracy: 0.7929\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.5079 - accuracy: 0.7756"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-52882bcc1f96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtotal_epochs\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0minitial_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfine_tune_epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m history_fine = model.fit(data.X_train, data.y_train,\n\u001b[0m\u001b[0;32m      5\u001b[0m                          \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                          \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1215\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1216\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1501\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(data.X_train, data.y_train,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         validation_data=(data.X_test, data.y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2513d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c636cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0.8, 1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5e856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(data.X_test, data.y_test)\n",
    "print('Test accuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2b621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(data.X_test)\n",
    "y_pred1 = np.argmax(y_pred, axis=1)\n",
    "y_test1 = np.argmax(data.y_test, axis=1)\n",
    "\n",
    "print(accuracy_score(y_test1, y_pred1))\n",
    "print(confusion_matrix(y_test1,y_pred1))\n",
    "print(classification_report(y_test1,y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5321696a",
   "metadata": {},
   "source": [
    "### Graph Method for Resnet 101 v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c22543a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train_val.shape)\n",
    "# print(y_train_val.shape)\n",
    "# print(data_train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "74ab6264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_test_val.shape)\n",
    "# print(y_test_val.shape)\n",
    "# print(data_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "00b37e3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # test train split\n",
    "\n",
    "# #Define Model\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(filters = 16, kernel_size = (3,3), padding='same', input_shape=(2,2,512), activation=\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(1,1))\n",
    "# model.add(Conv2D(24, (3,3), padding='same', activation=\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(1,1))\n",
    "# model.add(Conv2D(32, (3,3), padding='same', activation=\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(1,1))\n",
    "# model.add(Conv2D(48, (3,3), padding='same', activation=\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(1,1))\n",
    "# model.add(Conv2D(64, (3,3), padding='same', activation=\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(1,1))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128,activation=\"relu\"))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(128,activation=\"relu\"))\n",
    "# model.add(Dense(y_train_val.shape[1], activation=\"sigmoid\"))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "# history = model.fit(X_train_val, y_train_val, epochs=32, batch_size=16, verbose=2, validation_data=(X_test_val, y_test_val))\n",
    "\n",
    "# train_loss, train_acc = model.evaluate(X_train_val, y_train_val, verbose=0)\n",
    "# test_loss, test_acc = model.evaluate(X_test_val, y_test_val, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "98e832c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a970301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Train Loss: \" + str(train_loss))\n",
    "# print(\"Train Accuracy: \" + str(train_acc))\n",
    "\n",
    "# print(\"Test Loss: \" + str(test_loss))\n",
    "# print(\"Test Accuracy: \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "77958f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test_val)\n",
    "# y_pred1 = np.argmax(y_pred, axis=1)\n",
    "# y_test1 = np.argmax(y_test_val, axis=1)\n",
    "\n",
    "# print(accuracy_score(y_test1, y_pred1))\n",
    "# print(confusion_matrix(y_test1,y_pred1))\n",
    "# print(classification_report(y_test1,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "edca2572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ploting graph by using values of last epoch for graphs\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.style.use('ggplot')\n",
    "\n",
    "# def plot_history(history):\n",
    "#     acc = history.history['accuracy']\n",
    "#     val_acc = history.history['val_accuracy']\n",
    "#     loss = history.history['loss']\n",
    "#     val_loss = history.history['val_loss']\n",
    "#     x = range(1, len(acc) + 1)\n",
    "\n",
    "#     plt.figure(figsize=(12, 5))\n",
    "    \n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(x, acc, 'b', label='Training acc')\n",
    "#     plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "#     plt.title('Training and validation accuracy')\n",
    "#     plt.ylabel('Accuracy value (%)')\n",
    "#     plt.xlabel('No. epoch')\n",
    "#     plt.legend()\n",
    "    \n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.plot(x, loss, 'b', label='Training loss')\n",
    "#     plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "#     plt.title('Training and validation loss')\n",
    "#     plt.ylabel('Loss value')\n",
    "#     plt.xlabel('No. epoch')\n",
    "#     plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fab3a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f68043f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #All in one Graph (loss and accuracy)\n",
    "# plt.style.use('default')\n",
    "# plt.figure(figsize=(7, 3))\n",
    "# plt.plot(history.history[\"accuracy\"])\n",
    "# plt.plot(history.history[\"val_accuracy\"])\n",
    "# plt.plot(history.history[\"loss\"]) \n",
    "# plt.plot(history.history[\"val_loss\"]) \n",
    "# plt.title(\"Model Evaluation\")\n",
    "# plt.ylabel(\"Value (%)\")\n",
    "# plt.xlabel(\"No. of Epochs\")\n",
    "# plt.legend([\"Training Accuracy\",\"Validation Accuracy\",\"Training loss\",\"Validation loss\"])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3607f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af07519b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Hamza_Code.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "82ed002fa2d4956f5c6aec99bcefe0f73a9f79882f3c9e2319b14958a5896ac5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
