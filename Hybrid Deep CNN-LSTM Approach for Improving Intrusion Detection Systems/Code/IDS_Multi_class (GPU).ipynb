{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1f45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7174098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32ca6f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a12416f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0210216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout,Activation\n",
    "\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "#from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Embedding\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caeb4ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7e9393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"IDS_Combined_Data_IoT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "639309d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>fridge_temperature</th>\n",
       "      <th>temp_condition</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "      <th>door_state</th>\n",
       "      <th>sphone_signal</th>\n",
       "      <th>latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>FC2_Read_Discrete_Value</th>\n",
       "      <th>FC3_Read_Holding_Register</th>\n",
       "      <th>FC4_Read_Coil</th>\n",
       "      <th>motion_status</th>\n",
       "      <th>light_status</th>\n",
       "      <th>current_temperature</th>\n",
       "      <th>thermostat_status</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1556245180</td>\n",
       "      <td>25-Apr-19</td>\n",
       "      <td>19:19:40</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ddos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>...</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>1</td>\n",
       "      <td>23.016184</td>\n",
       "      <td>1.035</td>\n",
       "      <td>46.343618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1556245180</td>\n",
       "      <td>25-Apr-19</td>\n",
       "      <td>19:19:40</td>\n",
       "      <td>9.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ddos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>...</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>1</td>\n",
       "      <td>38.620990</td>\n",
       "      <td>1.035</td>\n",
       "      <td>46.343618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1556245185</td>\n",
       "      <td>25-Apr-19</td>\n",
       "      <td>19:19:45</td>\n",
       "      <td>12.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ddos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>...</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>1</td>\n",
       "      <td>42.732741</td>\n",
       "      <td>1.035</td>\n",
       "      <td>46.343618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1556245185</td>\n",
       "      <td>25-Apr-19</td>\n",
       "      <td>19:19:45</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ddos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>...</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>1</td>\n",
       "      <td>37.785562</td>\n",
       "      <td>1.035</td>\n",
       "      <td>46.343618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1556245195</td>\n",
       "      <td>25-Apr-19</td>\n",
       "      <td>19:19:55</td>\n",
       "      <td>12.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ddos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>...</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>1</td>\n",
       "      <td>36.353584</td>\n",
       "      <td>1.035</td>\n",
       "      <td>46.343618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ts       date        time  fridge_temperature  temp_condition  \\\n",
       "0  1556245180  25-Apr-19   19:19:40                 9.00               1   \n",
       "1  1556245180  25-Apr-19   19:19:40                 9.25               1   \n",
       "2  1556245185  25-Apr-19   19:19:45                12.65               1   \n",
       "3  1556245185  25-Apr-19   19:19:45                 4.65               0   \n",
       "4  1556245195  25-Apr-19   19:19:55                12.65               1   \n",
       "\n",
       "   label  type  door_state  sphone_signal  latitude  ...  \\\n",
       "0      1  ddos           0              0  4.514077  ...   \n",
       "1      1  ddos           0              0  4.514077  ...   \n",
       "2      1  ddos           0              0  4.514077  ...   \n",
       "3      1  ddos           0              0  4.514077  ...   \n",
       "4      1  ddos           0              0  4.514077  ...   \n",
       "\n",
       "   FC2_Read_Discrete_Value  FC3_Read_Holding_Register  FC4_Read_Coil  \\\n",
       "0                    32708                      32035          32728   \n",
       "1                    32708                      32035          32728   \n",
       "2                    32708                      32035          32728   \n",
       "3                    32708                      32035          32728   \n",
       "4                    32708                      32035          32728   \n",
       "\n",
       "   motion_status  light_status  current_temperature  thermostat_status  \\\n",
       "0              0             0            28.442693                  1   \n",
       "1              0             0            28.442693                  1   \n",
       "2              0             0            28.442693                  1   \n",
       "3              0             0            28.442693                  1   \n",
       "4              0             0            28.442693                  1   \n",
       "\n",
       "   temperature  pressure   humidity  \n",
       "0    23.016184     1.035  46.343618  \n",
       "1    38.620990     1.035  46.343618  \n",
       "2    42.732741     1.035  46.343618  \n",
       "3    37.785562     1.035  46.343618  \n",
       "4    36.353584     1.035  46.343618  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cbb4c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.drop(['ts', 'date', 'time'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ec5c8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fridge_temperature</th>\n",
       "      <th>temp_condition</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "      <th>door_state</th>\n",
       "      <th>sphone_signal</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>FC1_Read_Input_Register</th>\n",
       "      <th>FC2_Read_Discrete_Value</th>\n",
       "      <th>FC3_Read_Holding_Register</th>\n",
       "      <th>FC4_Read_Coil</th>\n",
       "      <th>motion_status</th>\n",
       "      <th>light_status</th>\n",
       "      <th>current_temperature</th>\n",
       "      <th>thermostat_status</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ddos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>14.421946</td>\n",
       "      <td>32450</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>1</td>\n",
       "      <td>23.016184</td>\n",
       "      <td>1.035</td>\n",
       "      <td>46.343618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ddos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>14.421946</td>\n",
       "      <td>32450</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>1</td>\n",
       "      <td>38.620990</td>\n",
       "      <td>1.035</td>\n",
       "      <td>46.343618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ddos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>14.421946</td>\n",
       "      <td>32450</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>1</td>\n",
       "      <td>42.732741</td>\n",
       "      <td>1.035</td>\n",
       "      <td>46.343618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ddos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>14.421946</td>\n",
       "      <td>32450</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>1</td>\n",
       "      <td>37.785562</td>\n",
       "      <td>1.035</td>\n",
       "      <td>46.343618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ddos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>14.421946</td>\n",
       "      <td>32450</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>1</td>\n",
       "      <td>36.353584</td>\n",
       "      <td>1.035</td>\n",
       "      <td>46.343618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fridge_temperature  temp_condition  label  type  door_state  sphone_signal  \\\n",
       "0                9.00               1      1  ddos           0              0   \n",
       "1                9.25               1      1  ddos           0              0   \n",
       "2               12.65               1      1  ddos           0              0   \n",
       "3                4.65               0      1  ddos           0              0   \n",
       "4               12.65               1      1  ddos           0              0   \n",
       "\n",
       "   latitude  longitude  FC1_Read_Input_Register  FC2_Read_Discrete_Value  \\\n",
       "0  4.514077  14.421946                    32450                    32708   \n",
       "1  4.514077  14.421946                    32450                    32708   \n",
       "2  4.514077  14.421946                    32450                    32708   \n",
       "3  4.514077  14.421946                    32450                    32708   \n",
       "4  4.514077  14.421946                    32450                    32708   \n",
       "\n",
       "   FC3_Read_Holding_Register  FC4_Read_Coil  motion_status  light_status  \\\n",
       "0                      32035          32728              0             0   \n",
       "1                      32035          32728              0             0   \n",
       "2                      32035          32728              0             0   \n",
       "3                      32035          32728              0             0   \n",
       "4                      32035          32728              0             0   \n",
       "\n",
       "   current_temperature  thermostat_status  temperature  pressure   humidity  \n",
       "0            28.442693                  1    23.016184     1.035  46.343618  \n",
       "1            28.442693                  1    38.620990     1.035  46.343618  \n",
       "2            28.442693                  1    42.732741     1.035  46.343618  \n",
       "3            28.442693                  1    37.785562     1.035  46.343618  \n",
       "4            28.442693                  1    36.353584     1.035  46.343618  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51021a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal        245000\n",
       "backdoor       35000\n",
       "injection      35000\n",
       "password       35000\n",
       "ddos           25000\n",
       "ransomware     16030\n",
       "xss             6116\n",
       "scanning        3973\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef07de34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "773ef825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fridge_temperature', 'temp_condition', 'label', 'type', 'door_state',\n",
       "       'sphone_signal', 'latitude', 'longitude', 'FC1_Read_Input_Register',\n",
       "       'FC2_Read_Discrete_Value', 'FC3_Read_Holding_Register', 'FC4_Read_Coil',\n",
       "       'motion_status', 'light_status', 'current_temperature',\n",
       "       'thermostat_status', 'temperature', 'pressure', 'humidity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4682abf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401119, 17)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.drop(['label','type'], axis = 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d536273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401119,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset['type']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "351b7ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8))) #don't change these values\n",
    "X_T = sel.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2a8e022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fridge_temperature</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>FC1_Read_Input_Register</th>\n",
       "      <th>FC2_Read_Discrete_Value</th>\n",
       "      <th>FC3_Read_Holding_Register</th>\n",
       "      <th>FC4_Read_Coil</th>\n",
       "      <th>current_temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>14.421946</td>\n",
       "      <td>32450</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>23.016184</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>46.343618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.25</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>14.421946</td>\n",
       "      <td>32450</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>38.620990</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>46.343618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.65</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>14.421946</td>\n",
       "      <td>32450</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>42.732741</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>46.343618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.65</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>14.421946</td>\n",
       "      <td>32450</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>37.785562</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>46.343618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.65</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>14.421946</td>\n",
       "      <td>32450</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>36.353584</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>46.343618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401114</th>\n",
       "      <td>6.70</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>14.421946</td>\n",
       "      <td>32450</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>24.250404</td>\n",
       "      <td>2.204924</td>\n",
       "      <td>37.024913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401115</th>\n",
       "      <td>6.70</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>14.421946</td>\n",
       "      <td>32450</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>20.155984</td>\n",
       "      <td>-2.030547</td>\n",
       "      <td>90.297894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401116</th>\n",
       "      <td>6.70</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>14.421946</td>\n",
       "      <td>32450</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>24.577566</td>\n",
       "      <td>0.872942</td>\n",
       "      <td>37.687701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401117</th>\n",
       "      <td>6.70</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>14.421946</td>\n",
       "      <td>32450</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>20.913710</td>\n",
       "      <td>3.168207</td>\n",
       "      <td>93.647950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401118</th>\n",
       "      <td>6.70</td>\n",
       "      <td>4.514077</td>\n",
       "      <td>14.421946</td>\n",
       "      <td>32450</td>\n",
       "      <td>32708</td>\n",
       "      <td>32035</td>\n",
       "      <td>32728</td>\n",
       "      <td>28.442693</td>\n",
       "      <td>21.267071</td>\n",
       "      <td>2.204924</td>\n",
       "      <td>37.024913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401119 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fridge_temperature  latitude  longitude  FC1_Read_Input_Register  \\\n",
       "0                     9.00  4.514077  14.421946                    32450   \n",
       "1                     9.25  4.514077  14.421946                    32450   \n",
       "2                    12.65  4.514077  14.421946                    32450   \n",
       "3                     4.65  4.514077  14.421946                    32450   \n",
       "4                    12.65  4.514077  14.421946                    32450   \n",
       "...                    ...       ...        ...                      ...   \n",
       "401114                6.70  4.514077  14.421946                    32450   \n",
       "401115                6.70  4.514077  14.421946                    32450   \n",
       "401116                6.70  4.514077  14.421946                    32450   \n",
       "401117                6.70  4.514077  14.421946                    32450   \n",
       "401118                6.70  4.514077  14.421946                    32450   \n",
       "\n",
       "        FC2_Read_Discrete_Value  FC3_Read_Holding_Register  FC4_Read_Coil  \\\n",
       "0                         32708                      32035          32728   \n",
       "1                         32708                      32035          32728   \n",
       "2                         32708                      32035          32728   \n",
       "3                         32708                      32035          32728   \n",
       "4                         32708                      32035          32728   \n",
       "...                         ...                        ...            ...   \n",
       "401114                    32708                      32035          32728   \n",
       "401115                    32708                      32035          32728   \n",
       "401116                    32708                      32035          32728   \n",
       "401117                    32708                      32035          32728   \n",
       "401118                    32708                      32035          32728   \n",
       "\n",
       "        current_temperature  temperature  pressure   humidity  \n",
       "0                 28.442693    23.016184  1.035000  46.343618  \n",
       "1                 28.442693    38.620990  1.035000  46.343618  \n",
       "2                 28.442693    42.732741  1.035000  46.343618  \n",
       "3                 28.442693    37.785562  1.035000  46.343618  \n",
       "4                 28.442693    36.353584  1.035000  46.343618  \n",
       "...                     ...          ...       ...        ...  \n",
       "401114            28.442693    24.250404  2.204924  37.024913  \n",
       "401115            28.442693    20.155984 -2.030547  90.297894  \n",
       "401116            28.442693    24.577566  0.872942  37.687701  \n",
       "401117            28.442693    20.913710  3.168207  93.647950  \n",
       "401118            28.442693    21.267071  2.204924  37.024913  \n",
       "\n",
       "[401119 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_cols = X_T.get_support(indices=True)\n",
    "X_VT = X.iloc[:,sel_cols]\n",
    "X_VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfdc50e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.61538462 0.00821665 0.00811167 ... 0.10772138 0.53355618 0.46251056]\n",
      " [0.63461538 0.00821665 0.00811167 ... 0.66504042 0.53355618 0.46251056]\n",
      " [0.89615385 0.00821665 0.00811167 ... 0.81188986 0.53355618 0.46251056]\n",
      " ...\n",
      " [0.43846154 0.00821665 0.00811167 ... 0.16348547 0.52695586 0.3756012 ]\n",
      " [0.43846154 0.00821665 0.00811167 ... 0.03263243 0.62043775 0.93746771]\n",
      " [0.43846154 0.00821665 0.00811167 ... 0.04525255 0.58120503 0.3689465 ]]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_M = scaler.fit_transform(X_VT)\n",
    "print(X_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b8514fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X_M, y, test_size = 0.20, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60232147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401119, 11)\n",
      "(401119,)\n",
      "(320895, 11)\n",
      "(320895,)\n",
      "(80224, 11)\n",
      "(80224,)\n"
     ]
    }
   ],
   "source": [
    "print(X_M.shape)\n",
    "print(y.shape)\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e6ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Train split\n",
    "lr = LogisticRegression(multi_class='ovr') #for multiclass\n",
    "lr.fit(trainX, trainY)\n",
    "y_predict = lr.predict(testX)\n",
    "print(accuracy_score(testY, y_predict))\n",
    "print(classification_report(testY, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "140db1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results with Grid Search:\n",
      "0.6617834494149176\n",
      "{'C': 100, 'solver': 'newton-cg'}\n",
      "\n",
      "Accuracy Score  on test data: 0.6601391104906262\n",
      "[[   56    68     7  6835   122     9     1     0]\n",
      " [   21  1123    24   612  3061   191     0     0]\n",
      " [    0    91   115  6513   200    11     0     0]\n",
      " [   77   183    17 47464   963   189     3     0]\n",
      " [    0   257   166  2880  3717    21     0     0]\n",
      " [    0   727     0   399  1610   418     0     0]\n",
      " [    0   100     3    97    13   527    57     0]\n",
      " [    0   345     0   142   101   679     0     9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    backdoor       0.36      0.01      0.02      7098\n",
      "        ddos       0.39      0.22      0.28      5032\n",
      "   injection       0.35      0.02      0.03      6930\n",
      "      normal       0.73      0.97      0.83     48896\n",
      "    password       0.38      0.53      0.44      7041\n",
      "  ransomware       0.20      0.13      0.16      3154\n",
      "    scanning       0.93      0.07      0.13       797\n",
      "         xss       1.00      0.01      0.01      1276\n",
      "\n",
      "    accuracy                           0.66     80224\n",
      "   macro avg       0.54      0.24      0.24     80224\n",
      "weighted avg       0.60      0.66      0.58     80224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Grid Search CV\n",
    "model = LogisticRegression(multi_class='ovr') \n",
    "\n",
    "parameters = [{'solver': ['newton-cg', 'lbfgs', 'liblinear'], 'C': [100, 10, 1.0, 0.1, 0.01]}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3, n_jobs = -1)\n",
    "\n",
    "grid_search = grid_search.fit(trainX, trainY)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(testX)\n",
    "\n",
    "print('\\nAccuracy Score  on test data: ' + str(accuracy_score(testY, y_pred)))\n",
    "print(confusion_matrix(testY,y_pred))\n",
    "print(classification_report(testY,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c5ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Train split\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(trainX, trainY)\n",
    "y_predict = lda.predict(testX)\n",
    "print(accuracy_score(testY, y_predict))\n",
    "print(classification_report(testY, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c153793e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results with Grid Search:\n",
      "0.722850153476994\n",
      "{'solver': 'svd'}\n",
      "\n",
      "Accuracy Score  on test data: 0.7195726964499402\n",
      "[[  250    51    25  6574   104    76     5    13]\n",
      " [   42   982    10   561  1468  1730   203    36]\n",
      " [    0    92   638  5007  1096    74    10    13]\n",
      " [  126    83   125 46967   888   556    16   135]\n",
      " [    0   225   177   861  5655   102     5    16]\n",
      " [    0   201     3   366    61  2497    19     7]\n",
      " [    0     1     5    90     9    10   179   503]\n",
      " [    0     1     0   136    23   534    23   559]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    backdoor       0.60      0.04      0.07      7098\n",
      "        ddos       0.60      0.20      0.29      5032\n",
      "   injection       0.65      0.09      0.16      6930\n",
      "      normal       0.78      0.96      0.86     48896\n",
      "    password       0.61      0.80      0.69      7041\n",
      "  ransomware       0.45      0.79      0.57      3154\n",
      "    scanning       0.39      0.22      0.28       797\n",
      "         xss       0.44      0.44      0.44      1276\n",
      "\n",
      "    accuracy                           0.72     80224\n",
      "   macro avg       0.56      0.44      0.42     80224\n",
      "weighted avg       0.70      0.72      0.65     80224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Grid search CV\n",
    "model = LinearDiscriminantAnalysis() \n",
    "\n",
    "parameters = [{'solver': ['svd', 'lsqr', 'eigen']}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3, n_jobs = -1)\n",
    "\n",
    "grid_search = grid_search.fit(trainX, trainY)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(testX)\n",
    "\n",
    "print('\\nAccuracy Score  on test data: ' + str(accuracy_score(testY, y_pred)))\n",
    "print(confusion_matrix(testY,y_pred))\n",
    "print(classification_report(testY,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6758a05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8139833466294376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    backdoor       0.49      0.47      0.48      7098\n",
      "        ddos       0.74      0.78      0.76      5032\n",
      "   injection       0.73      0.73      0.73      6930\n",
      "      normal       0.89      0.91      0.90     48896\n",
      "    password       0.78      0.68      0.73      7041\n",
      "  ransomware       0.77      0.69      0.73      3154\n",
      "    scanning       0.80      0.79      0.80       797\n",
      "         xss       0.76      0.60      0.67      1276\n",
      "\n",
      "    accuracy                           0.81     80224\n",
      "   macro avg       0.74      0.71      0.72     80224\n",
      "weighted avg       0.81      0.81      0.81     80224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test Train split\n",
    "#default parameters used in base paper (n_neighbors, default=5) (p, default=2 for Euclidean Distance)\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(trainX, trainY)\n",
    "y_predict = knn.predict(testX)\n",
    "print(accuracy_score(testY, y_predict))\n",
    "print(classification_report(testY, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b452f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results with Grid Search:\n",
      "0.8318047959612956\n",
      "{'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "\n",
      "Accuracy Score  on test data: 0.8330923414439569\n",
      "[[ 2583    54   458  3851    98    39     3    12]\n",
      " [   63  3879    66   450   351   199    13    11]\n",
      " [  604    59  5030   703   482    36     7     9]\n",
      " [  652   319   482 46456   616   214    56   101]\n",
      " [   66   403   691   713  5097    54     5    12]\n",
      " [   20   357    42   306    47  2347     1    34]\n",
      " [    8     8     6    89     8     3   654    21]\n",
      " [    5    19    15   151    19   174   105   788]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    backdoor       0.65      0.36      0.47      7098\n",
      "        ddos       0.76      0.77      0.77      5032\n",
      "   injection       0.74      0.73      0.73      6930\n",
      "      normal       0.88      0.95      0.91     48896\n",
      "    password       0.76      0.72      0.74      7041\n",
      "  ransomware       0.77      0.74      0.75      3154\n",
      "    scanning       0.77      0.82      0.80       797\n",
      "         xss       0.80      0.62      0.70      1276\n",
      "\n",
      "    accuracy                           0.83     80224\n",
      "   macro avg       0.77      0.71      0.73     80224\n",
      "weighted avg       0.82      0.83      0.82     80224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Grid search CV\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "parameters = [{'n_neighbors': [5,7,9,11], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3, n_jobs = -1)\n",
    "\n",
    "grid_search = grid_search.fit(trainX, trainY)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(testX)\n",
    "\n",
    "print('\\nAccuracy Score  on test data: ' + str(accuracy_score(testY, y_pred)))\n",
    "print(confusion_matrix(testY,y_pred))\n",
    "print(classification_report(testY,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6325674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8091344236138811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    backdoor       0.53      0.47      0.50      7098\n",
      "        ddos       0.72      0.73      0.72      5032\n",
      "   injection       0.71      0.73      0.72      6930\n",
      "      normal       0.88      0.91      0.90     48896\n",
      "    password       0.74      0.70      0.72      7041\n",
      "  ransomware       0.72      0.69      0.71      3154\n",
      "    scanning       0.77      0.75      0.76       797\n",
      "         xss       0.71      0.63      0.67      1276\n",
      "\n",
      "    accuracy                           0.81     80224\n",
      "   macro avg       0.72      0.70      0.71     80224\n",
      "weighted avg       0.80      0.81      0.81     80224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test Train split\n",
    "rf = RandomForestClassifier(n_estimators=10,criterion='gini')\n",
    "rf.fit(trainX, trainY)\n",
    "y_predict1 = rf.predict(testX)\n",
    "print(accuracy_score(testY, y_predict1))\n",
    "print(classification_report(testY, y_predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "291523c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results with Grid Search:\n",
      "0.845494632200564\n",
      "{'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "\n",
      "Accuracy Score  on test data: 0.8470158556043079\n",
      "[[ 2953    54   587  3370    86    34     3    11]\n",
      " [   51  3945    69   452   377   118    12     8]\n",
      " [  495    61  5299   605   424    30     7     9]\n",
      " [  481   299   527 46708   548   193    47    93]\n",
      " [   49   343   662   710  5212    50     7     8]\n",
      " [   18   384    41   309    51  2310     1    40]\n",
      " [    7     9    11    79     7     2   669    13]\n",
      " [    9    20    14   131    18   153    76   855]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    backdoor       0.73      0.42      0.53      7098\n",
      "        ddos       0.77      0.78      0.78      5032\n",
      "   injection       0.73      0.76      0.75      6930\n",
      "      normal       0.89      0.96      0.92     48896\n",
      "    password       0.78      0.74      0.76      7041\n",
      "  ransomware       0.80      0.73      0.76      3154\n",
      "    scanning       0.81      0.84      0.83       797\n",
      "         xss       0.82      0.67      0.74      1276\n",
      "\n",
      "    accuracy                           0.85     80224\n",
      "   macro avg       0.79      0.74      0.76     80224\n",
      "weighted avg       0.84      0.85      0.84     80224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Grid Search CV\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "parameters = [{'n_estimators': [20, 50], 'min_samples_split':[2, 5],\n",
    "              'min_samples_leaf':[1, 2], 'criterion': ['gini','entropy']}]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3, n_jobs = -1)\n",
    "\n",
    "grid_search = grid_search.fit(trainX, trainY)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(testX)\n",
    "\n",
    "print('\\nAccuracy Score  on test data: ' + str(accuracy_score(testY, y_pred)))\n",
    "print(confusion_matrix(testY,y_pred))\n",
    "print(classification_report(testY,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5f198a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.783393996808935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    backdoor       0.48      0.49      0.49      7098\n",
      "        ddos       0.70      0.70      0.70      5032\n",
      "   injection       0.67      0.68      0.68      6930\n",
      "      normal       0.88      0.88      0.88     48896\n",
      "    password       0.69      0.68      0.68      7041\n",
      "  ransomware       0.67      0.66      0.66      3154\n",
      "    scanning       0.73      0.72      0.72       797\n",
      "         xss       0.62      0.61      0.62      1276\n",
      "\n",
      "    accuracy                           0.78     80224\n",
      "   macro avg       0.68      0.68      0.68     80224\n",
      "weighted avg       0.78      0.78      0.78     80224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test Train Split\n",
    "dt = DecisionTreeClassifier(criterion='gini')\n",
    "dt.fit(trainX, trainY)\n",
    "y_predict1 = dt.predict(testX)\n",
    "print(accuracy_score(testY, y_predict1))\n",
    "print(classification_report(testY, y_predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "117d8f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results with Grid Search:\n",
      "0.7948332008912572\n",
      "{'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "\n",
      "Accuracy Score  on test data: 0.7971056043079378\n",
      "[[ 3260    81   530  3092    86    33     3    13]\n",
      " [  107  3866    70   490   303   174    12    10]\n",
      " [  837    84  4855   674   430    32     6    12]\n",
      " [ 2718   494   834 43954   539   212    54    91]\n",
      " [  165   457   738  1054  4559    51     7    10]\n",
      " [   62   403    61   384    79  2100     1    64]\n",
      " [   20    14    11   103    10     2   612    25]\n",
      " [   29    32    21   191    28   146    88   741]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    backdoor       0.45      0.46      0.46      7098\n",
      "        ddos       0.71      0.77      0.74      5032\n",
      "   injection       0.68      0.70      0.69      6930\n",
      "      normal       0.88      0.90      0.89     48896\n",
      "    password       0.76      0.65      0.70      7041\n",
      "  ransomware       0.76      0.67      0.71      3154\n",
      "    scanning       0.78      0.77      0.77       797\n",
      "         xss       0.77      0.58      0.66      1276\n",
      "\n",
      "    accuracy                           0.80     80224\n",
      "   macro avg       0.72      0.69      0.70     80224\n",
      "weighted avg       0.80      0.80      0.80     80224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier() \n",
    "\n",
    "parameters = [{'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2], 'splitter': ['best','random'],\n",
    "              'criterion': ['gini', 'entropy']}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3, n_jobs = -1)\n",
    "\n",
    "grid_search = grid_search.fit(trainX, trainY)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(testX)\n",
    "\n",
    "print('\\nAccuracy Score  on test data: ' + str(accuracy_score(testY, y_pred)))\n",
    "print(confusion_matrix(testY,y_pred))\n",
    "print(classification_report(testY,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8518df",
   "metadata": {},
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(trainX, trainY)\n",
    "y_predict1 = nb.predict(testX)\n",
    "print(accuracy_score(testY, y_predict1))\n",
    "print(classification_report(testY, y_predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d859811c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7747058236936578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    backdoor       0.60      0.02      0.04      7098\n",
      "        ddos       0.74      0.65      0.69      5032\n",
      "   injection       0.76      0.51      0.61      6930\n",
      "      normal       0.81      0.96      0.88     48896\n",
      "    password       0.67      0.79      0.72      7041\n",
      "  ransomware       0.59      0.71      0.64      3154\n",
      "    scanning       0.91      0.21      0.34       797\n",
      "         xss       0.34      0.26      0.30      1276\n",
      "\n",
      "    accuracy                           0.77     80224\n",
      "   macro avg       0.68      0.51      0.53     80224\n",
      "weighted avg       0.76      0.77      0.73     80224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test Train Split\n",
    "svclassifier = SVC(kernel='rbf', gamma='auto')\n",
    "svclassifier.fit(trainX, trainY)\n",
    "y_predict = svclassifier.predict(testX)\n",
    "print(accuracy_score(testY, y_predict))\n",
    "print(classification_report(testY, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "226ff26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results with Grid Search:\n",
      "0.8057059162654451\n",
      "{'C': 1, 'gamma': 0.5}\n",
      "\n",
      "Accuracy Score  on test data: 0.8049960111687275\n",
      "[[  580    57   775  5537    90    40    11     8]\n",
      " [   38  3431    70   518   683   275    13     4]\n",
      " [   86    58  5218  1047   464    40     9     8]\n",
      " [  221   345   677 46513   705   264    83    88]\n",
      " [   11   138   860   745  5210    59    10     8]\n",
      " [    0   349    46   335    49  2365     2     8]\n",
      " [    6     8     6    84     8     3   656    26]\n",
      " [    0    16    18   133    19   327   156   607]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    backdoor       0.62      0.08      0.14      7098\n",
      "        ddos       0.78      0.68      0.73      5032\n",
      "   injection       0.68      0.75      0.71      6930\n",
      "      normal       0.85      0.95      0.90     48896\n",
      "    password       0.72      0.74      0.73      7041\n",
      "  ransomware       0.70      0.75      0.72      3154\n",
      "    scanning       0.70      0.82      0.76       797\n",
      "         xss       0.80      0.48      0.60      1276\n",
      "\n",
      "    accuracy                           0.80     80224\n",
      "   macro avg       0.73      0.66      0.66     80224\n",
      "weighted avg       0.79      0.80      0.78     80224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Grid Search CV\n",
    "model = SVC() \n",
    "\n",
    "parameters = [{'C': [0.1,1], 'gamma':[0.01,0.5]}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3, n_jobs = -1)\n",
    "\n",
    "grid_search = grid_search.fit(trainX, trainY)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(testX)\n",
    "\n",
    "print('\\nAccuracy Score  on test data: ' + str(accuracy_score(testY, y_pred)))\n",
    "print(confusion_matrix(testY,y_pred))\n",
    "print(classification_report(testY,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7587cf82",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08f1b6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM training (label encoder + shape)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(trainY)\n",
    "y_train_L = encoder.transform(trainY) #for sparse_categorical\n",
    "X_train_L = trainX.reshape((-1, 1, trainX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24fe2e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM testing (label encoder + shape)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(testY)\n",
    "y_test_L = encoder.transform(testY) #for sparse_categorical\n",
    "X_test_L = testX.reshape((-1, 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac40875c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320895, 1, 11)\n",
      "(320895,)\n",
      "(80224, 1, 11)\n",
      "(80224,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_L.shape)\n",
    "print(y_train_L.shape)\n",
    "print(X_test_L.shape)\n",
    "print(y_test_L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13d8a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cbcbc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X1 = X_M.reshape((-1, 1, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2311f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc3537cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3930a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder = LabelEncoder()\n",
    "#encoder.fit(y)\n",
    "#y_E = encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0114f4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb957d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(y_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a4ed6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(X_train_L, X_test_L, y_train_L, y_test_L) = train_test_split(X1, y_E, test_size = 0.20, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e29050c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f190806\\AppData\\Local\\Temp\\2\\ipykernel_7188\\1247680612.py:11: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=1, epochs = 35, batch_size = 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 13s 3ms/step - loss: 1.1428 - accuracy: 0.6399\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.9416 - accuracy: 0.7019\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.9164 - accuracy: 0.7159\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.9017 - accuracy: 0.7239\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8896 - accuracy: 0.7339\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8818 - accuracy: 0.7379\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8761 - accuracy: 0.7414\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8668 - accuracy: 0.7478\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8567 - accuracy: 0.7521\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8465 - accuracy: 0.7549\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8389 - accuracy: 0.7554\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8318 - accuracy: 0.7560\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8276 - accuracy: 0.7562\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8237 - accuracy: 0.7563\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8182 - accuracy: 0.7568\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8153 - accuracy: 0.7541\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8137 - accuracy: 0.7556\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8105 - accuracy: 0.7572\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8082 - accuracy: 0.7576\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8083 - accuracy: 0.7604\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8051 - accuracy: 0.7612\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8017 - accuracy: 0.7637\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8008 - accuracy: 0.7630\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8015 - accuracy: 0.7629\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8004 - accuracy: 0.7637\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7982 - accuracy: 0.7643\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7991 - accuracy: 0.7634\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7971 - accuracy: 0.7638\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7972 - accuracy: 0.7621\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7954 - accuracy: 0.7637\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7945 - accuracy: 0.7642\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7927 - accuracy: 0.7644\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7947 - accuracy: 0.7631\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7925 - accuracy: 0.7643\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7922 - accuracy: 0.7646\n",
      "3343/3343 [==============================] - 5s 1ms/step\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 13s 3ms/step - loss: 1.0970 - accuracy: 0.6455\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.9481 - accuracy: 0.6891\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.9244 - accuracy: 0.7004\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.9072 - accuracy: 0.7146\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8898 - accuracy: 0.7273\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8715 - accuracy: 0.7375\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8495 - accuracy: 0.7419\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8339 - accuracy: 0.7458\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8203 - accuracy: 0.7502\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8108 - accuracy: 0.7543\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.8035 - accuracy: 0.7581\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7982 - accuracy: 0.7599\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7917 - accuracy: 0.7618\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7874 - accuracy: 0.7622\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7842 - accuracy: 0.7638\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7792 - accuracy: 0.7647\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7767 - accuracy: 0.7651\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7731 - accuracy: 0.7650\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7703 - accuracy: 0.7656\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7654 - accuracy: 0.7662\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7624 - accuracy: 0.7672\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7620 - accuracy: 0.7664\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7596 - accuracy: 0.7667\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7584 - accuracy: 0.7659\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7559 - accuracy: 0.7660\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7556 - accuracy: 0.7665\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7553 - accuracy: 0.7662\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7550 - accuracy: 0.7659\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7523 - accuracy: 0.7660\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7528 - accuracy: 0.7665\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7527 - accuracy: 0.7668\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7516 - accuracy: 0.7663\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7507 - accuracy: 0.7665\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7509 - accuracy: 0.7661\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7502 - accuracy: 0.7662\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 1.1525 - accuracy: 0.6423\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.9747 - accuracy: 0.6773\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.9452 - accuracy: 0.6861\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.9296 - accuracy: 0.7156\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.9123 - accuracy: 0.7198\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8918 - accuracy: 0.7184\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8780 - accuracy: 0.7208\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8637 - accuracy: 0.7240\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8532 - accuracy: 0.7252\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8446 - accuracy: 0.7322\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8385 - accuracy: 0.7356\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8323 - accuracy: 0.7391\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8280 - accuracy: 0.7409\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8245 - accuracy: 0.7422\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8226 - accuracy: 0.7416\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8184 - accuracy: 0.7415\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8158 - accuracy: 0.7399\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8133 - accuracy: 0.7404\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8134 - accuracy: 0.7400\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8121 - accuracy: 0.7402\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8092 - accuracy: 0.7407\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8094 - accuracy: 0.7410\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8089 - accuracy: 0.7413\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8073 - accuracy: 0.7425\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8071 - accuracy: 0.7429\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8061 - accuracy: 0.7437\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8076 - accuracy: 0.7422\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8054 - accuracy: 0.7437\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8069 - accuracy: 0.7433\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8043 - accuracy: 0.7444\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8012 - accuracy: 0.7453\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8025 - accuracy: 0.7452\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8022 - accuracy: 0.7455\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8013 - accuracy: 0.7461\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8023 - accuracy: 0.7462\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 1.0720 - accuracy: 0.6598\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.9120 - accuracy: 0.7134\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8756 - accuracy: 0.7340\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8531 - accuracy: 0.7457\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8374 - accuracy: 0.7523\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8210 - accuracy: 0.7563\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8066 - accuracy: 0.7615\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7921 - accuracy: 0.7654\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7787 - accuracy: 0.7684\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7685 - accuracy: 0.7714\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7589 - accuracy: 0.7738\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7533 - accuracy: 0.7762\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7460 - accuracy: 0.7773\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7406 - accuracy: 0.7784\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7361 - accuracy: 0.7797\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7327 - accuracy: 0.7804\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7295 - accuracy: 0.7818\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7260 - accuracy: 0.7828\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7240 - accuracy: 0.7827\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7217 - accuracy: 0.7826\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7201 - accuracy: 0.7828\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7173 - accuracy: 0.7838\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7157 - accuracy: 0.7838\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7145 - accuracy: 0.7842\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7141 - accuracy: 0.7846\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7119 - accuracy: 0.7849\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7101 - accuracy: 0.7857\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7089 - accuracy: 0.7849\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7073 - accuracy: 0.7861\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7067 - accuracy: 0.7858\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7058 - accuracy: 0.7856\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7051 - accuracy: 0.7856\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7026 - accuracy: 0.7868\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7018 - accuracy: 0.7870\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7012 - accuracy: 0.7866\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 1.0560 - accuracy: 0.6549\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8892 - accuracy: 0.7262\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8546 - accuracy: 0.7477\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8298 - accuracy: 0.7564\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8146 - accuracy: 0.7617\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8013 - accuracy: 0.7671\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7894 - accuracy: 0.7687\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7752 - accuracy: 0.7731\n",
      "Epoch 9/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7664 - accuracy: 0.7753\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7554 - accuracy: 0.7762\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7474 - accuracy: 0.7791\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7409 - accuracy: 0.7804\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7353 - accuracy: 0.7811\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7311 - accuracy: 0.7822\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7257 - accuracy: 0.7840\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7219 - accuracy: 0.7843\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7190 - accuracy: 0.7851\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7160 - accuracy: 0.7851\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7130 - accuracy: 0.7856\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7115 - accuracy: 0.7861\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7091 - accuracy: 0.7861\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7061 - accuracy: 0.7868\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7044 - accuracy: 0.7870\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7023 - accuracy: 0.7875\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7013 - accuracy: 0.7875\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6993 - accuracy: 0.7881\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6984 - accuracy: 0.7885\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6967 - accuracy: 0.7887\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6970 - accuracy: 0.7895\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6963 - accuracy: 0.7880\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6941 - accuracy: 0.7885\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6909 - accuracy: 0.7895\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6914 - accuracy: 0.7898\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6905 - accuracy: 0.7895\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6903 - accuracy: 0.7896\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 1.0610 - accuracy: 0.6601\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8923 - accuracy: 0.7171\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8508 - accuracy: 0.7423\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8260 - accuracy: 0.7534\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8124 - accuracy: 0.7576\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7998 - accuracy: 0.7616\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7881 - accuracy: 0.7649\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7794 - accuracy: 0.7669\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7724 - accuracy: 0.7687\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7663 - accuracy: 0.7699\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7586 - accuracy: 0.7715\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7534 - accuracy: 0.7734\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7475 - accuracy: 0.7753\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7432 - accuracy: 0.7775\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7375 - accuracy: 0.7789\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7331 - accuracy: 0.7799\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7284 - accuracy: 0.7811\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7259 - accuracy: 0.7815\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7249 - accuracy: 0.7820\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7207 - accuracy: 0.7831\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7174 - accuracy: 0.7830\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7156 - accuracy: 0.7829\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7134 - accuracy: 0.7843\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7098 - accuracy: 0.7849\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7096 - accuracy: 0.7842\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7077 - accuracy: 0.7859\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7064 - accuracy: 0.7856\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7048 - accuracy: 0.7856\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7026 - accuracy: 0.7868\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7031 - accuracy: 0.7863\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7010 - accuracy: 0.7874\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7016 - accuracy: 0.7871\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7006 - accuracy: 0.7868\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6978 - accuracy: 0.7880\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6974 - accuracy: 0.7889\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 1.0200 - accuracy: 0.6738\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8568 - accuracy: 0.7425\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8154 - accuracy: 0.7605\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7980 - accuracy: 0.7670\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7870 - accuracy: 0.7720\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7735 - accuracy: 0.7741\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7597 - accuracy: 0.7788\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7460 - accuracy: 0.7822\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7347 - accuracy: 0.7856\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7258 - accuracy: 0.7875\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7186 - accuracy: 0.7894\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7126 - accuracy: 0.7907\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7062 - accuracy: 0.7911\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7018 - accuracy: 0.7926\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6969 - accuracy: 0.7934\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6941 - accuracy: 0.7941\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6911 - accuracy: 0.7943\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6873 - accuracy: 0.7948\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6851 - accuracy: 0.7950\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6829 - accuracy: 0.7960\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6799 - accuracy: 0.7965\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6773 - accuracy: 0.7975\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6775 - accuracy: 0.7973\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6756 - accuracy: 0.7973\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6734 - accuracy: 0.7976\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6727 - accuracy: 0.7979\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6704 - accuracy: 0.7986\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6700 - accuracy: 0.7980\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6689 - accuracy: 0.7990\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6672 - accuracy: 0.7989\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6661 - accuracy: 0.7988\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6655 - accuracy: 0.7992\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6653 - accuracy: 0.7997\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6637 - accuracy: 0.7999\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6641 - accuracy: 0.7999\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 1.0249 - accuracy: 0.6757\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8682 - accuracy: 0.7353\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8326 - accuracy: 0.7516\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8115 - accuracy: 0.7615\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7971 - accuracy: 0.7677\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7833 - accuracy: 0.7731\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7682 - accuracy: 0.7765\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7550 - accuracy: 0.7795\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7434 - accuracy: 0.7821\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7348 - accuracy: 0.7836\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7282 - accuracy: 0.7853\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7214 - accuracy: 0.7869\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7156 - accuracy: 0.7884\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7101 - accuracy: 0.7884\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7065 - accuracy: 0.7895\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7018 - accuracy: 0.7902\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6990 - accuracy: 0.7909\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6956 - accuracy: 0.7910\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6925 - accuracy: 0.7918\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6904 - accuracy: 0.7918\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6864 - accuracy: 0.7926\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6850 - accuracy: 0.7929\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6836 - accuracy: 0.7934\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6807 - accuracy: 0.7939\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6792 - accuracy: 0.7937\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6764 - accuracy: 0.7948\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6751 - accuracy: 0.7952\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6746 - accuracy: 0.7946\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6726 - accuracy: 0.7962\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6726 - accuracy: 0.7950\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6711 - accuracy: 0.7961\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6688 - accuracy: 0.7969\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6689 - accuracy: 0.7967\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6681 - accuracy: 0.7975\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6671 - accuracy: 0.7982\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 1.0515 - accuracy: 0.6657\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8970 - accuracy: 0.7198\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8516 - accuracy: 0.7407\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8286 - accuracy: 0.7515\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8091 - accuracy: 0.7590\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7943 - accuracy: 0.7633\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7832 - accuracy: 0.7671\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7725 - accuracy: 0.7685\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7631 - accuracy: 0.7701\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7543 - accuracy: 0.7729\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7457 - accuracy: 0.7750\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7416 - accuracy: 0.7767\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7350 - accuracy: 0.7798\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7294 - accuracy: 0.7805\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7219 - accuracy: 0.7832\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7178 - accuracy: 0.7848\n",
      "Epoch 17/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7135 - accuracy: 0.7856\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7106 - accuracy: 0.7872\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7062 - accuracy: 0.7888\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7038 - accuracy: 0.7888\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7009 - accuracy: 0.7903\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6968 - accuracy: 0.7916\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6945 - accuracy: 0.7920\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6932 - accuracy: 0.7930\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6909 - accuracy: 0.7921\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6883 - accuracy: 0.7932\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6870 - accuracy: 0.7940\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6852 - accuracy: 0.7947\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6842 - accuracy: 0.7950\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6826 - accuracy: 0.7949\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6805 - accuracy: 0.7950\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6795 - accuracy: 0.7945\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6782 - accuracy: 0.7958\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6769 - accuracy: 0.7957\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6763 - accuracy: 0.7967\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 1.0141 - accuracy: 0.6779\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8530 - accuracy: 0.7452\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8138 - accuracy: 0.7620\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7897 - accuracy: 0.7713\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7679 - accuracy: 0.7774\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7515 - accuracy: 0.7808\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7369 - accuracy: 0.7841\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7257 - accuracy: 0.7867\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7166 - accuracy: 0.7890\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7081 - accuracy: 0.7900\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7012 - accuracy: 0.7917\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6953 - accuracy: 0.7919\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6902 - accuracy: 0.7937\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6858 - accuracy: 0.7949\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6821 - accuracy: 0.7951\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6785 - accuracy: 0.7956\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6759 - accuracy: 0.7961\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6732 - accuracy: 0.7978\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6710 - accuracy: 0.7970\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6677 - accuracy: 0.7975\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6663 - accuracy: 0.7986\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6646 - accuracy: 0.7988\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6638 - accuracy: 0.7993\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6617 - accuracy: 0.7996\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6601 - accuracy: 0.7999\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6565 - accuracy: 0.8004\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6567 - accuracy: 0.8012\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6556 - accuracy: 0.8013\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6552 - accuracy: 0.8012\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6536 - accuracy: 0.8009\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6530 - accuracy: 0.8015\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6515 - accuracy: 0.8022\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6506 - accuracy: 0.8028\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6503 - accuracy: 0.8022\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6494 - accuracy: 0.8036\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 1.0172 - accuracy: 0.6761\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8658 - accuracy: 0.7310\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8148 - accuracy: 0.7558\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7905 - accuracy: 0.7662\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7743 - accuracy: 0.7736\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7624 - accuracy: 0.7771\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7506 - accuracy: 0.7805\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7394 - accuracy: 0.7832\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7317 - accuracy: 0.7859\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7231 - accuracy: 0.7879\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7154 - accuracy: 0.7898\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7081 - accuracy: 0.7913\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7019 - accuracy: 0.7931\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6955 - accuracy: 0.7942\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6914 - accuracy: 0.7952\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6860 - accuracy: 0.7963\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6838 - accuracy: 0.7980\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6779 - accuracy: 0.7993\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6755 - accuracy: 0.7994\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6723 - accuracy: 0.8000\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6699 - accuracy: 0.8003\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6681 - accuracy: 0.8008\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6661 - accuracy: 0.8003\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6635 - accuracy: 0.8016\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6627 - accuracy: 0.8016\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6600 - accuracy: 0.8023\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6594 - accuracy: 0.8022\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6575 - accuracy: 0.8025\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6563 - accuracy: 0.8032\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6546 - accuracy: 0.8041\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6543 - accuracy: 0.8036\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6534 - accuracy: 0.8036\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6520 - accuracy: 0.8043\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6510 - accuracy: 0.8048\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6505 - accuracy: 0.8051\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 1.0130 - accuracy: 0.6788\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8531 - accuracy: 0.7407\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8143 - accuracy: 0.7591\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7944 - accuracy: 0.7683\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7811 - accuracy: 0.7733\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7686 - accuracy: 0.7772\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7553 - accuracy: 0.7797\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7426 - accuracy: 0.7830\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7289 - accuracy: 0.7861\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7216 - accuracy: 0.7884\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7104 - accuracy: 0.7911\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7037 - accuracy: 0.7930\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6969 - accuracy: 0.7946\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6917 - accuracy: 0.7964\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6865 - accuracy: 0.7972\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6818 - accuracy: 0.7987\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6780 - accuracy: 0.7989\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6747 - accuracy: 0.8003\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6708 - accuracy: 0.8009\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6680 - accuracy: 0.8010\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6650 - accuracy: 0.8012\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6620 - accuracy: 0.8022\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6596 - accuracy: 0.8025\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6579 - accuracy: 0.8029\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6552 - accuracy: 0.8043\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6536 - accuracy: 0.8041\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6513 - accuracy: 0.8049\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6501 - accuracy: 0.8049\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6491 - accuracy: 0.8051\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6470 - accuracy: 0.8059\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6459 - accuracy: 0.8063\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6442 - accuracy: 0.8068\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6441 - accuracy: 0.8068\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6424 - accuracy: 0.8073\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6417 - accuracy: 0.8077\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9920 - accuracy: 0.6835\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8396 - accuracy: 0.7525\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8007 - accuracy: 0.7679\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7828 - accuracy: 0.7763\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7656 - accuracy: 0.7823\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7482 - accuracy: 0.7850\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7336 - accuracy: 0.7886\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7207 - accuracy: 0.7914\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7108 - accuracy: 0.7928\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7040 - accuracy: 0.7951\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6968 - accuracy: 0.7956\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6905 - accuracy: 0.7977\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6854 - accuracy: 0.7990\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6810 - accuracy: 0.7994\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6763 - accuracy: 0.8006\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6733 - accuracy: 0.8004\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6692 - accuracy: 0.8015\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6664 - accuracy: 0.8023\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6636 - accuracy: 0.8029\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6605 - accuracy: 0.8032\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6585 - accuracy: 0.8040\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6563 - accuracy: 0.8042\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6550 - accuracy: 0.8046\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6529 - accuracy: 0.8056\n",
      "Epoch 25/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6509 - accuracy: 0.8058\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6497 - accuracy: 0.8058\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6476 - accuracy: 0.8065\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6474 - accuracy: 0.8064\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6450 - accuracy: 0.8077\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6443 - accuracy: 0.8071\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6423 - accuracy: 0.8081\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6418 - accuracy: 0.8074\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6407 - accuracy: 0.8079\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6401 - accuracy: 0.8078\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6388 - accuracy: 0.8084\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9804 - accuracy: 0.6939\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8310 - accuracy: 0.7498\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7951 - accuracy: 0.7648\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7793 - accuracy: 0.7720\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7659 - accuracy: 0.7776\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7524 - accuracy: 0.7822\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7392 - accuracy: 0.7855\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7296 - accuracy: 0.7882\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7194 - accuracy: 0.7911\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7104 - accuracy: 0.7921\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7040 - accuracy: 0.7942\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6963 - accuracy: 0.7961\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6908 - accuracy: 0.7973\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6851 - accuracy: 0.7991\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6808 - accuracy: 0.8001\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6752 - accuracy: 0.8012\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6710 - accuracy: 0.8021\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6668 - accuracy: 0.8033\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6628 - accuracy: 0.8033\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6599 - accuracy: 0.8043\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6566 - accuracy: 0.8048\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6540 - accuracy: 0.8051\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6498 - accuracy: 0.8059\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6479 - accuracy: 0.8066\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6464 - accuracy: 0.8071\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6438 - accuracy: 0.8070\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6417 - accuracy: 0.8072\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6403 - accuracy: 0.8074\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6387 - accuracy: 0.8077\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6369 - accuracy: 0.8074\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6354 - accuracy: 0.8093\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6344 - accuracy: 0.8091\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6323 - accuracy: 0.8087\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6310 - accuracy: 0.8097\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6302 - accuracy: 0.8101\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9891 - accuracy: 0.6838\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8358 - accuracy: 0.7472\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7968 - accuracy: 0.7630\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7783 - accuracy: 0.7701\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7666 - accuracy: 0.7760\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7541 - accuracy: 0.7797\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7427 - accuracy: 0.7828\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7331 - accuracy: 0.7851\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7222 - accuracy: 0.7886\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7135 - accuracy: 0.7909\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7054 - accuracy: 0.7928\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6994 - accuracy: 0.7942\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6921 - accuracy: 0.7969\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6869 - accuracy: 0.7977\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6821 - accuracy: 0.7984\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6759 - accuracy: 0.8012\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6713 - accuracy: 0.8007\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6674 - accuracy: 0.8029\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6637 - accuracy: 0.8030\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6603 - accuracy: 0.8035\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6576 - accuracy: 0.8042\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6544 - accuracy: 0.8046\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6518 - accuracy: 0.8058\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6483 - accuracy: 0.8066\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6461 - accuracy: 0.8072\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6440 - accuracy: 0.8077\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6425 - accuracy: 0.8081\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6417 - accuracy: 0.8078\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6392 - accuracy: 0.8085\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6369 - accuracy: 0.8096\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6367 - accuracy: 0.8092\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6358 - accuracy: 0.8097\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6331 - accuracy: 0.8101\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6334 - accuracy: 0.8104\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6317 - accuracy: 0.8106\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9867 - accuracy: 0.6896\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8377 - accuracy: 0.7499\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7954 - accuracy: 0.7663\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7743 - accuracy: 0.7742\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7606 - accuracy: 0.7792\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7458 - accuracy: 0.7823\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7335 - accuracy: 0.7859\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7204 - accuracy: 0.7899\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7105 - accuracy: 0.7924\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7008 - accuracy: 0.7950\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6933 - accuracy: 0.7973\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6855 - accuracy: 0.7991\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6798 - accuracy: 0.8006\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6739 - accuracy: 0.8013\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6691 - accuracy: 0.8025\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6643 - accuracy: 0.8035\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6616 - accuracy: 0.8039\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6574 - accuracy: 0.8046\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6542 - accuracy: 0.8057\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6502 - accuracy: 0.8059\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6489 - accuracy: 0.8059\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6472 - accuracy: 0.8057\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6442 - accuracy: 0.8067\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6427 - accuracy: 0.8076\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6402 - accuracy: 0.8076\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6393 - accuracy: 0.8087\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6379 - accuracy: 0.8086\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6371 - accuracy: 0.8080\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6350 - accuracy: 0.8091\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6337 - accuracy: 0.8096\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6322 - accuracy: 0.8097\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6317 - accuracy: 0.8100\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6317 - accuracy: 0.8098\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6290 - accuracy: 0.8109\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6291 - accuracy: 0.8118\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9946 - accuracy: 0.6861\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8300 - accuracy: 0.7491\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7899 - accuracy: 0.7645\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7690 - accuracy: 0.7741\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7586 - accuracy: 0.7779\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7488 - accuracy: 0.7809\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7374 - accuracy: 0.7838\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7260 - accuracy: 0.7871\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7144 - accuracy: 0.7897\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7059 - accuracy: 0.7922\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6981 - accuracy: 0.7940\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6889 - accuracy: 0.7968\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6831 - accuracy: 0.7980\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6773 - accuracy: 0.7988\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6706 - accuracy: 0.8008\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6648 - accuracy: 0.8024\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6603 - accuracy: 0.8030\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6584 - accuracy: 0.8037\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6534 - accuracy: 0.8045\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6508 - accuracy: 0.8055\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6497 - accuracy: 0.8055\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6459 - accuracy: 0.8066\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6430 - accuracy: 0.8076\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6417 - accuracy: 0.8080\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6398 - accuracy: 0.8083\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6383 - accuracy: 0.8084\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6372 - accuracy: 0.8088\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6358 - accuracy: 0.8091\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6336 - accuracy: 0.8096\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6330 - accuracy: 0.8100\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6312 - accuracy: 0.8099\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6306 - accuracy: 0.8105\n",
      "Epoch 33/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6298 - accuracy: 0.8107\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6283 - accuracy: 0.8105\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6277 - accuracy: 0.8113\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9805 - accuracy: 0.6906\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8282 - accuracy: 0.7523\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7910 - accuracy: 0.7671\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7721 - accuracy: 0.7763\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7574 - accuracy: 0.7808\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7424 - accuracy: 0.7857\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7285 - accuracy: 0.7885\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7148 - accuracy: 0.7917\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7042 - accuracy: 0.7946\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6963 - accuracy: 0.7968\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6860 - accuracy: 0.7986\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6809 - accuracy: 0.7998\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6746 - accuracy: 0.8008\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6688 - accuracy: 0.8022\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6649 - accuracy: 0.8026\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6612 - accuracy: 0.8035\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6575 - accuracy: 0.8040\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6531 - accuracy: 0.8047\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6505 - accuracy: 0.8059\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6481 - accuracy: 0.8061\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6465 - accuracy: 0.8063\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6449 - accuracy: 0.8065\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6425 - accuracy: 0.8067\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6415 - accuracy: 0.8074\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6391 - accuracy: 0.8078\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6383 - accuracy: 0.8076\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6364 - accuracy: 0.8089\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6359 - accuracy: 0.8084\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6347 - accuracy: 0.8087\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6331 - accuracy: 0.8097\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6321 - accuracy: 0.8094\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6308 - accuracy: 0.8106\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6302 - accuracy: 0.8103\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6291 - accuracy: 0.8099\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6281 - accuracy: 0.8104\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9871 - accuracy: 0.6857\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8225 - accuracy: 0.7602\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7768 - accuracy: 0.7769\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7547 - accuracy: 0.7843\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7386 - accuracy: 0.7881\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7238 - accuracy: 0.7914\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7111 - accuracy: 0.7928\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7006 - accuracy: 0.7953\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6926 - accuracy: 0.7979\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6836 - accuracy: 0.7991\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6770 - accuracy: 0.8003\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6715 - accuracy: 0.8016\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6666 - accuracy: 0.8030\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6608 - accuracy: 0.8037\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6568 - accuracy: 0.8049\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6543 - accuracy: 0.8054\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6492 - accuracy: 0.8059\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6479 - accuracy: 0.8066\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6444 - accuracy: 0.8065\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6423 - accuracy: 0.8074\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6394 - accuracy: 0.8078\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6375 - accuracy: 0.8081\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6367 - accuracy: 0.8083\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6354 - accuracy: 0.8087\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6337 - accuracy: 0.8088\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6324 - accuracy: 0.8091\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6312 - accuracy: 0.8096\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6303 - accuracy: 0.8094\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6291 - accuracy: 0.8100\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6279 - accuracy: 0.8106\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6276 - accuracy: 0.8105\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6259 - accuracy: 0.8104\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6252 - accuracy: 0.8108\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6247 - accuracy: 0.8112\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6229 - accuracy: 0.8116\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9919 - accuracy: 0.6842\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8431 - accuracy: 0.7473\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7978 - accuracy: 0.7670\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7752 - accuracy: 0.7768\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7577 - accuracy: 0.7829\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7419 - accuracy: 0.7876\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7272 - accuracy: 0.7906\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7163 - accuracy: 0.7932\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7043 - accuracy: 0.7954\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6963 - accuracy: 0.7979\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6882 - accuracy: 0.7988\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6802 - accuracy: 0.8010\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6728 - accuracy: 0.8026\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6686 - accuracy: 0.8025\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6633 - accuracy: 0.8035\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6589 - accuracy: 0.8049\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6554 - accuracy: 0.8048\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6512 - accuracy: 0.8067\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6488 - accuracy: 0.8070\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6452 - accuracy: 0.8073\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6431 - accuracy: 0.8079\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6404 - accuracy: 0.8082\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.6389 - accuracy: 0.8085\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6361 - accuracy: 0.8090\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6352 - accuracy: 0.8099\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6341 - accuracy: 0.8103\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6319 - accuracy: 0.8095\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6302 - accuracy: 0.8103\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.6281 - accuracy: 0.8111\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.6265 - accuracy: 0.8109\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.6251 - accuracy: 0.8114\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.6243 - accuracy: 0.8116\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.6228 - accuracy: 0.8118\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6218 - accuracy: 0.8124\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6205 - accuracy: 0.8127\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9727 - accuracy: 0.6948\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8077 - accuracy: 0.7627\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7649 - accuracy: 0.7810\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7434 - accuracy: 0.7871\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7250 - accuracy: 0.7906\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7115 - accuracy: 0.7929\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6999 - accuracy: 0.7953\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6928 - accuracy: 0.7972\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6841 - accuracy: 0.7991\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6776 - accuracy: 0.7997\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6698 - accuracy: 0.8022\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6660 - accuracy: 0.8026\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6598 - accuracy: 0.8038\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6559 - accuracy: 0.8045\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6533 - accuracy: 0.8051\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6502 - accuracy: 0.8059\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6471 - accuracy: 0.8066\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6446 - accuracy: 0.8069\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6423 - accuracy: 0.8077\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6393 - accuracy: 0.8075\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6377 - accuracy: 0.8086\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6358 - accuracy: 0.8084\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6343 - accuracy: 0.8090\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6326 - accuracy: 0.8094\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6311 - accuracy: 0.8095\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6302 - accuracy: 0.8097\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6283 - accuracy: 0.8103\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6272 - accuracy: 0.8107\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6259 - accuracy: 0.8114\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6253 - accuracy: 0.8105\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6244 - accuracy: 0.8116\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6233 - accuracy: 0.8118\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6218 - accuracy: 0.8115\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6212 - accuracy: 0.8126\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6204 - accuracy: 0.8130\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9653 - accuracy: 0.6985\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8096 - accuracy: 0.7617\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7778 - accuracy: 0.7756\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7606 - accuracy: 0.7814\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7461 - accuracy: 0.7853\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7300 - accuracy: 0.7886\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7155 - accuracy: 0.7927\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7039 - accuracy: 0.7951\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6937 - accuracy: 0.7977\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6863 - accuracy: 0.7990\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6794 - accuracy: 0.8012\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6728 - accuracy: 0.8027\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6668 - accuracy: 0.8036\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6616 - accuracy: 0.8042\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6580 - accuracy: 0.8050\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6549 - accuracy: 0.8055\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6515 - accuracy: 0.8063\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6482 - accuracy: 0.8070\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6446 - accuracy: 0.8068\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6429 - accuracy: 0.8077\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6399 - accuracy: 0.8081\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6383 - accuracy: 0.8080\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6367 - accuracy: 0.8084\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6344 - accuracy: 0.8089\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6328 - accuracy: 0.8096\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6320 - accuracy: 0.8100\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6294 - accuracy: 0.8104\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6284 - accuracy: 0.8105\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6277 - accuracy: 0.8106\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6260 - accuracy: 0.8107\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6244 - accuracy: 0.8112\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6232 - accuracy: 0.8121\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6223 - accuracy: 0.8123\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6213 - accuracy: 0.8131\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6199 - accuracy: 0.8129\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9708 - accuracy: 0.6957\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8113 - accuracy: 0.7603\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7772 - accuracy: 0.7736\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7589 - accuracy: 0.7811\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7436 - accuracy: 0.7848\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7298 - accuracy: 0.7885\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7152 - accuracy: 0.7912\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7034 - accuracy: 0.7945\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6919 - accuracy: 0.7965\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6843 - accuracy: 0.7984\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6760 - accuracy: 0.8007\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6716 - accuracy: 0.8017\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6647 - accuracy: 0.8036\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6592 - accuracy: 0.8048\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6557 - accuracy: 0.8056\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6511 - accuracy: 0.8058\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6479 - accuracy: 0.8075\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6434 - accuracy: 0.8082\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6413 - accuracy: 0.8078\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6393 - accuracy: 0.8087\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6355 - accuracy: 0.8094\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6348 - accuracy: 0.8103\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6329 - accuracy: 0.8102\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6308 - accuracy: 0.8110\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6296 - accuracy: 0.8110\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6283 - accuracy: 0.8115\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6269 - accuracy: 0.8115\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6250 - accuracy: 0.8123\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6252 - accuracy: 0.8124\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6220 - accuracy: 0.8135\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6214 - accuracy: 0.8133\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6213 - accuracy: 0.8135\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6207 - accuracy: 0.8135\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6187 - accuracy: 0.8142\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6179 - accuracy: 0.8142\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9973 - accuracy: 0.6801\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8588 - accuracy: 0.7423\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.7979 - accuracy: 0.7686\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7674 - accuracy: 0.7791\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7491 - accuracy: 0.7853\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7317 - accuracy: 0.7889\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7171 - accuracy: 0.7914\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7061 - accuracy: 0.7943\n",
      "Epoch 9/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6957 - accuracy: 0.7952\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6865 - accuracy: 0.7982\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6766 - accuracy: 0.7999\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6692 - accuracy: 0.8017\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6630 - accuracy: 0.8025\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6562 - accuracy: 0.8043\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6528 - accuracy: 0.8054\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6470 - accuracy: 0.8067\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6439 - accuracy: 0.8073\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6401 - accuracy: 0.8069\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6367 - accuracy: 0.8082\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6361 - accuracy: 0.8088\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6331 - accuracy: 0.8097\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6310 - accuracy: 0.8104\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.6286 - accuracy: 0.8105\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6266 - accuracy: 0.8113\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6252 - accuracy: 0.8116\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6236 - accuracy: 0.8118\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6227 - accuracy: 0.8124\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6208 - accuracy: 0.8124\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6201 - accuracy: 0.8137\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6197 - accuracy: 0.8131\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6187 - accuracy: 0.8135\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6176 - accuracy: 0.8139\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6163 - accuracy: 0.8135\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6163 - accuracy: 0.8140\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6154 - accuracy: 0.8144\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9580 - accuracy: 0.7026\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8034 - accuracy: 0.7642\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7665 - accuracy: 0.7789\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7451 - accuracy: 0.7858\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7302 - accuracy: 0.7892\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7150 - accuracy: 0.7918\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7026 - accuracy: 0.7939\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6910 - accuracy: 0.7971\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6825 - accuracy: 0.7992\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6752 - accuracy: 0.8001\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6670 - accuracy: 0.8025\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6610 - accuracy: 0.8033\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6551 - accuracy: 0.8051\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6505 - accuracy: 0.8055\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6466 - accuracy: 0.8067\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6428 - accuracy: 0.8077\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6382 - accuracy: 0.8087\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6353 - accuracy: 0.8093\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6328 - accuracy: 0.8097\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6298 - accuracy: 0.8110\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6277 - accuracy: 0.8110\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6266 - accuracy: 0.8120\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6241 - accuracy: 0.8127\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6233 - accuracy: 0.8131\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6207 - accuracy: 0.8136\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6201 - accuracy: 0.8134\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6184 - accuracy: 0.8140\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6172 - accuracy: 0.8138\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6157 - accuracy: 0.8141\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6157 - accuracy: 0.8144\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6150 - accuracy: 0.8146\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6137 - accuracy: 0.8149\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6138 - accuracy: 0.8149\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6114 - accuracy: 0.8155\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6110 - accuracy: 0.8162\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9382 - accuracy: 0.7091\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7878 - accuracy: 0.7677\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7576 - accuracy: 0.7795\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7408 - accuracy: 0.7845\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7271 - accuracy: 0.7871\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7141 - accuracy: 0.7898\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7036 - accuracy: 0.7921\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6937 - accuracy: 0.7944\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6855 - accuracy: 0.7970\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6775 - accuracy: 0.7997\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6721 - accuracy: 0.8004\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6639 - accuracy: 0.8021\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6602 - accuracy: 0.8038\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6543 - accuracy: 0.8040\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6499 - accuracy: 0.8054\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6458 - accuracy: 0.8069\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6423 - accuracy: 0.8069\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6396 - accuracy: 0.8075\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6369 - accuracy: 0.8085\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6341 - accuracy: 0.8088\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6307 - accuracy: 0.8096\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6290 - accuracy: 0.8103\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6263 - accuracy: 0.8116\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6254 - accuracy: 0.8114\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6246 - accuracy: 0.8115\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6227 - accuracy: 0.8123\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6201 - accuracy: 0.8123\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6199 - accuracy: 0.8134\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6190 - accuracy: 0.8137\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6174 - accuracy: 0.8139\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6160 - accuracy: 0.8141\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6153 - accuracy: 0.8140\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6139 - accuracy: 0.8145\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6132 - accuracy: 0.8151\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6114 - accuracy: 0.8151\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9691 - accuracy: 0.6955\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8070 - accuracy: 0.7614\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7662 - accuracy: 0.7767\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7490 - accuracy: 0.7834\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7352 - accuracy: 0.7875\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7223 - accuracy: 0.7901\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7105 - accuracy: 0.7921\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7000 - accuracy: 0.7948\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6903 - accuracy: 0.7974\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6817 - accuracy: 0.7996\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6749 - accuracy: 0.8011\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6682 - accuracy: 0.8029\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6607 - accuracy: 0.8047\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6563 - accuracy: 0.8058\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6518 - accuracy: 0.8068\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6474 - accuracy: 0.8081\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6424 - accuracy: 0.8083\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6390 - accuracy: 0.8094\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6376 - accuracy: 0.8098\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6342 - accuracy: 0.8105\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6319 - accuracy: 0.8105\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6290 - accuracy: 0.8112\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6262 - accuracy: 0.8110\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6243 - accuracy: 0.8115\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6229 - accuracy: 0.8122\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6208 - accuracy: 0.8119\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6197 - accuracy: 0.8122\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6179 - accuracy: 0.8131\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6166 - accuracy: 0.8134\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6159 - accuracy: 0.8143\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6143 - accuracy: 0.8144\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6138 - accuracy: 0.8146\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6120 - accuracy: 0.8151\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6108 - accuracy: 0.8156\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6106 - accuracy: 0.8149\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9574 - accuracy: 0.6998\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8014 - accuracy: 0.7634\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7653 - accuracy: 0.7788\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7494 - accuracy: 0.7853\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7327 - accuracy: 0.7895\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7173 - accuracy: 0.7931\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7010 - accuracy: 0.7967\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6886 - accuracy: 0.7988\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6790 - accuracy: 0.8010\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6719 - accuracy: 0.8025\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6643 - accuracy: 0.8047\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6587 - accuracy: 0.8057\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6522 - accuracy: 0.8067\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6477 - accuracy: 0.8073\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6441 - accuracy: 0.8080\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6395 - accuracy: 0.8092\n",
      "Epoch 17/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6364 - accuracy: 0.8097\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6336 - accuracy: 0.8097\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6309 - accuracy: 0.8101\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6287 - accuracy: 0.8106\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6266 - accuracy: 0.8100\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6250 - accuracy: 0.8111\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6231 - accuracy: 0.8115\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6220 - accuracy: 0.8121\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6208 - accuracy: 0.8118\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6186 - accuracy: 0.8129\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6181 - accuracy: 0.8133\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6157 - accuracy: 0.8131\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6157 - accuracy: 0.8137\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6145 - accuracy: 0.8137\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6139 - accuracy: 0.8139\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6111 - accuracy: 0.8149\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6109 - accuracy: 0.8147\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6108 - accuracy: 0.8152\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6092 - accuracy: 0.8153\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9657 - accuracy: 0.6970\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8064 - accuracy: 0.7618\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7730 - accuracy: 0.7761\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7502 - accuracy: 0.7826\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7333 - accuracy: 0.7858\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7192 - accuracy: 0.7882\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7064 - accuracy: 0.7916\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6978 - accuracy: 0.7941\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6885 - accuracy: 0.7966\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6795 - accuracy: 0.7987\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6732 - accuracy: 0.8003\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6673 - accuracy: 0.8018\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6606 - accuracy: 0.8038\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6566 - accuracy: 0.8041\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6524 - accuracy: 0.8055\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6483 - accuracy: 0.8069\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6444 - accuracy: 0.8073\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6406 - accuracy: 0.8083\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6380 - accuracy: 0.8089\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6356 - accuracy: 0.8094\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6321 - accuracy: 0.8097\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6311 - accuracy: 0.8105\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6279 - accuracy: 0.8113\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6257 - accuracy: 0.8123\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6249 - accuracy: 0.8118\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6220 - accuracy: 0.8123\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6210 - accuracy: 0.8129\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6202 - accuracy: 0.8127\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6184 - accuracy: 0.8136\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6170 - accuracy: 0.8138\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6170 - accuracy: 0.8132\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6148 - accuracy: 0.8141\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6137 - accuracy: 0.8148\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6130 - accuracy: 0.8150\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6124 - accuracy: 0.8148\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 12s 3ms/step - loss: 0.9553 - accuracy: 0.7003\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8038 - accuracy: 0.7652\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7683 - accuracy: 0.7801\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7478 - accuracy: 0.7872\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7318 - accuracy: 0.7897\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7166 - accuracy: 0.7926\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7027 - accuracy: 0.7958\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6904 - accuracy: 0.7981\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6803 - accuracy: 0.8009\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6716 - accuracy: 0.8022\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6651 - accuracy: 0.8042\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6604 - accuracy: 0.8046\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6545 - accuracy: 0.8053\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6501 - accuracy: 0.8063\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6454 - accuracy: 0.8072\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6419 - accuracy: 0.8083\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6390 - accuracy: 0.8091\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6364 - accuracy: 0.8097\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6322 - accuracy: 0.8102\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6310 - accuracy: 0.8102\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6293 - accuracy: 0.8102\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6274 - accuracy: 0.8107\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6254 - accuracy: 0.8109\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6231 - accuracy: 0.8125\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6229 - accuracy: 0.8122\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6215 - accuracy: 0.8120\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6197 - accuracy: 0.8129\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6184 - accuracy: 0.8134\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6176 - accuracy: 0.8127\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6169 - accuracy: 0.8131\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6164 - accuracy: 0.8134\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6146 - accuracy: 0.8141\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6143 - accuracy: 0.8141\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6132 - accuracy: 0.8145\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6122 - accuracy: 0.8146\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "5014/5014 [==============================] - 17s 3ms/step - loss: 0.9318 - accuracy: 0.7132\n",
      "Epoch 2/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.7930 - accuracy: 0.7706\n",
      "Epoch 3/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.7635 - accuracy: 0.7813\n",
      "Epoch 4/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.7400 - accuracy: 0.7869\n",
      "Epoch 5/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.7189 - accuracy: 0.7919\n",
      "Epoch 6/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.7023 - accuracy: 0.7954\n",
      "Epoch 7/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6880 - accuracy: 0.7975\n",
      "Epoch 8/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6769 - accuracy: 0.8001\n",
      "Epoch 9/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6669 - accuracy: 0.8023\n",
      "Epoch 10/35\n",
      "5014/5014 [==============================] - 16s 3ms/step - loss: 0.6595 - accuracy: 0.8034\n",
      "Epoch 11/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6546 - accuracy: 0.8045\n",
      "Epoch 12/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6498 - accuracy: 0.8056\n",
      "Epoch 13/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6456 - accuracy: 0.8059\n",
      "Epoch 14/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6420 - accuracy: 0.8070\n",
      "Epoch 15/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6394 - accuracy: 0.8070\n",
      "Epoch 16/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6367 - accuracy: 0.8077\n",
      "Epoch 17/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6344 - accuracy: 0.8081\n",
      "Epoch 18/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6322 - accuracy: 0.8089\n",
      "Epoch 19/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6313 - accuracy: 0.8095\n",
      "Epoch 20/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6290 - accuracy: 0.8096\n",
      "Epoch 21/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6279 - accuracy: 0.8098\n",
      "Epoch 22/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6269 - accuracy: 0.8105\n",
      "Epoch 23/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6261 - accuracy: 0.8103\n",
      "Epoch 24/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6244 - accuracy: 0.8107\n",
      "Epoch 25/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6240 - accuracy: 0.8109\n",
      "Epoch 26/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6232 - accuracy: 0.8112\n",
      "Epoch 27/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6223 - accuracy: 0.8111\n",
      "Epoch 28/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6212 - accuracy: 0.8117\n",
      "Epoch 29/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6200 - accuracy: 0.8117\n",
      "Epoch 30/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6190 - accuracy: 0.8123\n",
      "Epoch 31/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6189 - accuracy: 0.8125\n",
      "Epoch 32/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6181 - accuracy: 0.8123\n",
      "Epoch 33/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6172 - accuracy: 0.8129\n",
      "Epoch 34/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6166 - accuracy: 0.8130\n",
      "Epoch 35/35\n",
      "5014/5014 [==============================] - 15s 3ms/step - loss: 0.6158 - accuracy: 0.8124\n",
      "Best Results with Grid Search:\n",
      "0.8198538462737032\n",
      "{'unit': 60}\n"
     ]
    }
   ],
   "source": [
    "#Perceptron Tuning\n",
    "\n",
    "def create_model(unit):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=unit, input_shape=(1, 11), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1, epochs = 35, batch_size = 64)\n",
    "\n",
    "parameters = {\n",
    "    'unit': [10,20,30,40,50,60,70,80,90,100],\n",
    "    #'activation': ['relu','tanh'], \n",
    "    #'solver': ['adam','sgd'], \n",
    "    #'last_act': ['sigmoid','softmax'],\n",
    "    #'epochs': [70,100],\n",
    "    #'batch_size': [5,10] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3) # run 1 job at a time\n",
    "\n",
    "grid_search = grid_search.fit(X_train_L, y_train_L)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c476b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xaxis_perceptrons = [10,20,30,40,50,60,70,80,90,100]\n",
    "plt.plot(xaxis_perceptrons,means,'.-')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Perceptrons')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"Figures/No.OfPerceptron_LSTM.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1e06b91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f190806\\AppData\\Local\\Temp\\2/ipykernel_5996/829844154.py:48: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=1, epochs = 35, batch_size = 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 13s 3ms/step - loss: 0.9880 - accuracy: 0.6896\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8201 - accuracy: 0.7570\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7790 - accuracy: 0.7713\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7597 - accuracy: 0.7784\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7444 - accuracy: 0.7822\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7338 - accuracy: 0.7865\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7217 - accuracy: 0.7884\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7127 - accuracy: 0.7912\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7047 - accuracy: 0.7928 0s - l\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6958 - accuracy: 0.7958\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6899 - accuracy: 0.7954\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6828 - accuracy: 0.7985\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6770 - accuracy: 0.8005\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6718 - accuracy: 0.8015\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6681 - accuracy: 0.8011\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6633 - accuracy: 0.8029\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6593 - accuracy: 0.8027\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6568 - accuracy: 0.8046\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6529 - accuracy: 0.8049\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6496 - accuracy: 0.8057\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6475 - accuracy: 0.8064\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6457 - accuracy: 0.8067\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6438 - accuracy: 0.8074\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6419 - accuracy: 0.8074\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6396 - accuracy: 0.8087\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6392 - accuracy: 0.8085\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6368 - accuracy: 0.8087\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6354 - accuracy: 0.8092\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6343 - accuracy: 0.8084\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6338 - accuracy: 0.8097\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6320 - accuracy: 0.8096\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6293 - accuracy: 0.8107\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6287 - accuracy: 0.8107\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6275 - accuracy: 0.8109\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6269 - accuracy: 0.8113\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.9741 - accuracy: 0.6941\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7995 - accuracy: 0.7662\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7626 - accuracy: 0.7794\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7438 - accuracy: 0.7853\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7293 - accuracy: 0.7889\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7148 - accuracy: 0.7913\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7020 - accuracy: 0.7951\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6914 - accuracy: 0.7970\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6828 - accuracy: 0.7994\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6756 - accuracy: 0.8015\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6691 - accuracy: 0.8027\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6632 - accuracy: 0.8033\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6591 - accuracy: 0.8047\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6555 - accuracy: 0.8055\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6515 - accuracy: 0.8060\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6486 - accuracy: 0.8066\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6456 - accuracy: 0.8074\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6433 - accuracy: 0.8075\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6402 - accuracy: 0.8080\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6390 - accuracy: 0.8081\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6374 - accuracy: 0.8088\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6356 - accuracy: 0.8091\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6335 - accuracy: 0.8090\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6320 - accuracy: 0.8092\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6315 - accuracy: 0.8099\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6302 - accuracy: 0.8097\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6296 - accuracy: 0.8108\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6278 - accuracy: 0.8102\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6270 - accuracy: 0.8101\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6271 - accuracy: 0.8107\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6258 - accuracy: 0.8109\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6245 - accuracy: 0.8115\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6247 - accuracy: 0.8112\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6230 - accuracy: 0.8119\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6213 - accuracy: 0.8123\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 11s 3ms/step - loss: 0.9778 - accuracy: 0.6902\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.8130 - accuracy: 0.7610\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7798 - accuracy: 0.7740\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7658 - accuracy: 0.7809\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7524 - accuracy: 0.7844\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7402 - accuracy: 0.7868\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7246 - accuracy: 0.7910\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7127 - accuracy: 0.7938\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.7019 - accuracy: 0.7963\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6920 - accuracy: 0.7979\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6851 - accuracy: 0.7996\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6770 - accuracy: 0.8014\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6697 - accuracy: 0.8021\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6641 - accuracy: 0.8032\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6604 - accuracy: 0.8042\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6564 - accuracy: 0.8044\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6523 - accuracy: 0.8047\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6491 - accuracy: 0.8055\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6479 - accuracy: 0.8051\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6446 - accuracy: 0.8057\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6417 - accuracy: 0.8059\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6398 - accuracy: 0.8067\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6373 - accuracy: 0.8071\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6366 - accuracy: 0.8077\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6349 - accuracy: 0.8079\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6338 - accuracy: 0.8076\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6315 - accuracy: 0.8093\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6298 - accuracy: 0.8100\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6292 - accuracy: 0.8095\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6284 - accuracy: 0.8097\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6277 - accuracy: 0.8101\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6263 - accuracy: 0.8104\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6262 - accuracy: 0.8107\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6245 - accuracy: 0.8106\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 10s 3ms/step - loss: 0.6252 - accuracy: 0.8111\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.9108 - accuracy: 0.7207\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.7485 - accuracy: 0.7731\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.7094 - accuracy: 0.7882\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6897 - accuracy: 0.7960\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6758 - accuracy: 0.8002\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6674 - accuracy: 0.8031\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6598 - accuracy: 0.8050\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6530 - accuracy: 0.8066\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6481 - accuracy: 0.8073\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6431 - accuracy: 0.8088\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6399 - accuracy: 0.8095\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6371 - accuracy: 0.8099\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6356 - accuracy: 0.8106\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6321 - accuracy: 0.8108\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6309 - accuracy: 0.8116\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6281 - accuracy: 0.8121\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6253 - accuracy: 0.8122\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6246 - accuracy: 0.8128\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6226 - accuracy: 0.8127\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6216 - accuracy: 0.8136\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6205 - accuracy: 0.8138\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6190 - accuracy: 0.8136\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6185 - accuracy: 0.8143\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6160 - accuracy: 0.8143\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6148 - accuracy: 0.8152\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6154 - accuracy: 0.8147\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6142 - accuracy: 0.8150\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6122 - accuracy: 0.8155\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6125 - accuracy: 0.8154\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6113 - accuracy: 0.8161\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6106 - accuracy: 0.8167\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6113 - accuracy: 0.8152\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6102 - accuracy: 0.8159\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6089 - accuracy: 0.8166\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6081 - accuracy: 0.8165\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.8879 - accuracy: 0.7297\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.7242 - accuracy: 0.7826\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6937 - accuracy: 0.7945\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6775 - accuracy: 0.7993\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6683 - accuracy: 0.8022\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6586 - accuracy: 0.8058\n",
      "Epoch 7/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6519 - accuracy: 0.8074\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6497 - accuracy: 0.8080\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6446 - accuracy: 0.8092\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6411 - accuracy: 0.8101\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6386 - accuracy: 0.8101\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6338 - accuracy: 0.8116\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6331 - accuracy: 0.8119\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6308 - accuracy: 0.8116\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6291 - accuracy: 0.8124\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6245 - accuracy: 0.8132\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6245 - accuracy: 0.8127\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6226 - accuracy: 0.8134\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6216 - accuracy: 0.8133\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6205 - accuracy: 0.8133\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6182 - accuracy: 0.8141\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6163 - accuracy: 0.8147\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6159 - accuracy: 0.8141\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - ETA: 0s - loss: 0.6156 - accuracy: 0.81 - 16s 5ms/step - loss: 0.6156 - accuracy: 0.8149\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6141 - accuracy: 0.8155\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6117 - accuracy: 0.8157\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6117 - accuracy: 0.8158\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6106 - accuracy: 0.8157\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6103 - accuracy: 0.8163\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6095 - accuracy: 0.8166\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6095 - accuracy: 0.8160\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6072 - accuracy: 0.8167\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6077 - accuracy: 0.8166\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6066 - accuracy: 0.8169\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6045 - accuracy: 0.8177\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.8854 - accuracy: 0.7310\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.7246 - accuracy: 0.7828\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6930 - accuracy: 0.7945\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6766 - accuracy: 0.8003\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6676 - accuracy: 0.8026\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6620 - accuracy: 0.8049\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6565 - accuracy: 0.8058\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6496 - accuracy: 0.8071\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6465 - accuracy: 0.8086\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6426 - accuracy: 0.8097\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6404 - accuracy: 0.8100\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6372 - accuracy: 0.8107\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6360 - accuracy: 0.8109\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6334 - accuracy: 0.8110\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6317 - accuracy: 0.8112\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6289 - accuracy: 0.8124\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6269 - accuracy: 0.8123\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6263 - accuracy: 0.8123\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6241 - accuracy: 0.8129\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6240 - accuracy: 0.8131\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6217 - accuracy: 0.8129\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6208 - accuracy: 0.8137\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6202 - accuracy: 0.8135\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6192 - accuracy: 0.8139\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6181 - accuracy: 0.8140\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6169 - accuracy: 0.8146\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6163 - accuracy: 0.8146\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6158 - accuracy: 0.8158\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6141 - accuracy: 0.8150\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6136 - accuracy: 0.8151\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6135 - accuracy: 0.8155\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6123 - accuracy: 0.8161\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6123 - accuracy: 0.8164\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6110 - accuracy: 0.8163\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 16s 5ms/step - loss: 0.6108 - accuracy: 0.8158\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 25s 7ms/step - loss: 0.8816 - accuracy: 0.7259\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.7295 - accuracy: 0.7764\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.7009 - accuracy: 0.7889\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6842 - accuracy: 0.7949\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6741 - accuracy: 0.7994\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6673 - accuracy: 0.8012\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6625 - accuracy: 0.8035\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6597 - accuracy: 0.8030\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6556 - accuracy: 0.8049\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6523 - accuracy: 0.8061\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6496 - accuracy: 0.8063\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6476 - accuracy: 0.8073\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6456 - accuracy: 0.8072\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6443 - accuracy: 0.8072\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6419 - accuracy: 0.8082\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6401 - accuracy: 0.8089\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6399 - accuracy: 0.8091\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6384 - accuracy: 0.8090\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6373 - accuracy: 0.8095\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6359 - accuracy: 0.8099\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6361 - accuracy: 0.8098\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6350 - accuracy: 0.8104\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6333 - accuracy: 0.8098\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6316 - accuracy: 0.8107\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6305 - accuracy: 0.8110\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6302 - accuracy: 0.8104\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6286 - accuracy: 0.8117\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6281 - accuracy: 0.8108\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6275 - accuracy: 0.8111\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6271 - accuracy: 0.8119\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6259 - accuracy: 0.8116\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6236 - accuracy: 0.8125\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6238 - accuracy: 0.8118\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6230 - accuracy: 0.8128\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 23s 7ms/step - loss: 0.6221 - accuracy: 0.8128\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 25s 7ms/step - loss: 0.8741 - accuracy: 0.7268\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.7235 - accuracy: 0.7795\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6928 - accuracy: 0.7908\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6780 - accuracy: 0.7966\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6680 - accuracy: 0.7992\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6603 - accuracy: 0.8013\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6554 - accuracy: 0.8030\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6517 - accuracy: 0.8042\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6486 - accuracy: 0.8051\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6467 - accuracy: 0.8060\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6441 - accuracy: 0.8068\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6431 - accuracy: 0.8063\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6402 - accuracy: 0.8080\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6377 - accuracy: 0.8085\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6380 - accuracy: 0.8083\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6366 - accuracy: 0.8089\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6340 - accuracy: 0.8099\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6338 - accuracy: 0.8092\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6320 - accuracy: 0.8108\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6301 - accuracy: 0.8106\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6287 - accuracy: 0.8111\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6273 - accuracy: 0.8118\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6269 - accuracy: 0.8117\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6262 - accuracy: 0.8122\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6244 - accuracy: 0.8125\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6241 - accuracy: 0.8125\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6235 - accuracy: 0.8128\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6219 - accuracy: 0.8135\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6211 - accuracy: 0.8132\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6193 - accuracy: 0.8140\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6189 - accuracy: 0.8138\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6180 - accuracy: 0.8148\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6171 - accuracy: 0.8141\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6151 - accuracy: 0.8149\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6145 - accuracy: 0.8147\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 25s 7ms/step - loss: 0.8675 - accuracy: 0.7304\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.7238 - accuracy: 0.7796\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6954 - accuracy: 0.7906\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6782 - accuracy: 0.7958\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6686 - accuracy: 0.7994\n",
      "Epoch 6/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6603 - accuracy: 0.8015\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6564 - accuracy: 0.8029\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6523 - accuracy: 0.8038\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6490 - accuracy: 0.8052\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6456 - accuracy: 0.8067\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6424 - accuracy: 0.8075\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6415 - accuracy: 0.8073\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6388 - accuracy: 0.8080\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6382 - accuracy: 0.8082\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6359 - accuracy: 0.8098\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6343 - accuracy: 0.8098\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6331 - accuracy: 0.8096\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6329 - accuracy: 0.8096\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6312 - accuracy: 0.8104\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6292 - accuracy: 0.8115\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6277 - accuracy: 0.8111\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6280 - accuracy: 0.8114\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6254 - accuracy: 0.8122\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6256 - accuracy: 0.8122\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6245 - accuracy: 0.8129\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6235 - accuracy: 0.8131\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6238 - accuracy: 0.8126\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6218 - accuracy: 0.8130\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6210 - accuracy: 0.8132\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6196 - accuracy: 0.8138\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6180 - accuracy: 0.8139\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6181 - accuracy: 0.8142\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6174 - accuracy: 0.8139\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6172 - accuracy: 0.8139\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 22s 7ms/step - loss: 0.6154 - accuracy: 0.8142\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 32s 9ms/step - loss: 0.8713 - accuracy: 0.7274\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.7297 - accuracy: 0.7755\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.7018 - accuracy: 0.7869\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6882 - accuracy: 0.7931\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6784 - accuracy: 0.7959\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6718 - accuracy: 0.7990\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6659 - accuracy: 0.8017\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6632 - accuracy: 0.8016\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6580 - accuracy: 0.8029\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6539 - accuracy: 0.8048\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6514 - accuracy: 0.8057\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6493 - accuracy: 0.8057\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6471 - accuracy: 0.8060\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6455 - accuracy: 0.8063\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6428 - accuracy: 0.8073\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6410 - accuracy: 0.8076\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6399 - accuracy: 0.8087\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6383 - accuracy: 0.8087\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6371 - accuracy: 0.8094\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6357 - accuracy: 0.8095\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6346 - accuracy: 0.8095\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6333 - accuracy: 0.8107\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6330 - accuracy: 0.8102\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6316 - accuracy: 0.8102\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6290 - accuracy: 0.8113\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6315 - accuracy: 0.8103\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6304 - accuracy: 0.8104\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6284 - accuracy: 0.8113\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6271 - accuracy: 0.8114\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6263 - accuracy: 0.8124\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6249 - accuracy: 0.8123\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6243 - accuracy: 0.8122\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6234 - accuracy: 0.8119\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6214 - accuracy: 0.8133\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6218 - accuracy: 0.8125\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 33s 9ms/step - loss: 0.8867 - accuracy: 0.7209\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.7301 - accuracy: 0.7773\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.7006 - accuracy: 0.7880\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6861 - accuracy: 0.7942\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 28s 8ms/step - loss: 0.6769 - accuracy: 0.7962\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 28s 9ms/step - loss: 0.6704 - accuracy: 0.7982\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6653 - accuracy: 0.8001\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6601 - accuracy: 0.8021\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6574 - accuracy: 0.8028\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 28s 9ms/step - loss: 0.6541 - accuracy: 0.8032\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6509 - accuracy: 0.8037\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6489 - accuracy: 0.8046\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6482 - accuracy: 0.8047\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6460 - accuracy: 0.8062\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6439 - accuracy: 0.8067\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6427 - accuracy: 0.8075\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6423 - accuracy: 0.8070\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6409 - accuracy: 0.8076\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 28s 9ms/step - loss: 0.6393 - accuracy: 0.8086\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6386 - accuracy: 0.8085\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6386 - accuracy: 0.8087\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 28s 8ms/step - loss: 0.6364 - accuracy: 0.8083\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6351 - accuracy: 0.8096\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6338 - accuracy: 0.8098\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6347 - accuracy: 0.8091\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6328 - accuracy: 0.8099\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 28s 9ms/step - loss: 0.6326 - accuracy: 0.8102\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6324 - accuracy: 0.8107\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6314 - accuracy: 0.8109\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6292 - accuracy: 0.8114\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6301 - accuracy: 0.8109\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6281 - accuracy: 0.8117\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 28s 9ms/step - loss: 0.6289 - accuracy: 0.8109\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6272 - accuracy: 0.8119\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6268 - accuracy: 0.8116\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 32s 9ms/step - loss: 0.8882 - accuracy: 0.7220\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.7306 - accuracy: 0.7762\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.7057 - accuracy: 0.7857\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6921 - accuracy: 0.7907\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6820 - accuracy: 0.7953\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6777 - accuracy: 0.7958\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6719 - accuracy: 0.7986\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6668 - accuracy: 0.8000\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6614 - accuracy: 0.8025\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6589 - accuracy: 0.8032\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6570 - accuracy: 0.8029\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6542 - accuracy: 0.8051\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6513 - accuracy: 0.8059\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6516 - accuracy: 0.8048\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6488 - accuracy: 0.8064\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6480 - accuracy: 0.8070\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6459 - accuracy: 0.8075\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6452 - accuracy: 0.8061\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6444 - accuracy: 0.8071\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6429 - accuracy: 0.8080\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6415 - accuracy: 0.8078\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6397 - accuracy: 0.8084\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6371 - accuracy: 0.8092\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6371 - accuracy: 0.8096\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6357 - accuracy: 0.8092\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6355 - accuracy: 0.8101\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6346 - accuracy: 0.8101\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6330 - accuracy: 0.8110\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6342 - accuracy: 0.8100\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 30s 9ms/step - loss: 0.6327 - accuracy: 0.8104\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6327 - accuracy: 0.8094\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6317 - accuracy: 0.8105\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6298 - accuracy: 0.8117\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6289 - accuracy: 0.8113\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 29s 9ms/step - loss: 0.6292 - accuracy: 0.8121\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 39s 10ms/step - loss: 0.8721 - accuracy: 0.7295\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.7290 - accuracy: 0.7767\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.7049 - accuracy: 0.7870\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 35s 11ms/step - loss: 0.6905 - accuracy: 0.7925\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6823 - accuracy: 0.7947\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6754 - accuracy: 0.7967\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6715 - accuracy: 0.7994\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6661 - accuracy: 0.8006\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6636 - accuracy: 0.8020\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6602 - accuracy: 0.8022\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6586 - accuracy: 0.8029\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6560 - accuracy: 0.8036\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6538 - accuracy: 0.8047\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6532 - accuracy: 0.8042\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6513 - accuracy: 0.8055\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6494 - accuracy: 0.8059\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6486 - accuracy: 0.8054\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6478 - accuracy: 0.8068\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6472 - accuracy: 0.8064\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6450 - accuracy: 0.8073\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 35s 11ms/step - loss: 0.6439 - accuracy: 0.8073\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6421 - accuracy: 0.8084\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6433 - accuracy: 0.8087\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6419 - accuracy: 0.8084\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6396 - accuracy: 0.8089\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6387 - accuracy: 0.8094\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6390 - accuracy: 0.8089\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6383 - accuracy: 0.8092\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6352 - accuracy: 0.8097\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6357 - accuracy: 0.8109\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6356 - accuracy: 0.8095\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6337 - accuracy: 0.8109\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6334 - accuracy: 0.8107\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6312 - accuracy: 0.8110\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6312 - accuracy: 0.8121\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 40s 10ms/step - loss: 0.8903 - accuracy: 0.7202\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.7229 - accuracy: 0.7787\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6992 - accuracy: 0.7895\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6839 - accuracy: 0.7953\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6770 - accuracy: 0.7971\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 35s 11ms/step - loss: 0.6711 - accuracy: 0.7991\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6662 - accuracy: 0.8011\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6630 - accuracy: 0.8025\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6607 - accuracy: 0.8021\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6589 - accuracy: 0.8036\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6570 - accuracy: 0.8045\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6547 - accuracy: 0.8045\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6534 - accuracy: 0.8048\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6528 - accuracy: 0.8053\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6502 - accuracy: 0.8050\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6495 - accuracy: 0.8060\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6469 - accuracy: 0.8060\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6461 - accuracy: 0.8067\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6441 - accuracy: 0.8074\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6432 - accuracy: 0.8082\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6420 - accuracy: 0.8071\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6400 - accuracy: 0.8086\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6394 - accuracy: 0.8086\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6389 - accuracy: 0.8090\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 35s 11ms/step - loss: 0.6377 - accuracy: 0.8093\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6379 - accuracy: 0.8093\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6354 - accuracy: 0.8098\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6350 - accuracy: 0.8103\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6347 - accuracy: 0.8098\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6352 - accuracy: 0.8097\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6349 - accuracy: 0.8094\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6336 - accuracy: 0.8103\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6324 - accuracy: 0.8107\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6322 - accuracy: 0.8104\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6311 - accuracy: 0.8110\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 40s 10ms/step - loss: 0.8937 - accuracy: 0.7183\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.7283 - accuracy: 0.7767\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.7021 - accuracy: 0.7875\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6882 - accuracy: 0.7935\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6801 - accuracy: 0.7968\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6738 - accuracy: 0.7988\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6725 - accuracy: 0.7996\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6699 - accuracy: 0.7996\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 35s 11ms/step - loss: 0.6652 - accuracy: 0.8018\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6631 - accuracy: 0.8029\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6622 - accuracy: 0.8032\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 35s 11ms/step - loss: 0.6623 - accuracy: 0.8023\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6574 - accuracy: 0.8030\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6575 - accuracy: 0.8037\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6538 - accuracy: 0.8050\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 35s 11ms/step - loss: 0.6526 - accuracy: 0.8043\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6516 - accuracy: 0.8049\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6501 - accuracy: 0.8057\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6496 - accuracy: 0.8056\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 35s 11ms/step - loss: 0.6483 - accuracy: 0.8062\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6488 - accuracy: 0.8061\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6463 - accuracy: 0.8072\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6458 - accuracy: 0.8069\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 35s 11ms/step - loss: 0.6441 - accuracy: 0.8073\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6437 - accuracy: 0.8079\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6435 - accuracy: 0.8074\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6428 - accuracy: 0.8077\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6405 - accuracy: 0.8089\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6404 - accuracy: 0.8084\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6395 - accuracy: 0.8093\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6399 - accuracy: 0.8086\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6406 - accuracy: 0.8090\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6382 - accuracy: 0.8092\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6380 - accuracy: 0.8098\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 35s 10ms/step - loss: 0.6365 - accuracy: 0.8097\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "5014/5014 [==============================] - 26s 5ms/step - loss: 0.8397 - accuracy: 0.7453\n",
      "Epoch 2/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.7033 - accuracy: 0.7918\n",
      "Epoch 3/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6745 - accuracy: 0.8009\n",
      "Epoch 4/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6603 - accuracy: 0.8052\n",
      "Epoch 5/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6523 - accuracy: 0.8076\n",
      "Epoch 6/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6459 - accuracy: 0.8099\n",
      "Epoch 7/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6404 - accuracy: 0.8109\n",
      "Epoch 8/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6366 - accuracy: 0.8114\n",
      "Epoch 9/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6329 - accuracy: 0.8120\n",
      "Epoch 10/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6293 - accuracy: 0.8129\n",
      "Epoch 11/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6257 - accuracy: 0.8128\n",
      "Epoch 12/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6245 - accuracy: 0.8132\n",
      "Epoch 13/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6219 - accuracy: 0.8145\n",
      "Epoch 14/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6192 - accuracy: 0.8150\n",
      "Epoch 15/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6178 - accuracy: 0.8148\n",
      "Epoch 16/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6154 - accuracy: 0.8160\n",
      "Epoch 17/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6136 - accuracy: 0.8166\n",
      "Epoch 18/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6125 - accuracy: 0.8170\n",
      "Epoch 19/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6108 - accuracy: 0.8175\n",
      "Epoch 20/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6101 - accuracy: 0.8178\n",
      "Epoch 21/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6086 - accuracy: 0.8177\n",
      "Epoch 22/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6071 - accuracy: 0.8182\n",
      "Epoch 23/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6072 - accuracy: 0.8179\n",
      "Epoch 24/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6064 - accuracy: 0.8184\n",
      "Epoch 25/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6049 - accuracy: 0.8184\n",
      "Epoch 26/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6040 - accuracy: 0.8187\n",
      "Epoch 27/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6034 - accuracy: 0.8188\n",
      "Epoch 28/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6025 - accuracy: 0.8195\n",
      "Epoch 29/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6014 - accuracy: 0.8192\n",
      "Epoch 30/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6018 - accuracy: 0.8192\n",
      "Epoch 31/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6016 - accuracy: 0.8197\n",
      "Epoch 32/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.6006 - accuracy: 0.8196\n",
      "Epoch 33/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.5988 - accuracy: 0.8197\n",
      "Epoch 34/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.5995 - accuracy: 0.8196\n",
      "Epoch 35/35\n",
      "5014/5014 [==============================] - 24s 5ms/step - loss: 0.5986 - accuracy: 0.8207\n",
      "Best Results with Grid Search:\n",
      "0.8242446906308918\n",
      "{'No_Of_layers': 2}\n"
     ]
    }
   ],
   "source": [
    "#Layers Tuning for LSTM Layer\n",
    "\n",
    "def create_model(No_Of_layers):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if No_Of_layers == 1:\n",
    "        model.add(LSTM(units=60, input_shape=(1, 11), activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "    elif No_Of_layers == 2:\n",
    "        model.add(LSTM(units=60, input_shape=(1, 11), return_sequences = True, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=60, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "    elif No_Of_layers == 3:\n",
    "        model.add(LSTM(units=60, input_shape=(1, 11), return_sequences = True, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=60,  return_sequences = True, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=60, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "    elif No_Of_layers == 4:\n",
    "        model.add(LSTM(units=60, input_shape=(1, 11), return_sequences = True, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=60,  return_sequences = True, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=60,  return_sequences = True, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=60, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "    elif No_Of_layers == 5:\n",
    "        model.add(LSTM(units=60, input_shape=(1, 11), return_sequences = True, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=60,  return_sequences = True, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=60,  return_sequences = True, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=60,  return_sequences = True, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=60, activation='relu'))\n",
    "        model.add(Dropout(0.2))    \n",
    "    \n",
    "    # Add an output layer \n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    #compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1, epochs = 35, batch_size = 64)\n",
    "\n",
    "parameters = {\n",
    "    #'unit': [60],\n",
    "    'No_Of_layers': [1,2,3,4,5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_L, y_train_L)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1409723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xaxis_LSTM_layers =[1,2,3,4,5]\n",
    "plt.plot(xaxis_LSTM_layers,means,'.-')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of LSTM Layers')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"Figures/No.OfLayers_LSTM.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed629fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f190806\\AppData\\Local\\Temp\\2\\ipykernel_1140\\1341314236.py:21: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=1, epochs = 35, batch_size = 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 22s 5ms/step - loss: 0.8883 - accuracy: 0.7305\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.7308 - accuracy: 0.7809\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6992 - accuracy: 0.7938\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6828 - accuracy: 0.7986\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6691 - accuracy: 0.8035\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6626 - accuracy: 0.8050\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6582 - accuracy: 0.8071\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6526 - accuracy: 0.8083\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6489 - accuracy: 0.8091\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6456 - accuracy: 0.8104\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6436 - accuracy: 0.8104\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6404 - accuracy: 0.8108\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6386 - accuracy: 0.8111\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6363 - accuracy: 0.8118\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6344 - accuracy: 0.8122\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6317 - accuracy: 0.8125\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6296 - accuracy: 0.8127\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6279 - accuracy: 0.8132\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6261 - accuracy: 0.8139\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6256 - accuracy: 0.8133\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6227 - accuracy: 0.8137\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6216 - accuracy: 0.8139\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6198 - accuracy: 0.8151\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6197 - accuracy: 0.8142\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6184 - accuracy: 0.8151\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6173 - accuracy: 0.8152\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6169 - accuracy: 0.8156\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6159 - accuracy: 0.8166\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6149 - accuracy: 0.8162\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6139 - accuracy: 0.8167\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6141 - accuracy: 0.8163\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6124 - accuracy: 0.8169\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6132 - accuracy: 0.8172\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6112 - accuracy: 0.8173\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6105 - accuracy: 0.8175\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 20s 5ms/step - loss: 0.8774 - accuracy: 0.7342\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.7205 - accuracy: 0.7823\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6920 - accuracy: 0.7940\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6752 - accuracy: 0.7998\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6649 - accuracy: 0.8030\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6586 - accuracy: 0.8046\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6541 - accuracy: 0.8061\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6502 - accuracy: 0.8075\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6465 - accuracy: 0.8093\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6431 - accuracy: 0.8098\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6395 - accuracy: 0.8098\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6375 - accuracy: 0.8106\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6339 - accuracy: 0.8108\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6319 - accuracy: 0.8108\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6287 - accuracy: 0.8118\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6260 - accuracy: 0.8130\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6245 - accuracy: 0.8135\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6219 - accuracy: 0.8141\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6217 - accuracy: 0.8132\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6200 - accuracy: 0.8144\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6199 - accuracy: 0.8147\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6168 - accuracy: 0.8156\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6162 - accuracy: 0.8153\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6160 - accuracy: 0.8158\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6149 - accuracy: 0.8154\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6130 - accuracy: 0.8161\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6129 - accuracy: 0.8162\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6127 - accuracy: 0.8155\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6114 - accuracy: 0.8165\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6107 - accuracy: 0.8167\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6108 - accuracy: 0.8165\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6078 - accuracy: 0.8178\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6094 - accuracy: 0.8174\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6079 - accuracy: 0.8169\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6063 - accuracy: 0.8171\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 19s 5ms/step - loss: 0.8813 - accuracy: 0.7331\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.7328 - accuracy: 0.7809\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.7000 - accuracy: 0.7918\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6819 - accuracy: 0.7987\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6718 - accuracy: 0.8014\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6624 - accuracy: 0.8035\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6575 - accuracy: 0.8053\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6526 - accuracy: 0.8066\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6488 - accuracy: 0.8086\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6454 - accuracy: 0.8083\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6411 - accuracy: 0.8098\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6368 - accuracy: 0.8105\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6357 - accuracy: 0.8109\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6332 - accuracy: 0.8108\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6325 - accuracy: 0.8111\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6287 - accuracy: 0.8121\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6278 - accuracy: 0.8125\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6261 - accuracy: 0.8130\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6244 - accuracy: 0.8128\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6214 - accuracy: 0.8139\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6216 - accuracy: 0.8140\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6205 - accuracy: 0.8141\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6185 - accuracy: 0.8139\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6179 - accuracy: 0.8149\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6175 - accuracy: 0.8146\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6163 - accuracy: 0.8155\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6152 - accuracy: 0.8151\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6153 - accuracy: 0.8157\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6132 - accuracy: 0.8162\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6126 - accuracy: 0.8157\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6116 - accuracy: 0.8163\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6108 - accuracy: 0.8168\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6105 - accuracy: 0.8164\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6095 - accuracy: 0.8166\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6095 - accuracy: 0.8165\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 20s 5ms/step - loss: 0.8496 - accuracy: 0.7398\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.7185 - accuracy: 0.7839\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6944 - accuracy: 0.7923\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6808 - accuracy: 0.7967\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6727 - accuracy: 0.8001\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6669 - accuracy: 0.8012\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6616 - accuracy: 0.8029\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6567 - accuracy: 0.8038\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6525 - accuracy: 0.8048\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6500 - accuracy: 0.8057\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6487 - accuracy: 0.8057\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6456 - accuracy: 0.8065\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6435 - accuracy: 0.8070\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6408 - accuracy: 0.8074\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6392 - accuracy: 0.8078\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6385 - accuracy: 0.8076\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6357 - accuracy: 0.8080\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6341 - accuracy: 0.8077\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6336 - accuracy: 0.8081\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6320 - accuracy: 0.8090\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6307 - accuracy: 0.8100\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6289 - accuracy: 0.8098\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6278 - accuracy: 0.8100\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6266 - accuracy: 0.8106\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6261 - accuracy: 0.8101\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6241 - accuracy: 0.8118\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6249 - accuracy: 0.8121\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6222 - accuracy: 0.8118\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6219 - accuracy: 0.8113\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6203 - accuracy: 0.8117\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6195 - accuracy: 0.8125\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6185 - accuracy: 0.8129\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6186 - accuracy: 0.8130\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6173 - accuracy: 0.8129\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6168 - accuracy: 0.8129\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 20s 5ms/step - loss: 0.8489 - accuracy: 0.7379\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.7196 - accuracy: 0.7817\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6903 - accuracy: 0.7933\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6746 - accuracy: 0.7982\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6643 - accuracy: 0.8020\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6591 - accuracy: 0.8020\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6520 - accuracy: 0.8048\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6480 - accuracy: 0.8056\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6450 - accuracy: 0.8055\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6411 - accuracy: 0.8069\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6391 - accuracy: 0.8070\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6358 - accuracy: 0.8089\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6335 - accuracy: 0.8086\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6320 - accuracy: 0.8090\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6319 - accuracy: 0.8095\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6287 - accuracy: 0.8101\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6277 - accuracy: 0.8106\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6264 - accuracy: 0.8106\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6256 - accuracy: 0.8101\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6243 - accuracy: 0.8111\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6239 - accuracy: 0.8110\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6219 - accuracy: 0.8123\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6220 - accuracy: 0.8120\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6209 - accuracy: 0.8121\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6196 - accuracy: 0.8129\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6180 - accuracy: 0.8136\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6167 - accuracy: 0.8136\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6170 - accuracy: 0.8127\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6171 - accuracy: 0.8130\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6162 - accuracy: 0.8140\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6151 - accuracy: 0.8140\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6133 - accuracy: 0.8146\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6123 - accuracy: 0.8144\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6143 - accuracy: 0.8143\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6120 - accuracy: 0.8148\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 21s 5ms/step - loss: 0.8635 - accuracy: 0.7328\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.7232 - accuracy: 0.7812\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6969 - accuracy: 0.7909\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6807 - accuracy: 0.7971\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6734 - accuracy: 0.7987\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6667 - accuracy: 0.8017\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6622 - accuracy: 0.8017\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6582 - accuracy: 0.8030\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6551 - accuracy: 0.8043\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6508 - accuracy: 0.8059\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6482 - accuracy: 0.8065\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6461 - accuracy: 0.8069\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6438 - accuracy: 0.8076\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6428 - accuracy: 0.8072\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6425 - accuracy: 0.8078\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6403 - accuracy: 0.8081\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6376 - accuracy: 0.8085\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6366 - accuracy: 0.8090\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6345 - accuracy: 0.8103\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6346 - accuracy: 0.8102\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6329 - accuracy: 0.8102\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6325 - accuracy: 0.8104\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6325 - accuracy: 0.8101\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6297 - accuracy: 0.8110\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6307 - accuracy: 0.8105\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6291 - accuracy: 0.8108\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6274 - accuracy: 0.8116\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6268 - accuracy: 0.8116\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6268 - accuracy: 0.8118\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6258 - accuracy: 0.8107\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6251 - accuracy: 0.8122\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6243 - accuracy: 0.8114\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6234 - accuracy: 0.8119\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6233 - accuracy: 0.8128\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6224 - accuracy: 0.8122\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 21s 6ms/step - loss: 0.8320 - accuracy: 0.7418\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.7192 - accuracy: 0.7818\n",
      "Epoch 3/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6999 - accuracy: 0.7889\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6874 - accuracy: 0.7930\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6793 - accuracy: 0.7951\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6732 - accuracy: 0.7964\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6658 - accuracy: 0.7991\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6604 - accuracy: 0.8006\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6607 - accuracy: 0.7995\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6541 - accuracy: 0.8016\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6532 - accuracy: 0.8020\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6515 - accuracy: 0.8032\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6501 - accuracy: 0.8029\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6479 - accuracy: 0.8038\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6462 - accuracy: 0.8044\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6456 - accuracy: 0.8049\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6428 - accuracy: 0.8057\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6415 - accuracy: 0.8066\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6412 - accuracy: 0.8067\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6389 - accuracy: 0.8079\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6385 - accuracy: 0.8070\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6369 - accuracy: 0.8077\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6349 - accuracy: 0.8086\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6338 - accuracy: 0.8083\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6344 - accuracy: 0.8090\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6326 - accuracy: 0.8087\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6325 - accuracy: 0.8089\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6315 - accuracy: 0.8094\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6287 - accuracy: 0.8105\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6281 - accuracy: 0.8109\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6279 - accuracy: 0.8099\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6277 - accuracy: 0.8105\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6266 - accuracy: 0.8102\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6245 - accuracy: 0.8108\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6240 - accuracy: 0.8108\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 20s 5ms/step - loss: 0.8284 - accuracy: 0.7447\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.7115 - accuracy: 0.7852\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6909 - accuracy: 0.7921\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6812 - accuracy: 0.7958\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6730 - accuracy: 0.7979\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6649 - accuracy: 0.7999\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6596 - accuracy: 0.8015\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6554 - accuracy: 0.8027\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6533 - accuracy: 0.8030\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6505 - accuracy: 0.8041\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6485 - accuracy: 0.8048\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6466 - accuracy: 0.8050\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6454 - accuracy: 0.8058\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6436 - accuracy: 0.8059\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6433 - accuracy: 0.8059\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6415 - accuracy: 0.8059\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6408 - accuracy: 0.8071\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6380 - accuracy: 0.8075\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6377 - accuracy: 0.8089\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6368 - accuracy: 0.8084\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6356 - accuracy: 0.8084\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6345 - accuracy: 0.8089\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6354 - accuracy: 0.8091\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6330 - accuracy: 0.8089\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6333 - accuracy: 0.8094\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6310 - accuracy: 0.8099\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6304 - accuracy: 0.8099\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6325 - accuracy: 0.8090\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6296 - accuracy: 0.8104\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6292 - accuracy: 0.8106\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6290 - accuracy: 0.8106\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6277 - accuracy: 0.8103\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6269 - accuracy: 0.8113\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6270 - accuracy: 0.8120\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 17s 5ms/step - loss: 0.6254 - accuracy: 0.8118\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 21s 5ms/step - loss: 0.8285 - accuracy: 0.7423\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.7207 - accuracy: 0.7806\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6994 - accuracy: 0.7897\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6874 - accuracy: 0.7932\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6803 - accuracy: 0.7942\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6729 - accuracy: 0.7985\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6680 - accuracy: 0.7989\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6619 - accuracy: 0.8006\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6598 - accuracy: 0.8010\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6555 - accuracy: 0.8024\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6527 - accuracy: 0.8028\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6514 - accuracy: 0.8033\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6501 - accuracy: 0.8039\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6483 - accuracy: 0.8053\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6487 - accuracy: 0.8041\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6468 - accuracy: 0.8047\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6444 - accuracy: 0.8062\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6436 - accuracy: 0.8055\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6428 - accuracy: 0.8057\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6430 - accuracy: 0.8066\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6412 - accuracy: 0.8067\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6404 - accuracy: 0.8080\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6401 - accuracy: 0.8069\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6394 - accuracy: 0.8076\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6369 - accuracy: 0.8077\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6367 - accuracy: 0.8074\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6358 - accuracy: 0.8089\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6353 - accuracy: 0.8086\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6353 - accuracy: 0.8095\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6338 - accuracy: 0.8092\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6347 - accuracy: 0.8089\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6330 - accuracy: 0.8100\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6323 - accuracy: 0.8091\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6324 - accuracy: 0.8092\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6323 - accuracy: 0.8097\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 22s 6ms/step - loss: 0.8248 - accuracy: 0.7430\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.7217 - accuracy: 0.7797\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.7015 - accuracy: 0.7878\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6899 - accuracy: 0.7932\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6818 - accuracy: 0.7950\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6737 - accuracy: 0.7970\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6694 - accuracy: 0.7989\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6661 - accuracy: 0.7990\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6631 - accuracy: 0.8001\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6593 - accuracy: 0.8009\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6559 - accuracy: 0.8012\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6553 - accuracy: 0.8022\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6518 - accuracy: 0.8034\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6503 - accuracy: 0.8029\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6483 - accuracy: 0.8047\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6475 - accuracy: 0.8048\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6455 - accuracy: 0.8052\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6445 - accuracy: 0.8056\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6440 - accuracy: 0.8055\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6423 - accuracy: 0.8064\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6407 - accuracy: 0.8082\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6399 - accuracy: 0.8063\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6409 - accuracy: 0.8072\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6379 - accuracy: 0.8077\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6374 - accuracy: 0.8079\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6364 - accuracy: 0.8078\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6365 - accuracy: 0.8077\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6368 - accuracy: 0.8081\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6357 - accuracy: 0.8082\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6343 - accuracy: 0.8082\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6330 - accuracy: 0.8092\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6326 - accuracy: 0.8092\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6309 - accuracy: 0.8103\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6303 - accuracy: 0.8101\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6300 - accuracy: 0.8099\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 21s 6ms/step - loss: 0.8250 - accuracy: 0.7431\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.7209 - accuracy: 0.7798\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.7001 - accuracy: 0.7878\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6878 - accuracy: 0.7924\n",
      "Epoch 5/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6802 - accuracy: 0.7946\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6730 - accuracy: 0.7968\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6676 - accuracy: 0.7990\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6631 - accuracy: 0.7995\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6628 - accuracy: 0.7990\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6571 - accuracy: 0.8015\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6561 - accuracy: 0.8017\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6537 - accuracy: 0.8020\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6499 - accuracy: 0.8043\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6492 - accuracy: 0.8033\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6520 - accuracy: 0.8028\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6476 - accuracy: 0.8039\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6459 - accuracy: 0.8038\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6449 - accuracy: 0.8050\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6450 - accuracy: 0.8052\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6439 - accuracy: 0.8054\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6423 - accuracy: 0.8048\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6408 - accuracy: 0.8064\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6397 - accuracy: 0.8068\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6399 - accuracy: 0.8063\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6388 - accuracy: 0.8075\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6384 - accuracy: 0.8072\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6366 - accuracy: 0.8080\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6373 - accuracy: 0.8078\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6354 - accuracy: 0.8081\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6361 - accuracy: 0.8083\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6351 - accuracy: 0.8078\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6346 - accuracy: 0.8084\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6343 - accuracy: 0.8086\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6336 - accuracy: 0.8090\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6327 - accuracy: 0.8088\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 21s 5ms/step - loss: 0.8267 - accuracy: 0.7429\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.7252 - accuracy: 0.7781\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.7030 - accuracy: 0.7868\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6904 - accuracy: 0.7909\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6814 - accuracy: 0.7935\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6755 - accuracy: 0.7957\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6715 - accuracy: 0.7970\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6685 - accuracy: 0.7975\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6652 - accuracy: 0.7992\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6625 - accuracy: 0.8004\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6583 - accuracy: 0.8019\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6576 - accuracy: 0.8020\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6557 - accuracy: 0.8021\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6539 - accuracy: 0.8035\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6520 - accuracy: 0.8033\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6511 - accuracy: 0.8037\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6508 - accuracy: 0.8042\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6471 - accuracy: 0.8061\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6473 - accuracy: 0.8060\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6445 - accuracy: 0.8062\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6454 - accuracy: 0.8062\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6446 - accuracy: 0.8067\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6432 - accuracy: 0.8063\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6432 - accuracy: 0.8058\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6423 - accuracy: 0.8058\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6416 - accuracy: 0.8067\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6410 - accuracy: 0.8085\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6407 - accuracy: 0.8078\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6398 - accuracy: 0.8073\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6379 - accuracy: 0.8079\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6382 - accuracy: 0.8091\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6367 - accuracy: 0.8097\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6357 - accuracy: 0.8093\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6355 - accuracy: 0.8089\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6357 - accuracy: 0.8087\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 21s 5ms/step - loss: 0.8371 - accuracy: 0.7381\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.7268 - accuracy: 0.7779\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.7053 - accuracy: 0.7853\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6935 - accuracy: 0.7900\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6841 - accuracy: 0.7935\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6771 - accuracy: 0.7954\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6731 - accuracy: 0.7973\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6689 - accuracy: 0.7981\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6685 - accuracy: 0.7978\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6643 - accuracy: 0.8001\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6614 - accuracy: 0.8002\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6591 - accuracy: 0.8016\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6588 - accuracy: 0.8019\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6577 - accuracy: 0.8023\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6570 - accuracy: 0.8017\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6546 - accuracy: 0.8045\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6534 - accuracy: 0.8026\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6505 - accuracy: 0.8041\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6516 - accuracy: 0.8034\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6510 - accuracy: 0.8041\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6491 - accuracy: 0.8053\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6492 - accuracy: 0.8044\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6476 - accuracy: 0.8053\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6476 - accuracy: 0.8048\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6463 - accuracy: 0.8054\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6468 - accuracy: 0.8052\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6463 - accuracy: 0.8059\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6454 - accuracy: 0.8056\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6447 - accuracy: 0.8059\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6447 - accuracy: 0.8055\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6432 - accuracy: 0.8070\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6442 - accuracy: 0.8062\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6424 - accuracy: 0.8072\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6421 - accuracy: 0.8067\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6416 - accuracy: 0.8069\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 22s 6ms/step - loss: 0.8349 - accuracy: 0.7382\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.7259 - accuracy: 0.7792\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.7028 - accuracy: 0.7866\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6917 - accuracy: 0.7896\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6832 - accuracy: 0.7934\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6789 - accuracy: 0.7943\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6743 - accuracy: 0.7953\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6715 - accuracy: 0.7962\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6673 - accuracy: 0.7986\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6655 - accuracy: 0.7976\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6623 - accuracy: 0.7992\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6613 - accuracy: 0.7989\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6606 - accuracy: 0.7989\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6583 - accuracy: 0.8005\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6565 - accuracy: 0.8017\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6562 - accuracy: 0.8015\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6534 - accuracy: 0.8025\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6542 - accuracy: 0.8020\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6525 - accuracy: 0.8026\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6495 - accuracy: 0.8031\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6496 - accuracy: 0.8044\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6500 - accuracy: 0.8026\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6486 - accuracy: 0.8033\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 40s 12ms/step - loss: 0.6475 - accuracy: 0.8044\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6493 - accuracy: 0.8032\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6470 - accuracy: 0.8043\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6460 - accuracy: 0.8056\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6469 - accuracy: 0.8042\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6442 - accuracy: 0.8053\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6431 - accuracy: 0.8061\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6427 - accuracy: 0.8063\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6419 - accuracy: 0.8052\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6400 - accuracy: 0.8067\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6390 - accuracy: 0.8077\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6410 - accuracy: 0.8075\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 22s 6ms/step - loss: 0.8214 - accuracy: 0.7446\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.7157 - accuracy: 0.7826\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6954 - accuracy: 0.7893\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6859 - accuracy: 0.7920\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6789 - accuracy: 0.7939\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6721 - accuracy: 0.7966\n",
      "Epoch 7/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6681 - accuracy: 0.7981\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6656 - accuracy: 0.7996\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6634 - accuracy: 0.7998\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6609 - accuracy: 0.8005\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6596 - accuracy: 0.8004\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6573 - accuracy: 0.8012\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6558 - accuracy: 0.8022\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6543 - accuracy: 0.8018\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6520 - accuracy: 0.8029\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6524 - accuracy: 0.8036\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6491 - accuracy: 0.8043\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6498 - accuracy: 0.8043\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6488 - accuracy: 0.8037\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6487 - accuracy: 0.8046\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6465 - accuracy: 0.8047\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6460 - accuracy: 0.8042\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6442 - accuracy: 0.8064\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6434 - accuracy: 0.8061\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6425 - accuracy: 0.8071\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6435 - accuracy: 0.8066\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6419 - accuracy: 0.8067\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6412 - accuracy: 0.8074\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6415 - accuracy: 0.8073\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6403 - accuracy: 0.8076\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6398 - accuracy: 0.8082\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6381 - accuracy: 0.8085\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6378 - accuracy: 0.8089\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 18s 6ms/step - loss: 0.6382 - accuracy: 0.8091\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 18s 5ms/step - loss: 0.6357 - accuracy: 0.8092\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 22s 6ms/step - loss: 0.8273 - accuracy: 0.7421\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.7256 - accuracy: 0.7781\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.7038 - accuracy: 0.7855\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6919 - accuracy: 0.7892\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6855 - accuracy: 0.7919\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6792 - accuracy: 0.7930\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6758 - accuracy: 0.7951\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6725 - accuracy: 0.7947\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6705 - accuracy: 0.7951\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6684 - accuracy: 0.7977\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6656 - accuracy: 0.7975\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6629 - accuracy: 0.7989\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6616 - accuracy: 0.7994\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6597 - accuracy: 0.8011\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6581 - accuracy: 0.8013\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6568 - accuracy: 0.8016\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6559 - accuracy: 0.8023\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6551 - accuracy: 0.8025\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6542 - accuracy: 0.8027\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6538 - accuracy: 0.8026\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6539 - accuracy: 0.8027\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6529 - accuracy: 0.8022\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6510 - accuracy: 0.8030\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6511 - accuracy: 0.8041\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6512 - accuracy: 0.8030\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6493 - accuracy: 0.8040\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6487 - accuracy: 0.8037\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6479 - accuracy: 0.8036\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6504 - accuracy: 0.8034\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6497 - accuracy: 0.8045\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6470 - accuracy: 0.8058\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6459 - accuracy: 0.8062\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6478 - accuracy: 0.8049\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6448 - accuracy: 0.8060\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6457 - accuracy: 0.8047\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 22s 6ms/step - loss: 0.8265 - accuracy: 0.7433\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.7221 - accuracy: 0.7792\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6992 - accuracy: 0.7864\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6882 - accuracy: 0.7891\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6795 - accuracy: 0.7923\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6751 - accuracy: 0.7940\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6707 - accuracy: 0.7964\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6673 - accuracy: 0.7970\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6649 - accuracy: 0.7986\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6627 - accuracy: 0.7993\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6597 - accuracy: 0.8010\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6579 - accuracy: 0.8009\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6571 - accuracy: 0.8011\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6557 - accuracy: 0.8022\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6529 - accuracy: 0.8032\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6518 - accuracy: 0.8033\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6502 - accuracy: 0.8044\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6514 - accuracy: 0.8044\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6496 - accuracy: 0.8039\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6486 - accuracy: 0.8038\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6477 - accuracy: 0.8044\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6463 - accuracy: 0.8049\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6470 - accuracy: 0.8043\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6446 - accuracy: 0.8052\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6436 - accuracy: 0.8064\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6421 - accuracy: 0.8071\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6412 - accuracy: 0.8070\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6420 - accuracy: 0.8064\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6431 - accuracy: 0.8068\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6423 - accuracy: 0.8052\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6413 - accuracy: 0.8073\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6395 - accuracy: 0.8073\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6412 - accuracy: 0.8076\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6394 - accuracy: 0.8075\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6385 - accuracy: 0.8082\n",
      "3343/3343 [==============================] - 9s 3ms/step\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "3343/3343 [==============================] - 22s 6ms/step - loss: 0.8299 - accuracy: 0.7410\n",
      "Epoch 2/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.7275 - accuracy: 0.7772\n",
      "Epoch 3/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.7059 - accuracy: 0.7845\n",
      "Epoch 4/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6961 - accuracy: 0.7876\n",
      "Epoch 5/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6876 - accuracy: 0.7901\n",
      "Epoch 6/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6816 - accuracy: 0.7928\n",
      "Epoch 7/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6782 - accuracy: 0.7938\n",
      "Epoch 8/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6749 - accuracy: 0.7948\n",
      "Epoch 9/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6701 - accuracy: 0.7957\n",
      "Epoch 10/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6682 - accuracy: 0.7971\n",
      "Epoch 11/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6657 - accuracy: 0.7988\n",
      "Epoch 12/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6657 - accuracy: 0.7981\n",
      "Epoch 13/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6635 - accuracy: 0.7991\n",
      "Epoch 14/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6607 - accuracy: 0.7994\n",
      "Epoch 15/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6612 - accuracy: 0.7997\n",
      "Epoch 16/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6591 - accuracy: 0.8006\n",
      "Epoch 17/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6576 - accuracy: 0.8013\n",
      "Epoch 18/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6573 - accuracy: 0.8016\n",
      "Epoch 19/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6570 - accuracy: 0.8013\n",
      "Epoch 20/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6550 - accuracy: 0.8013\n",
      "Epoch 21/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6548 - accuracy: 0.8022\n",
      "Epoch 22/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6525 - accuracy: 0.8026\n",
      "Epoch 23/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6540 - accuracy: 0.8024\n",
      "Epoch 24/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6516 - accuracy: 0.8042\n",
      "Epoch 25/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6512 - accuracy: 0.8036\n",
      "Epoch 26/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6494 - accuracy: 0.8042\n",
      "Epoch 27/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6500 - accuracy: 0.8037\n",
      "Epoch 28/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6487 - accuracy: 0.8039\n",
      "Epoch 29/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6482 - accuracy: 0.8047\n",
      "Epoch 30/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6478 - accuracy: 0.8051\n",
      "Epoch 31/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6474 - accuracy: 0.8040\n",
      "Epoch 32/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6463 - accuracy: 0.8057\n",
      "Epoch 33/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6457 - accuracy: 0.8054\n",
      "Epoch 34/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6452 - accuracy: 0.8051\n",
      "Epoch 35/35\n",
      "3343/3343 [==============================] - 19s 6ms/step - loss: 0.6464 - accuracy: 0.8046\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/35\n",
      "5014/5014 [==============================] - 28s 5ms/step - loss: 0.8482 - accuracy: 0.7413\n",
      "Epoch 2/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.7022 - accuracy: 0.7908\n",
      "Epoch 3/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6736 - accuracy: 0.8005\n",
      "Epoch 4/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6580 - accuracy: 0.8051\n",
      "Epoch 5/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6488 - accuracy: 0.8078\n",
      "Epoch 6/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6422 - accuracy: 0.8095\n",
      "Epoch 7/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6376 - accuracy: 0.8106\n",
      "Epoch 8/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6345 - accuracy: 0.8111\n",
      "Epoch 9/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6307 - accuracy: 0.8122\n",
      "Epoch 10/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6277 - accuracy: 0.8130\n",
      "Epoch 11/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6251 - accuracy: 0.8135\n",
      "Epoch 12/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6228 - accuracy: 0.8139\n",
      "Epoch 13/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6194 - accuracy: 0.8143\n",
      "Epoch 14/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6177 - accuracy: 0.8144\n",
      "Epoch 15/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6160 - accuracy: 0.8154\n",
      "Epoch 16/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6139 - accuracy: 0.8159\n",
      "Epoch 17/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6124 - accuracy: 0.8160\n",
      "Epoch 18/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6111 - accuracy: 0.8162\n",
      "Epoch 19/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6096 - accuracy: 0.8173\n",
      "Epoch 20/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6091 - accuracy: 0.8172\n",
      "Epoch 21/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6079 - accuracy: 0.8173\n",
      "Epoch 22/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6064 - accuracy: 0.8175\n",
      "Epoch 23/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6050 - accuracy: 0.8182\n",
      "Epoch 24/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6039 - accuracy: 0.8176\n",
      "Epoch 25/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6026 - accuracy: 0.8188\n",
      "Epoch 26/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6015 - accuracy: 0.8193\n",
      "Epoch 27/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6016 - accuracy: 0.8187\n",
      "Epoch 28/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6012 - accuracy: 0.8186\n",
      "Epoch 29/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.6005 - accuracy: 0.8193\n",
      "Epoch 30/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.5993 - accuracy: 0.8191\n",
      "Epoch 31/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.5987 - accuracy: 0.8192\n",
      "Epoch 32/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.5984 - accuracy: 0.8194\n",
      "Epoch 33/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.5981 - accuracy: 0.8192\n",
      "Epoch 34/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.5974 - accuracy: 0.8197\n",
      "Epoch 35/35\n",
      "5014/5014 [==============================] - 25s 5ms/step - loss: 0.5958 - accuracy: 0.8198\n",
      "Best Results with Grid Search:\n",
      "0.8227301765374966\n",
      "{'No_Of_layers': 0}\n"
     ]
    }
   ],
   "source": [
    "#Layers Tuning for Dense Layer\n",
    "\n",
    "def create_model(No_Of_layers):\n",
    "    model = Sequential()\n",
    "    # Add an input layer\n",
    "    model.add(LSTM(units=60, input_shape=(1, 11), return_sequences = True, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=60, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    for i in range(No_Of_layers):\n",
    "        model.add(Dense(units=60, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "    # Add an output layer \n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    #compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1, epochs = 35, batch_size = 64)\n",
    "\n",
    "parameters = {\n",
    "    #'unit': [95],\n",
    "    'No_Of_layers': [0,1,2,3,4,5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_L, y_train_L)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c11666e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xaxis_layers = [0,1,2,3,4,5]\n",
    "plt.plot(xaxis_layers,means,'.-')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Dense Layers')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"Figures/No.OfLayers_Dense.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94090b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perceptron Tuning for Dense Layer\n",
    "\n",
    "def create_model(unit):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=60, input_shape=(1, 11), return_sequences = True, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=60, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0, epochs = 35, batch_size = 64)\n",
    "\n",
    "parameters = {\n",
    "    'unit': [10,20,30,40,50,60,70,80,90,100],\n",
    "    #'activation': ['relu','tanh'], \n",
    "    #'solver': ['adam','sgd'], \n",
    "    #'last_act': ['sigmoid','softmax'],\n",
    "    #'epochs': [70,100],\n",
    "    #'batch_size': [5,10] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_L, y_train_L)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis_perceptrons = [10,20,30,40,50,60,70,80,90,100]\n",
    "plt.plot(xaxis_perceptrons,means,'.-')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Perceptrons in Dense layer')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"Figures/No.OfPerceptron_Dense.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48057b1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f190806\\AppData\\Local\\Temp\\2\\ipykernel_7160\\1102260081.py:14: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=0, batch_size = 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Best Results with Grid Search:\n",
      "0.8274887424235343\n",
      "{'epochs': 80}\n"
     ]
    }
   ],
   "source": [
    "#Epochs Tuning\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=60, input_shape=(1, 11), return_sequences = True, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=60, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    #compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0, batch_size = 64)\n",
    "\n",
    "parameters = {\n",
    "    #'unit': [95],\n",
    "    'epochs': [30,40,50,60,70,80]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_L, y_train_L)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea900c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xaxis_epochs = [30,40,50,60,70,80]\n",
    "plt.plot(xaxis_epochs,means,'.-')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"Figures/No.OfEpochs_LSTM.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf654815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f190806\\AppData\\Local\\Temp\\2\\ipykernel_7160\\2794914093.py:14: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=0, epochs = 80)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Best Results with Grid Search:\n",
      "0.8288692562987894\n",
      "{'batch_size': 30}\n"
     ]
    }
   ],
   "source": [
    "#Batch Size Tuning\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=60, input_shape=(1, 11), return_sequences = True, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=60, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    #compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0, epochs = 80)\n",
    "\n",
    "parameters = {\n",
    "    #'unit': [95],\n",
    "    'batch_size': [30,40,50,60,70,80]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_L, y_train_L)\n",
    "\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a67c755b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xaxis_batch = [30,40,50,60,70,80]\n",
    "plt.plot(xaxis_batch,means,'.-')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Batch SIze')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"Figures/No.OfBatch_LSTM.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0d19fc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f190806\\AppData\\Local\\Temp\\2\\ipykernel_7160\\3782331227.py:13: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Best Results with Grid Search:\n",
      "0.8341077299428162\n",
      "{'activation': 'tanh', 'batch_size': 80, 'dropout': 0.1, 'epochs': 100, 'solver': 'adam', 'unit': 80}\n",
      "2507/2507 [==============================] - 5s 2ms/step\n",
      "\n",
      "Accuracy Score  on test data: 0.8302627642600718\n",
      "[[ 2410    62   318  4154    99    39     6    10]\n",
      " [   75  3788    49   463   418   216    16     7]\n",
      " [  902    60  4525   619   775    36     4     9]\n",
      " [  450   291   442 46705   638   218    54    98]\n",
      " [   73   356   458   704  5374    59     8     9]\n",
      " [   21   348    32   296    55  2392     1     9]\n",
      " [   11    11     7    74     7     2   657    28]\n",
      " [    7    19    13   133    17   223   108   756]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.34      0.44      7098\n",
      "           1       0.77      0.75      0.76      5032\n",
      "           2       0.77      0.65      0.71      6930\n",
      "           3       0.88      0.96      0.92     48896\n",
      "           4       0.73      0.76      0.75      7041\n",
      "           5       0.75      0.76      0.75      3154\n",
      "           6       0.77      0.82      0.80       797\n",
      "           7       0.82      0.59      0.69      1276\n",
      "\n",
      "    accuracy                           0.83     80224\n",
      "   macro avg       0.76      0.70      0.73     80224\n",
      "weighted avg       0.82      0.83      0.82     80224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tuning with Grid Seaerch CV\n",
    "\n",
    "def create_model(unit, solver, dropout, activation):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=unit, input_shape=(1, 11), return_sequences = True, activation=activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(units=unit, activation=activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=solver, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "parameters = {\n",
    "    'unit': [60,80],\n",
    "    'dropout': [0.1,0.2],\n",
    "    'activation': ['relu','tanh'], \n",
    "    #'solver': ['adam','sgd'], \n",
    "    'solver': ['adam','Adamax','Nadam'],\n",
    "    'epochs': [80,100],\n",
    "    'batch_size': [80,100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_L, y_train_L)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test_L)\n",
    "\n",
    "print('\\nAccuracy Score  on test data: ' + str(accuracy_score(y_test_L, y_pred)))\n",
    "print(confusion_matrix(y_test_L,y_pred))\n",
    "print(classification_report(y_test_L,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9dce468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Results with Grid Search:\n",
      "0.8341077299428162\n",
      "{'activation': 'tanh', 'batch_size': 80, 'dropout': 0.1, 'epochs': 100, 'solver': 'adam', 'unit': 80}\n",
      "2507/2507 [==============================] - 4s 2ms/step\n",
      "\n",
      "Accuracy Score  on test data: 0.8302627642600718\n",
      "[[ 2410    62   318  4154    99    39     6    10]\n",
      " [   75  3788    49   463   418   216    16     7]\n",
      " [  902    60  4525   619   775    36     4     9]\n",
      " [  450   291   442 46705   638   218    54    98]\n",
      " [   73   356   458   704  5374    59     8     9]\n",
      " [   21   348    32   296    55  2392     1     9]\n",
      " [   11    11     7    74     7     2   657    28]\n",
      " [    7    19    13   133    17   223   108   756]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.34      0.44      7098\n",
      "           1       0.77      0.75      0.76      5032\n",
      "           2       0.77      0.65      0.71      6930\n",
      "           3       0.88      0.96      0.92     48896\n",
      "           4       0.73      0.76      0.75      7041\n",
      "           5       0.75      0.76      0.75      3154\n",
      "           6       0.77      0.82      0.80       797\n",
      "           7       0.82      0.59      0.69      1276\n",
      "\n",
      "    accuracy                           0.83     80224\n",
      "   macro avg       0.76      0.70      0.73     80224\n",
      "weighted avg       0.82      0.83      0.82     80224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test_L)\n",
    "\n",
    "print('\\nAccuracy Score  on test data: ' + str(accuracy_score(y_test_L, y_pred)))\n",
    "print(confusion_matrix(y_test_L,y_pred))\n",
    "print(classification_report(y_test_L,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed23ca58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6bc92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fde6eea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4012/4012 - 21s - loss: 0.7663 - accuracy: 0.7686 - val_loss: 0.6563 - val_accuracy: 0.7981 - 21s/epoch - 5ms/step\n",
      "Epoch 2/100\n",
      "4012/4012 - 15s - loss: 0.6549 - accuracy: 0.8027 - val_loss: 0.6320 - val_accuracy: 0.8102 - 15s/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "4012/4012 - 15s - loss: 0.6380 - accuracy: 0.8081 - val_loss: 0.6238 - val_accuracy: 0.8112 - 15s/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "4012/4012 - 15s - loss: 0.6295 - accuracy: 0.8107 - val_loss: 0.6182 - val_accuracy: 0.8089 - 15s/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "4012/4012 - 15s - loss: 0.6237 - accuracy: 0.8124 - val_loss: 0.6077 - val_accuracy: 0.8161 - 15s/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "4012/4012 - 15s - loss: 0.6170 - accuracy: 0.8138 - val_loss: 0.6007 - val_accuracy: 0.8171 - 15s/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "4012/4012 - 15s - loss: 0.6111 - accuracy: 0.8147 - val_loss: 0.5967 - val_accuracy: 0.8175 - 15s/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "4012/4012 - 15s - loss: 0.6058 - accuracy: 0.8160 - val_loss: 0.5990 - val_accuracy: 0.8147 - 15s/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "4012/4012 - 15s - loss: 0.6023 - accuracy: 0.8168 - val_loss: 0.5879 - val_accuracy: 0.8189 - 15s/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "4012/4012 - 15s - loss: 0.5984 - accuracy: 0.8172 - val_loss: 0.5860 - val_accuracy: 0.8193 - 15s/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "4012/4012 - 15s - loss: 0.5939 - accuracy: 0.8178 - val_loss: 0.5820 - val_accuracy: 0.8171 - 15s/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "4012/4012 - 15s - loss: 0.5905 - accuracy: 0.8184 - val_loss: 0.5869 - val_accuracy: 0.8176 - 15s/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "4012/4012 - 15s - loss: 0.5869 - accuracy: 0.8193 - val_loss: 0.5775 - val_accuracy: 0.8203 - 15s/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "4012/4012 - 15s - loss: 0.5844 - accuracy: 0.8205 - val_loss: 0.5717 - val_accuracy: 0.8219 - 15s/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "4012/4012 - 15s - loss: 0.5831 - accuracy: 0.8212 - val_loss: 0.5786 - val_accuracy: 0.8208 - 15s/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "4012/4012 - 15s - loss: 0.5807 - accuracy: 0.8218 - val_loss: 0.5702 - val_accuracy: 0.8218 - 15s/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "4012/4012 - 15s - loss: 0.5795 - accuracy: 0.8217 - val_loss: 0.5693 - val_accuracy: 0.8220 - 15s/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "4012/4012 - 15s - loss: 0.5774 - accuracy: 0.8222 - val_loss: 0.5661 - val_accuracy: 0.8226 - 15s/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "4012/4012 - 15s - loss: 0.5761 - accuracy: 0.8230 - val_loss: 0.5642 - val_accuracy: 0.8250 - 15s/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "4012/4012 - 15s - loss: 0.5749 - accuracy: 0.8227 - val_loss: 0.5628 - val_accuracy: 0.8258 - 15s/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "4012/4012 - 15s - loss: 0.5736 - accuracy: 0.8235 - val_loss: 0.5626 - val_accuracy: 0.8229 - 15s/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "4012/4012 - 15s - loss: 0.5718 - accuracy: 0.8242 - val_loss: 0.5596 - val_accuracy: 0.8250 - 15s/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "4012/4012 - 15s - loss: 0.5713 - accuracy: 0.8237 - val_loss: 0.5618 - val_accuracy: 0.8256 - 15s/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "4012/4012 - 15s - loss: 0.5693 - accuracy: 0.8248 - val_loss: 0.5616 - val_accuracy: 0.8244 - 15s/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "4012/4012 - 15s - loss: 0.5690 - accuracy: 0.8247 - val_loss: 0.5596 - val_accuracy: 0.8285 - 15s/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "4012/4012 - 15s - loss: 0.5666 - accuracy: 0.8253 - val_loss: 0.5596 - val_accuracy: 0.8266 - 15s/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "4012/4012 - 15s - loss: 0.5660 - accuracy: 0.8259 - val_loss: 0.5538 - val_accuracy: 0.8273 - 15s/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "4012/4012 - 15s - loss: 0.5643 - accuracy: 0.8258 - val_loss: 0.5533 - val_accuracy: 0.8279 - 15s/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "4012/4012 - 15s - loss: 0.5627 - accuracy: 0.8263 - val_loss: 0.5504 - val_accuracy: 0.8285 - 15s/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "4012/4012 - 15s - loss: 0.5610 - accuracy: 0.8267 - val_loss: 0.5503 - val_accuracy: 0.8295 - 15s/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "4012/4012 - 15s - loss: 0.5602 - accuracy: 0.8268 - val_loss: 0.5497 - val_accuracy: 0.8291 - 15s/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "4012/4012 - 15s - loss: 0.5594 - accuracy: 0.8272 - val_loss: 0.5470 - val_accuracy: 0.8295 - 15s/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "4012/4012 - 15s - loss: 0.5582 - accuracy: 0.8275 - val_loss: 0.5493 - val_accuracy: 0.8280 - 15s/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "4012/4012 - 15s - loss: 0.5584 - accuracy: 0.8274 - val_loss: 0.5566 - val_accuracy: 0.8222 - 15s/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "4012/4012 - 15s - loss: 0.5572 - accuracy: 0.8275 - val_loss: 0.5551 - val_accuracy: 0.8293 - 15s/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "4012/4012 - 15s - loss: 0.5566 - accuracy: 0.8275 - val_loss: 0.5464 - val_accuracy: 0.8302 - 15s/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "4012/4012 - 15s - loss: 0.5559 - accuracy: 0.8281 - val_loss: 0.5459 - val_accuracy: 0.8293 - 15s/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "4012/4012 - 15s - loss: 0.5555 - accuracy: 0.8284 - val_loss: 0.5463 - val_accuracy: 0.8288 - 15s/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "4012/4012 - 15s - loss: 0.5551 - accuracy: 0.8277 - val_loss: 0.5419 - val_accuracy: 0.8310 - 15s/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "4012/4012 - 15s - loss: 0.5542 - accuracy: 0.8286 - val_loss: 0.5470 - val_accuracy: 0.8292 - 15s/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "4012/4012 - 15s - loss: 0.5541 - accuracy: 0.8285 - val_loss: 0.5431 - val_accuracy: 0.8302 - 15s/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "4012/4012 - 15s - loss: 0.5532 - accuracy: 0.8286 - val_loss: 0.5421 - val_accuracy: 0.8299 - 15s/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "4012/4012 - 15s - loss: 0.5530 - accuracy: 0.8285 - val_loss: 0.5473 - val_accuracy: 0.8295 - 15s/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "4012/4012 - 15s - loss: 0.5527 - accuracy: 0.8284 - val_loss: 0.5451 - val_accuracy: 0.8298 - 15s/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "4012/4012 - 15s - loss: 0.5518 - accuracy: 0.8291 - val_loss: 0.5432 - val_accuracy: 0.8297 - 15s/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "4012/4012 - 15s - loss: 0.5516 - accuracy: 0.8293 - val_loss: 0.5419 - val_accuracy: 0.8301 - 15s/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "4012/4012 - 15s - loss: 0.5515 - accuracy: 0.8289 - val_loss: 0.5421 - val_accuracy: 0.8310 - 15s/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "4012/4012 - 15s - loss: 0.5505 - accuracy: 0.8290 - val_loss: 0.5440 - val_accuracy: 0.8302 - 15s/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "4012/4012 - 15s - loss: 0.5509 - accuracy: 0.8287 - val_loss: 0.5423 - val_accuracy: 0.8314 - 15s/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "4012/4012 - 15s - loss: 0.5502 - accuracy: 0.8290 - val_loss: 0.5408 - val_accuracy: 0.8319 - 15s/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "4012/4012 - 15s - loss: 0.5507 - accuracy: 0.8290 - val_loss: 0.5427 - val_accuracy: 0.8316 - 15s/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "4012/4012 - 15s - loss: 0.5497 - accuracy: 0.8296 - val_loss: 0.5396 - val_accuracy: 0.8312 - 15s/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "4012/4012 - 15s - loss: 0.5493 - accuracy: 0.8298 - val_loss: 0.5415 - val_accuracy: 0.8306 - 15s/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "4012/4012 - 15s - loss: 0.5496 - accuracy: 0.8294 - val_loss: 0.5391 - val_accuracy: 0.8319 - 15s/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "4012/4012 - 15s - loss: 0.5489 - accuracy: 0.8296 - val_loss: 0.5403 - val_accuracy: 0.8310 - 15s/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "4012/4012 - 15s - loss: 0.5484 - accuracy: 0.8294 - val_loss: 0.5396 - val_accuracy: 0.8308 - 15s/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "4012/4012 - 15s - loss: 0.5488 - accuracy: 0.8296 - val_loss: 0.5386 - val_accuracy: 0.8322 - 15s/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "4012/4012 - 15s - loss: 0.5480 - accuracy: 0.8299 - val_loss: 0.5410 - val_accuracy: 0.8305 - 15s/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "4012/4012 - 15s - loss: 0.5481 - accuracy: 0.8301 - val_loss: 0.5406 - val_accuracy: 0.8302 - 15s/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "4012/4012 - 15s - loss: 0.5472 - accuracy: 0.8304 - val_loss: 0.5410 - val_accuracy: 0.8281 - 15s/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "4012/4012 - 15s - loss: 0.5475 - accuracy: 0.8297 - val_loss: 0.5369 - val_accuracy: 0.8327 - 15s/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "4012/4012 - 15s - loss: 0.5478 - accuracy: 0.8303 - val_loss: 0.5364 - val_accuracy: 0.8317 - 15s/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "4012/4012 - 15s - loss: 0.5480 - accuracy: 0.8298 - val_loss: 0.5381 - val_accuracy: 0.8316 - 15s/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "4012/4012 - 15s - loss: 0.5470 - accuracy: 0.8300 - val_loss: 0.5366 - val_accuracy: 0.8322 - 15s/epoch - 4ms/step\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4012/4012 - 15s - loss: 0.5476 - accuracy: 0.8304 - val_loss: 0.5361 - val_accuracy: 0.8315 - 15s/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "4012/4012 - 15s - loss: 0.5470 - accuracy: 0.8300 - val_loss: 0.5380 - val_accuracy: 0.8331 - 15s/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "4012/4012 - 15s - loss: 0.5457 - accuracy: 0.8302 - val_loss: 0.5372 - val_accuracy: 0.8324 - 15s/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "4012/4012 - 15s - loss: 0.5463 - accuracy: 0.8304 - val_loss: 0.5390 - val_accuracy: 0.8314 - 15s/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "4012/4012 - 15s - loss: 0.5467 - accuracy: 0.8300 - val_loss: 0.5407 - val_accuracy: 0.8308 - 15s/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "4012/4012 - 15s - loss: 0.5460 - accuracy: 0.8302 - val_loss: 0.5405 - val_accuracy: 0.8317 - 15s/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "4012/4012 - 15s - loss: 0.5456 - accuracy: 0.8305 - val_loss: 0.5359 - val_accuracy: 0.8334 - 15s/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "4012/4012 - 15s - loss: 0.5452 - accuracy: 0.8304 - val_loss: 0.5393 - val_accuracy: 0.8314 - 15s/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "4012/4012 - 15s - loss: 0.5456 - accuracy: 0.8302 - val_loss: 0.5385 - val_accuracy: 0.8321 - 15s/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "4012/4012 - 15s - loss: 0.5455 - accuracy: 0.8306 - val_loss: 0.5354 - val_accuracy: 0.8326 - 15s/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "4012/4012 - 15s - loss: 0.5450 - accuracy: 0.8306 - val_loss: 0.5365 - val_accuracy: 0.8319 - 15s/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "4012/4012 - 15s - loss: 0.5449 - accuracy: 0.8302 - val_loss: 0.5365 - val_accuracy: 0.8329 - 15s/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "4012/4012 - 15s - loss: 0.5445 - accuracy: 0.8308 - val_loss: 0.5338 - val_accuracy: 0.8330 - 15s/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "4012/4012 - 15s - loss: 0.5450 - accuracy: 0.8304 - val_loss: 0.5344 - val_accuracy: 0.8323 - 15s/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "4012/4012 - 15s - loss: 0.5443 - accuracy: 0.8309 - val_loss: 0.5396 - val_accuracy: 0.8318 - 15s/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "4012/4012 - 15s - loss: 0.5438 - accuracy: 0.8307 - val_loss: 0.5356 - val_accuracy: 0.8333 - 15s/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "4012/4012 - 15s - loss: 0.5444 - accuracy: 0.8305 - val_loss: 0.5360 - val_accuracy: 0.8324 - 15s/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "4012/4012 - 15s - loss: 0.5445 - accuracy: 0.8306 - val_loss: 0.5374 - val_accuracy: 0.8320 - 15s/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "4012/4012 - 15s - loss: 0.5443 - accuracy: 0.8305 - val_loss: 0.5379 - val_accuracy: 0.8324 - 15s/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "4012/4012 - 14s - loss: 0.5438 - accuracy: 0.8304 - val_loss: 0.5347 - val_accuracy: 0.8329 - 14s/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "4012/4012 - 15s - loss: 0.5433 - accuracy: 0.8310 - val_loss: 0.5333 - val_accuracy: 0.8325 - 15s/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "4012/4012 - 15s - loss: 0.5436 - accuracy: 0.8309 - val_loss: 0.5381 - val_accuracy: 0.8324 - 15s/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "4012/4012 - 15s - loss: 0.5430 - accuracy: 0.8308 - val_loss: 0.5347 - val_accuracy: 0.8324 - 15s/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "4012/4012 - 15s - loss: 0.5435 - accuracy: 0.8309 - val_loss: 0.5321 - val_accuracy: 0.8335 - 15s/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "4012/4012 - 15s - loss: 0.5429 - accuracy: 0.8307 - val_loss: 0.5362 - val_accuracy: 0.8314 - 15s/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "4012/4012 - 15s - loss: 0.5428 - accuracy: 0.8311 - val_loss: 0.5336 - val_accuracy: 0.8321 - 15s/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "4012/4012 - 15s - loss: 0.5429 - accuracy: 0.8313 - val_loss: 0.5341 - val_accuracy: 0.8332 - 15s/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "4012/4012 - 15s - loss: 0.5429 - accuracy: 0.8311 - val_loss: 0.5423 - val_accuracy: 0.8269 - 15s/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "4012/4012 - 15s - loss: 0.5426 - accuracy: 0.8309 - val_loss: 0.5340 - val_accuracy: 0.8336 - 15s/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "4012/4012 - 15s - loss: 0.5428 - accuracy: 0.8317 - val_loss: 0.5329 - val_accuracy: 0.8327 - 15s/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "4012/4012 - 15s - loss: 0.5427 - accuracy: 0.8314 - val_loss: 0.5343 - val_accuracy: 0.8331 - 15s/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "4012/4012 - 15s - loss: 0.5423 - accuracy: 0.8309 - val_loss: 0.5344 - val_accuracy: 0.8336 - 15s/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "4012/4012 - 15s - loss: 0.5420 - accuracy: 0.8310 - val_loss: 0.5350 - val_accuracy: 0.8306 - 15s/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "4012/4012 - 15s - loss: 0.5419 - accuracy: 0.8316 - val_loss: 0.5317 - val_accuracy: 0.8334 - 15s/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "4012/4012 - 15s - loss: 0.5416 - accuracy: 0.8315 - val_loss: 0.5345 - val_accuracy: 0.8329 - 15s/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "4012/4012 - 15s - loss: 0.5409 - accuracy: 0.8315 - val_loss: 0.5360 - val_accuracy: 0.8328 - 15s/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29ac346bac0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 LSTM Layer (input), 3 Dense Hidden Layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=80, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(units=80, activation='tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_L, y_train_L, epochs=100, batch_size=80, verbose=2, validation_data=(X_test_L, y_test_L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3c29e6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2507/2507 [==============================] - 6s 2ms/step - loss: 0.5360 - accuracy: 0.8328\n",
      "Loss:0.5359705686569214\n",
      "Accuracy:0.8327931761741638\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_L, y_test_L)\n",
    "print(\"Loss:\" + str(loss))\n",
    "print(\"Accuracy:\" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eed95b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_327\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_654 (LSTM)             (None, 1, 80)             29440     \n",
      "                                                                 \n",
      " dropout_654 (Dropout)       (None, 1, 80)             0         \n",
      "                                                                 \n",
      " lstm_655 (LSTM)             (None, 80)                51520     \n",
      "                                                                 \n",
      " dropout_655 (Dropout)       (None, 80)                0         \n",
      "                                                                 \n",
      " dense_327 (Dense)           (None, 8)                 648       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,608\n",
      "Trainable params: 81,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3389d5d0",
   "metadata": {},
   "source": [
    "### Conv-LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c2ea1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM training (label encoder + shape)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(trainY)\n",
    "y_train_L = encoder.transform(trainY) #for sparse_categorical\n",
    "X_train_L = trainX.reshape((-1, 1, trainX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d2d0314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM testing (label encoder + shape)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(testY)\n",
    "y_test_L = encoder.transform(testY) #for sparse_categorical\n",
    "X_test_L = testX.reshape((-1, 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db1a9b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320895, 1, 11)\n",
      "(320895,)\n",
      "(80224, 1, 11)\n",
      "(80224,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_L.shape)\n",
    "print(y_train_L.shape)\n",
    "print(X_test_L.shape)\n",
    "print(y_test_L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ace6c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e134578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1 = X_M.reshape((-1, 1, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c898896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69b08090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0334f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(y)\n",
    "# y_E = encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95314306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "593d3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (trainX, testX, trainY, testY) = train_test_split(X1, y_E, test_size = 0.20, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2a9ed92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f190806\\AppData\\Local\\Temp\\2\\ipykernel_7160\\893372933.py:14: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=2, epochs = 100, batch_size = 80)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 - 11s - loss: 0.7949 - accuracy: 0.7579 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6762 - accuracy: 0.7966 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6557 - accuracy: 0.8030 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6443 - accuracy: 0.8071 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6363 - accuracy: 0.8095 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6306 - accuracy: 0.8108 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6244 - accuracy: 0.8120 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6191 - accuracy: 0.8136 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6158 - accuracy: 0.8141 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6126 - accuracy: 0.8144 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6092 - accuracy: 0.8148 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6060 - accuracy: 0.8148 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.6029 - accuracy: 0.8162 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 7s - loss: 0.6017 - accuracy: 0.8169 - 7s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 7s - loss: 0.5978 - accuracy: 0.8187 - 7s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5964 - accuracy: 0.8191 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 7s - loss: 0.5953 - accuracy: 0.8190 - 7s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5935 - accuracy: 0.8195 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 7s - loss: 0.5911 - accuracy: 0.8200 - 7s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5899 - accuracy: 0.8203 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5895 - accuracy: 0.8205 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5870 - accuracy: 0.8210 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5870 - accuracy: 0.8205 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5864 - accuracy: 0.8209 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5860 - accuracy: 0.8210 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5834 - accuracy: 0.8220 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5838 - accuracy: 0.8216 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5826 - accuracy: 0.8220 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5824 - accuracy: 0.8222 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5813 - accuracy: 0.8221 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 7s - loss: 0.5807 - accuracy: 0.8226 - 7s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5799 - accuracy: 0.8228 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5794 - accuracy: 0.8227 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5797 - accuracy: 0.8225 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5786 - accuracy: 0.8230 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5781 - accuracy: 0.8228 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5770 - accuracy: 0.8233 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5771 - accuracy: 0.8224 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5772 - accuracy: 0.8229 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5770 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5760 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5760 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5752 - accuracy: 0.8236 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 7s - loss: 0.5744 - accuracy: 0.8238 - 7s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5742 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5741 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5731 - accuracy: 0.8238 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5724 - accuracy: 0.8244 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5721 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5719 - accuracy: 0.8238 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5700 - accuracy: 0.8250 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5703 - accuracy: 0.8244 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5692 - accuracy: 0.8246 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5691 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5683 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5675 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5670 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5666 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5661 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5665 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5662 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5657 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5659 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5642 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5648 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5646 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5643 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5641 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5632 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5629 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5636 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5630 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5630 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5633 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5630 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5622 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5623 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5620 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5616 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5620 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5608 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5601 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5594 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5596 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 11s - loss: 0.7927 - accuracy: 0.7581 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6742 - accuracy: 0.7962 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6539 - accuracy: 0.8028 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6423 - accuracy: 0.8063 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6331 - accuracy: 0.8095 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6272 - accuracy: 0.8112 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6228 - accuracy: 0.8120 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6174 - accuracy: 0.8131 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6130 - accuracy: 0.8139 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6111 - accuracy: 0.8137 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6088 - accuracy: 0.8151 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6065 - accuracy: 0.8149 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.6040 - accuracy: 0.8163 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.6014 - accuracy: 0.8160 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.6006 - accuracy: 0.8167 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5983 - accuracy: 0.8169 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5955 - accuracy: 0.8177 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5951 - accuracy: 0.8181 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5929 - accuracy: 0.8186 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5929 - accuracy: 0.8187 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5905 - accuracy: 0.8187 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5887 - accuracy: 0.8200 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5894 - accuracy: 0.8203 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5862 - accuracy: 0.8203 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5867 - accuracy: 0.8204 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5859 - accuracy: 0.8205 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5837 - accuracy: 0.8210 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5828 - accuracy: 0.8218 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5819 - accuracy: 0.8221 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5812 - accuracy: 0.8222 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5809 - accuracy: 0.8225 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5801 - accuracy: 0.8217 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5799 - accuracy: 0.8226 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5782 - accuracy: 0.8225 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5783 - accuracy: 0.8226 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5781 - accuracy: 0.8223 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5765 - accuracy: 0.8222 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5761 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5755 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5747 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5737 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5739 - accuracy: 0.8241 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5721 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5716 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5709 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5700 - accuracy: 0.8250 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5699 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5691 - accuracy: 0.8250 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5684 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5672 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5672 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5667 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5670 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5658 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5657 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5657 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5651 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 7s - loss: 0.5640 - accuracy: 0.8259 - 7s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 7s - loss: 0.5637 - accuracy: 0.8256 - 7s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5644 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5637 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5635 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5628 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5627 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5627 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5623 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5625 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5627 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5620 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5617 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5621 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5612 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5592 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5594 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5590 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5591 - accuracy: 0.8283 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5590 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5582 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5580 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5574 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5579 - accuracy: 0.8281 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5583 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5584 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5580 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5564 - accuracy: 0.8285 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 11s - loss: 0.7963 - accuracy: 0.7584 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6745 - accuracy: 0.7964 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6559 - accuracy: 0.8021 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6428 - accuracy: 0.8072 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6356 - accuracy: 0.8091 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6285 - accuracy: 0.8119 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6244 - accuracy: 0.8119 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6201 - accuracy: 0.8129 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6157 - accuracy: 0.8135 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6134 - accuracy: 0.8138 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6096 - accuracy: 0.8142 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6070 - accuracy: 0.8145 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.6054 - accuracy: 0.8159 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.6025 - accuracy: 0.8168 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.6003 - accuracy: 0.8174 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5987 - accuracy: 0.8174 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5962 - accuracy: 0.8181 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5944 - accuracy: 0.8188 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5932 - accuracy: 0.8183 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5915 - accuracy: 0.8196 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5911 - accuracy: 0.8193 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5890 - accuracy: 0.8201 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5885 - accuracy: 0.8201 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5873 - accuracy: 0.8200 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5862 - accuracy: 0.8205 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5849 - accuracy: 0.8213 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5847 - accuracy: 0.8212 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5837 - accuracy: 0.8209 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5832 - accuracy: 0.8217 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5826 - accuracy: 0.8214 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5824 - accuracy: 0.8213 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5812 - accuracy: 0.8220 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5814 - accuracy: 0.8216 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5797 - accuracy: 0.8222 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5792 - accuracy: 0.8224 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5791 - accuracy: 0.8220 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5788 - accuracy: 0.8222 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5776 - accuracy: 0.8229 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5779 - accuracy: 0.8224 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5756 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5760 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5748 - accuracy: 0.8228 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5747 - accuracy: 0.8236 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5748 - accuracy: 0.8233 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5744 - accuracy: 0.8238 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5742 - accuracy: 0.8239 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5734 - accuracy: 0.8240 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5737 - accuracy: 0.8233 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5720 - accuracy: 0.8241 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5717 - accuracy: 0.8246 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5707 - accuracy: 0.8244 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5714 - accuracy: 0.8241 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5707 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5704 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5695 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5693 - accuracy: 0.8244 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5688 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5681 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5678 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5675 - accuracy: 0.8250 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5680 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5665 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5662 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5659 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5663 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5664 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5658 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5647 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5652 - accuracy: 0.8246 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5648 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5645 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5647 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 7s - loss: 0.5647 - accuracy: 0.8255 - 7s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5635 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5633 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5637 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5642 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5622 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5633 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5629 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5629 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5620 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5623 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5622 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5619 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5619 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5622 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5621 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5612 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5601 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 10s - loss: 0.7770 - accuracy: 0.7647 - 10s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6689 - accuracy: 0.7982 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6504 - accuracy: 0.8050 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6394 - accuracy: 0.8085 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6324 - accuracy: 0.8094 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6254 - accuracy: 0.8114 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6222 - accuracy: 0.8121 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6172 - accuracy: 0.8135 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6142 - accuracy: 0.8143 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6104 - accuracy: 0.8146 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6078 - accuracy: 0.8151 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6037 - accuracy: 0.8160 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.6021 - accuracy: 0.8159 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.6003 - accuracy: 0.8172 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5982 - accuracy: 0.8169 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5967 - accuracy: 0.8176 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5947 - accuracy: 0.8177 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5926 - accuracy: 0.8192 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5917 - accuracy: 0.8196 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5904 - accuracy: 0.8192 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5898 - accuracy: 0.8196 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5882 - accuracy: 0.8199 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5877 - accuracy: 0.8205 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5871 - accuracy: 0.8202 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5858 - accuracy: 0.8204 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5847 - accuracy: 0.8205 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5840 - accuracy: 0.8214 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5829 - accuracy: 0.8218 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5824 - accuracy: 0.8217 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5818 - accuracy: 0.8216 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5805 - accuracy: 0.8221 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5803 - accuracy: 0.8219 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5799 - accuracy: 0.8221 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5793 - accuracy: 0.8223 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5783 - accuracy: 0.8230 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5774 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5775 - accuracy: 0.8228 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5770 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5764 - accuracy: 0.8229 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5768 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5760 - accuracy: 0.8227 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5743 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5750 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5749 - accuracy: 0.8232 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5747 - accuracy: 0.8233 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5732 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5729 - accuracy: 0.8236 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5728 - accuracy: 0.8236 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5717 - accuracy: 0.8236 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5714 - accuracy: 0.8243 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5703 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5702 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5706 - accuracy: 0.8244 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5692 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5683 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5685 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5676 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5669 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5678 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5665 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5664 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5665 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5664 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5666 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5662 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5652 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5648 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5641 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5642 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5646 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5651 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5638 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5639 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5631 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5636 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5637 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5633 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5627 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5632 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5629 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5627 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5630 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5615 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5621 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5621 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5619 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 7s - loss: 0.5613 - accuracy: 0.8270 - 7s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 7s - loss: 0.5615 - accuracy: 0.8276 - 7s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5619 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5615 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5604 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5602 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 11s - loss: 0.7752 - accuracy: 0.7645 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6653 - accuracy: 0.7994 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6462 - accuracy: 0.8057 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6368 - accuracy: 0.8086 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6294 - accuracy: 0.8104 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6242 - accuracy: 0.8116 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6203 - accuracy: 0.8127 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6158 - accuracy: 0.8132 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6130 - accuracy: 0.8138 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6086 - accuracy: 0.8148 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6067 - accuracy: 0.8154 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6044 - accuracy: 0.8155 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.6023 - accuracy: 0.8163 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5998 - accuracy: 0.8170 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5988 - accuracy: 0.8170 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5965 - accuracy: 0.8175 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5948 - accuracy: 0.8179 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5933 - accuracy: 0.8188 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5919 - accuracy: 0.8189 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5896 - accuracy: 0.8199 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5889 - accuracy: 0.8200 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5867 - accuracy: 0.8197 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5854 - accuracy: 0.8207 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5845 - accuracy: 0.8209 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5832 - accuracy: 0.8213 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5826 - accuracy: 0.8217 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5831 - accuracy: 0.8217 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5818 - accuracy: 0.8219 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5805 - accuracy: 0.8220 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5788 - accuracy: 0.8224 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5782 - accuracy: 0.8230 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5783 - accuracy: 0.8222 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5776 - accuracy: 0.8227 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5769 - accuracy: 0.8226 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5754 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5758 - accuracy: 0.8227 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5738 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5749 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5738 - accuracy: 0.8237 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5731 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5722 - accuracy: 0.8237 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5715 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5701 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5702 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5701 - accuracy: 0.8243 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5693 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5694 - accuracy: 0.8239 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5690 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5685 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5678 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5675 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5673 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5662 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5651 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5648 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5652 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5647 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5644 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5643 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5640 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5632 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5634 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5620 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5623 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5615 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5604 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5594 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5596 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5589 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5582 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5591 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5586 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5584 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5591 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5578 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5584 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5575 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5574 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5580 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5573 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5570 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5563 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5565 - accuracy: 0.8285 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5566 - accuracy: 0.8280 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5574 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5566 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5562 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5570 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5558 - accuracy: 0.8282 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5565 - accuracy: 0.8280 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 10s - loss: 0.7867 - accuracy: 0.7601 - 10s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 7s - loss: 0.6722 - accuracy: 0.7969 - 7s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6533 - accuracy: 0.8035 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6419 - accuracy: 0.8070 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6340 - accuracy: 0.8101 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6274 - accuracy: 0.8112 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6224 - accuracy: 0.8126 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6191 - accuracy: 0.8132 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6154 - accuracy: 0.8143 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6128 - accuracy: 0.8144 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6097 - accuracy: 0.8146 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6064 - accuracy: 0.8158 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.6038 - accuracy: 0.8169 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.6020 - accuracy: 0.8167 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5998 - accuracy: 0.8174 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5976 - accuracy: 0.8180 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5961 - accuracy: 0.8186 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5940 - accuracy: 0.8189 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5919 - accuracy: 0.8198 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5895 - accuracy: 0.8204 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5882 - accuracy: 0.8205 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5875 - accuracy: 0.8210 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5855 - accuracy: 0.8210 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5837 - accuracy: 0.8220 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5829 - accuracy: 0.8214 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5821 - accuracy: 0.8219 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5812 - accuracy: 0.8222 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5794 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5776 - accuracy: 0.8230 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5774 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5769 - accuracy: 0.8232 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5750 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5746 - accuracy: 0.8237 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5742 - accuracy: 0.8244 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5730 - accuracy: 0.8244 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5729 - accuracy: 0.8241 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5719 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5719 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5704 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5705 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5687 - accuracy: 0.8250 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5691 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5683 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5686 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5680 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5684 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5665 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5668 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5661 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5655 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5657 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5660 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5662 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5646 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5647 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5644 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5638 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5625 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5642 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5637 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5633 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5633 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5627 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5615 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5615 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5622 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5620 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5612 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5612 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5601 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5591 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5591 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5589 - accuracy: 0.8280 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5583 - accuracy: 0.8282 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8281 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5584 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5582 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5586 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5585 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5585 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5572 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5578 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5584 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5576 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5568 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5571 - accuracy: 0.8280 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5572 - accuracy: 0.8282 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 11s - loss: 0.7731 - accuracy: 0.7652 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6659 - accuracy: 0.7997 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6481 - accuracy: 0.8056 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6377 - accuracy: 0.8087 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6314 - accuracy: 0.8101 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6259 - accuracy: 0.8112 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6201 - accuracy: 0.8129 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6170 - accuracy: 0.8131 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6132 - accuracy: 0.8134 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6095 - accuracy: 0.8145 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6074 - accuracy: 0.8150 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6050 - accuracy: 0.8155 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.6024 - accuracy: 0.8158 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5992 - accuracy: 0.8167 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5975 - accuracy: 0.8175 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 7s - loss: 0.5964 - accuracy: 0.8181 - 7s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 7s - loss: 0.5945 - accuracy: 0.8179 - 7s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5928 - accuracy: 0.8188 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5916 - accuracy: 0.8188 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5902 - accuracy: 0.8193 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5901 - accuracy: 0.8187 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5888 - accuracy: 0.8200 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5870 - accuracy: 0.8203 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5868 - accuracy: 0.8199 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5856 - accuracy: 0.8205 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5851 - accuracy: 0.8213 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5852 - accuracy: 0.8206 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5836 - accuracy: 0.8210 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5834 - accuracy: 0.8215 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5821 - accuracy: 0.8215 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5816 - accuracy: 0.8209 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5816 - accuracy: 0.8215 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5807 - accuracy: 0.8218 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5807 - accuracy: 0.8220 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5795 - accuracy: 0.8230 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5776 - accuracy: 0.8233 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5782 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5777 - accuracy: 0.8221 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5776 - accuracy: 0.8224 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5762 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5764 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5753 - accuracy: 0.8227 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5746 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5735 - accuracy: 0.8238 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5733 - accuracy: 0.8244 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5719 - accuracy: 0.8244 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5724 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5707 - accuracy: 0.8243 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5712 - accuracy: 0.8240 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5704 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5689 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5699 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5690 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5683 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5689 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5680 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5677 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5675 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5662 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5670 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5657 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5670 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5655 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5661 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5649 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5661 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5652 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5645 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5652 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5645 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5637 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5641 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5632 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5634 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5641 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5636 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5621 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5636 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5632 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5629 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5631 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5628 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5619 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5616 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5628 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5612 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5626 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5615 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5596 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5597 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 10s - loss: 0.7693 - accuracy: 0.7657 - 10s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6649 - accuracy: 0.7995 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6475 - accuracy: 0.8050 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6359 - accuracy: 0.8102 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6284 - accuracy: 0.8111 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6231 - accuracy: 0.8124 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6187 - accuracy: 0.8139 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6150 - accuracy: 0.8146 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6105 - accuracy: 0.8157 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6091 - accuracy: 0.8158 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6052 - accuracy: 0.8160 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6035 - accuracy: 0.8168 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.6005 - accuracy: 0.8171 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5970 - accuracy: 0.8178 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5963 - accuracy: 0.8179 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5946 - accuracy: 0.8181 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5931 - accuracy: 0.8182 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5917 - accuracy: 0.8190 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5897 - accuracy: 0.8197 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5884 - accuracy: 0.8199 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5869 - accuracy: 0.8200 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5858 - accuracy: 0.8207 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5840 - accuracy: 0.8209 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5829 - accuracy: 0.8213 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5818 - accuracy: 0.8211 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5802 - accuracy: 0.8217 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5792 - accuracy: 0.8222 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5774 - accuracy: 0.8226 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5757 - accuracy: 0.8230 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 7s - loss: 0.5750 - accuracy: 0.8235 - 7s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 7s - loss: 0.5745 - accuracy: 0.8235 - 7s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5735 - accuracy: 0.8237 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5725 - accuracy: 0.8238 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5709 - accuracy: 0.8239 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5708 - accuracy: 0.8243 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5703 - accuracy: 0.8243 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5691 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5696 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5687 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5692 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5680 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5674 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5664 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5661 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5661 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5653 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5656 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5647 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5642 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5641 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5635 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5634 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5632 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5628 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5625 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5627 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5625 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5616 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5616 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5619 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5604 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5590 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5594 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5592 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5585 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5587 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5589 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5587 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5579 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5580 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5584 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5583 - accuracy: 0.8282 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5572 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5575 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5574 - accuracy: 0.8280 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5577 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5566 - accuracy: 0.8280 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5571 - accuracy: 0.8280 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5583 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5571 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5560 - accuracy: 0.8280 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5565 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5567 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5568 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5559 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5560 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5552 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5563 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5558 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 11s - loss: 0.7739 - accuracy: 0.7652 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6681 - accuracy: 0.7985 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6503 - accuracy: 0.8047 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6385 - accuracy: 0.8082 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6315 - accuracy: 0.8103 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6244 - accuracy: 0.8116 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6213 - accuracy: 0.8127 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6170 - accuracy: 0.8131 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6140 - accuracy: 0.8139 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6105 - accuracy: 0.8142 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6079 - accuracy: 0.8148 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6054 - accuracy: 0.8153 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.6023 - accuracy: 0.8167 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.6009 - accuracy: 0.8160 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5997 - accuracy: 0.8168 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5955 - accuracy: 0.8183 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5933 - accuracy: 0.8186 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5939 - accuracy: 0.8181 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5907 - accuracy: 0.8193 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5901 - accuracy: 0.8197 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5891 - accuracy: 0.8199 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5873 - accuracy: 0.8201 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5852 - accuracy: 0.8206 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5852 - accuracy: 0.8213 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5839 - accuracy: 0.8205 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5840 - accuracy: 0.8206 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5824 - accuracy: 0.8220 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5812 - accuracy: 0.8213 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5810 - accuracy: 0.8219 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5791 - accuracy: 0.8219 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5776 - accuracy: 0.8228 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5765 - accuracy: 0.8232 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5765 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5752 - accuracy: 0.8233 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5742 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5736 - accuracy: 0.8238 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5728 - accuracy: 0.8239 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5725 - accuracy: 0.8243 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5729 - accuracy: 0.8237 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5721 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5702 - accuracy: 0.8246 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5702 - accuracy: 0.8246 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5693 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5691 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 7s - loss: 0.5688 - accuracy: 0.8249 - 7s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 7s - loss: 0.5679 - accuracy: 0.8251 - 7s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5683 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5675 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5668 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5663 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5656 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5650 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5657 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5660 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5647 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5640 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5638 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5648 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5632 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5633 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5641 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5620 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5629 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5623 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5630 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5617 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5620 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5608 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5596 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5601 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5592 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5592 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5589 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5594 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5586 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5592 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5589 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5584 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5587 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5589 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5580 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5584 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 10s - loss: 0.7650 - accuracy: 0.7686 - 10s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6642 - accuracy: 0.8004 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6466 - accuracy: 0.8054 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6359 - accuracy: 0.8101 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6274 - accuracy: 0.8120 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6224 - accuracy: 0.8128 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6172 - accuracy: 0.8142 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6144 - accuracy: 0.8142 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6105 - accuracy: 0.8153 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6078 - accuracy: 0.8151 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6049 - accuracy: 0.8159 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6019 - accuracy: 0.8167 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.5996 - accuracy: 0.8169 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5976 - accuracy: 0.8175 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5950 - accuracy: 0.8180 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5923 - accuracy: 0.8194 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5918 - accuracy: 0.8193 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5910 - accuracy: 0.8194 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5891 - accuracy: 0.8197 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5881 - accuracy: 0.8203 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5866 - accuracy: 0.8210 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5857 - accuracy: 0.8207 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5851 - accuracy: 0.8207 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5839 - accuracy: 0.8213 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5835 - accuracy: 0.8218 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5813 - accuracy: 0.8224 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5802 - accuracy: 0.8223 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5790 - accuracy: 0.8230 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5792 - accuracy: 0.8223 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5777 - accuracy: 0.8227 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5767 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5757 - accuracy: 0.8233 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5753 - accuracy: 0.8241 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5739 - accuracy: 0.8233 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5738 - accuracy: 0.8241 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5725 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5717 - accuracy: 0.8236 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5712 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5714 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5713 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5701 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5700 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5697 - accuracy: 0.8250 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5691 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5694 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5698 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5681 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5684 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5669 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5683 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5678 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5683 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5673 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5656 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5657 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5648 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5656 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5653 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 7s - loss: 0.5653 - accuracy: 0.8260 - 7s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 7s - loss: 0.5647 - accuracy: 0.8260 - 7s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5650 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5645 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5646 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5645 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5637 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5646 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5635 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5626 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5633 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5633 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5629 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5625 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5620 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5638 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5619 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5617 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5616 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5622 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5612 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5601 - accuracy: 0.8280 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8280 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5601 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5602 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5589 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5590 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5590 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8281 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5579 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 11s - loss: 0.7574 - accuracy: 0.7698 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6603 - accuracy: 0.8017 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6440 - accuracy: 0.8072 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6339 - accuracy: 0.8102 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6269 - accuracy: 0.8121 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6222 - accuracy: 0.8132 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6171 - accuracy: 0.8137 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6138 - accuracy: 0.8139 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6115 - accuracy: 0.8149 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6076 - accuracy: 0.8159 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6042 - accuracy: 0.8160 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6021 - accuracy: 0.8166 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.5992 - accuracy: 0.8166 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5968 - accuracy: 0.8173 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5948 - accuracy: 0.8186 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5933 - accuracy: 0.8187 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5914 - accuracy: 0.8191 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5899 - accuracy: 0.8190 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5878 - accuracy: 0.8203 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5863 - accuracy: 0.8204 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5840 - accuracy: 0.8213 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5825 - accuracy: 0.8217 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5825 - accuracy: 0.8207 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5794 - accuracy: 0.8221 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5796 - accuracy: 0.8223 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5779 - accuracy: 0.8224 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5772 - accuracy: 0.8226 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5750 - accuracy: 0.8229 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5738 - accuracy: 0.8232 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5741 - accuracy: 0.8233 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5736 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5724 - accuracy: 0.8243 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5720 - accuracy: 0.8240 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5715 - accuracy: 0.8239 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5715 - accuracy: 0.8240 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5708 - accuracy: 0.8244 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5698 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5690 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5684 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5683 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5676 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5678 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5659 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5669 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5668 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5657 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5663 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5647 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5649 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5652 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5644 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5631 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5653 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5643 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5634 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5637 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5647 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5629 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5628 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5623 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5631 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5626 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5628 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5619 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5619 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5615 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5621 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5608 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 7s - loss: 0.5611 - accuracy: 0.8264 - 7s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5596 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5590 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5596 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5601 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5587 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5594 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5582 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5584 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5586 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5583 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5586 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5585 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5585 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5583 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5584 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5580 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5578 - accuracy: 0.8281 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5573 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 11s - loss: 0.7635 - accuracy: 0.7680 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6641 - accuracy: 0.7997 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6458 - accuracy: 0.8059 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6351 - accuracy: 0.8091 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6285 - accuracy: 0.8102 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6230 - accuracy: 0.8113 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6177 - accuracy: 0.8132 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6139 - accuracy: 0.8141 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6110 - accuracy: 0.8143 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6076 - accuracy: 0.8152 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6046 - accuracy: 0.8154 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6028 - accuracy: 0.8162 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.6002 - accuracy: 0.8168 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5978 - accuracy: 0.8171 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5937 - accuracy: 0.8175 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5928 - accuracy: 0.8183 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5912 - accuracy: 0.8192 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5890 - accuracy: 0.8197 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5878 - accuracy: 0.8203 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5845 - accuracy: 0.8209 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5835 - accuracy: 0.8216 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5830 - accuracy: 0.8213 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5813 - accuracy: 0.8219 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5793 - accuracy: 0.8224 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5788 - accuracy: 0.8228 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5779 - accuracy: 0.8229 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5757 - accuracy: 0.8233 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5752 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5742 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5733 - accuracy: 0.8233 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5731 - accuracy: 0.8239 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5722 - accuracy: 0.8244 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5716 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5693 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5688 - accuracy: 0.8246 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5689 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5686 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5688 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5684 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5684 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5675 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5661 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5666 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5670 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5660 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5652 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5651 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5652 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5632 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5644 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5638 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5631 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5630 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5637 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5619 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5623 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5627 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5608 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5597 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5597 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5591 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5594 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5592 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5580 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5592 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5586 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5587 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5577 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 7s - loss: 0.5577 - accuracy: 0.8275 - 7s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 7s - loss: 0.5579 - accuracy: 0.8274 - 7s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5569 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5571 - accuracy: 0.8281 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5580 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5575 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5575 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5577 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5577 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5570 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5569 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5567 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5564 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5572 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 11s - loss: 0.7616 - accuracy: 0.7690 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6628 - accuracy: 0.8019 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6450 - accuracy: 0.8071 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6350 - accuracy: 0.8100 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6278 - accuracy: 0.8122 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6226 - accuracy: 0.8122 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6187 - accuracy: 0.8134 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6147 - accuracy: 0.8141 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6132 - accuracy: 0.8144 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6093 - accuracy: 0.8154 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6079 - accuracy: 0.8153 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6051 - accuracy: 0.8158 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.6014 - accuracy: 0.8163 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5992 - accuracy: 0.8170 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5977 - accuracy: 0.8170 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5961 - accuracy: 0.8183 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5930 - accuracy: 0.8192 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5916 - accuracy: 0.8197 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5893 - accuracy: 0.8200 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5888 - accuracy: 0.8197 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5880 - accuracy: 0.8200 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5867 - accuracy: 0.8210 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5857 - accuracy: 0.8209 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5854 - accuracy: 0.8203 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5845 - accuracy: 0.8211 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5832 - accuracy: 0.8216 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5823 - accuracy: 0.8221 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5820 - accuracy: 0.8216 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5809 - accuracy: 0.8223 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5800 - accuracy: 0.8215 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5799 - accuracy: 0.8226 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5787 - accuracy: 0.8223 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5782 - accuracy: 0.8222 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5773 - accuracy: 0.8228 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5767 - accuracy: 0.8229 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5760 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5748 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5735 - accuracy: 0.8238 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5734 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5720 - accuracy: 0.8246 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5717 - accuracy: 0.8241 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5706 - accuracy: 0.8241 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5701 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5704 - accuracy: 0.8246 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5699 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5685 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5687 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5684 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5675 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5680 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5679 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5663 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5660 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5656 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5649 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5656 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5641 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5648 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5656 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5643 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5646 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5648 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5641 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5634 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5640 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5633 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5633 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5635 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5631 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5625 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5634 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5626 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5625 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5617 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5620 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5617 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5615 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5608 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5615 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5602 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5612 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5601 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 7s - loss: 0.5596 - accuracy: 0.8271 - 7s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 7s - loss: 0.5604 - accuracy: 0.8269 - 7s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 11s - loss: 0.7570 - accuracy: 0.7699 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6606 - accuracy: 0.8006 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6437 - accuracy: 0.8060 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6329 - accuracy: 0.8102 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6267 - accuracy: 0.8111 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6205 - accuracy: 0.8132 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6172 - accuracy: 0.8136 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6135 - accuracy: 0.8143 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6110 - accuracy: 0.8146 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6071 - accuracy: 0.8157 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6051 - accuracy: 0.8162 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6029 - accuracy: 0.8167 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.5995 - accuracy: 0.8171 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5957 - accuracy: 0.8178 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5946 - accuracy: 0.8181 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5915 - accuracy: 0.8186 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5901 - accuracy: 0.8186 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5878 - accuracy: 0.8196 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5857 - accuracy: 0.8202 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5846 - accuracy: 0.8206 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5838 - accuracy: 0.8211 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5838 - accuracy: 0.8207 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5819 - accuracy: 0.8208 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5806 - accuracy: 0.8212 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5794 - accuracy: 0.8216 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5792 - accuracy: 0.8217 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5773 - accuracy: 0.8222 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5764 - accuracy: 0.8224 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5769 - accuracy: 0.8222 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5754 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5739 - accuracy: 0.8229 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5740 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5721 - accuracy: 0.8233 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5714 - accuracy: 0.8241 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5720 - accuracy: 0.8243 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5710 - accuracy: 0.8236 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5699 - accuracy: 0.8243 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5699 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5683 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5681 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5679 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5671 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5677 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5666 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5662 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5658 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5654 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5653 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5641 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5644 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5640 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5642 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5636 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5635 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5640 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5626 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5630 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5626 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5628 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5619 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5620 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5616 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5617 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5615 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5608 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5596 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5591 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5591 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5594 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5590 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5597 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5596 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5590 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5597 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5590 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5591 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5590 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5591 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5582 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5583 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5578 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5577 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5589 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5583 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5582 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5585 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 11s - loss: 0.7621 - accuracy: 0.7693 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6620 - accuracy: 0.8007 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6455 - accuracy: 0.8060 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6349 - accuracy: 0.8098 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6279 - accuracy: 0.8112 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6229 - accuracy: 0.8129 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6177 - accuracy: 0.8138 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6135 - accuracy: 0.8142 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 7s - loss: 0.6111 - accuracy: 0.8144 - 7s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 7s - loss: 0.6073 - accuracy: 0.8158 - 7s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6050 - accuracy: 0.8166 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6010 - accuracy: 0.8175 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.5984 - accuracy: 0.8181 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5975 - accuracy: 0.8173 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5944 - accuracy: 0.8185 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5934 - accuracy: 0.8190 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5912 - accuracy: 0.8193 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5901 - accuracy: 0.8204 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5886 - accuracy: 0.8197 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5872 - accuracy: 0.8210 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5865 - accuracy: 0.8205 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5855 - accuracy: 0.8205 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5848 - accuracy: 0.8207 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5832 - accuracy: 0.8211 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5824 - accuracy: 0.8210 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5829 - accuracy: 0.8214 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5819 - accuracy: 0.8221 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5797 - accuracy: 0.8223 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5789 - accuracy: 0.8222 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5780 - accuracy: 0.8225 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5772 - accuracy: 0.8232 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5765 - accuracy: 0.8227 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5755 - accuracy: 0.8236 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5743 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5732 - accuracy: 0.8236 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5719 - accuracy: 0.8244 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5716 - accuracy: 0.8244 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5718 - accuracy: 0.8237 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5711 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5706 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5702 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5698 - accuracy: 0.8246 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5690 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5685 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5687 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5679 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5676 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5669 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5671 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5667 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5659 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5662 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5666 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5660 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5653 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5657 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5650 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5644 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5651 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5643 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5647 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5640 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5639 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5632 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5634 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5628 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5625 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5623 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5629 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5625 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5623 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5616 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5619 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5612 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5612 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5612 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8282 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5602 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5604 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5597 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5589 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5584 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5594 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5601 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5584 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5583 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 10s - loss: 0.7553 - accuracy: 0.7706 - 10s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6603 - accuracy: 0.8020 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6436 - accuracy: 0.8072 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6317 - accuracy: 0.8099 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6251 - accuracy: 0.8109 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6194 - accuracy: 0.8127 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6152 - accuracy: 0.8134 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6116 - accuracy: 0.8140 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6086 - accuracy: 0.8144 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6052 - accuracy: 0.8151 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6009 - accuracy: 0.8165 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.5991 - accuracy: 0.8167 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.5958 - accuracy: 0.8179 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5936 - accuracy: 0.8195 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5919 - accuracy: 0.8191 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5895 - accuracy: 0.8187 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5882 - accuracy: 0.8197 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5861 - accuracy: 0.8205 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5850 - accuracy: 0.8207 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5850 - accuracy: 0.8206 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5837 - accuracy: 0.8208 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5814 - accuracy: 0.8216 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5822 - accuracy: 0.8210 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 7s - loss: 0.5810 - accuracy: 0.8219 - 7s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5795 - accuracy: 0.8221 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5790 - accuracy: 0.8222 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5782 - accuracy: 0.8226 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5774 - accuracy: 0.8227 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5769 - accuracy: 0.8229 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5765 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5755 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5744 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5735 - accuracy: 0.8233 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5723 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5713 - accuracy: 0.8243 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5713 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5703 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5705 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5686 - accuracy: 0.8250 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5684 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5682 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5678 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5679 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5671 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5653 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5662 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5656 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5653 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5660 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5647 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5649 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5637 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5645 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5632 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5635 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5640 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5633 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5630 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5625 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5634 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5626 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5622 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5623 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5619 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5604 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5604 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5604 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5601 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5589 - accuracy: 0.8280 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5589 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5594 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5585 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5578 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5591 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5583 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5594 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5575 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5584 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5577 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5576 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5571 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5579 - accuracy: 0.8283 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5578 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5578 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 11s - loss: 0.7518 - accuracy: 0.7723 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6573 - accuracy: 0.8028 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6398 - accuracy: 0.8075 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6313 - accuracy: 0.8101 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6246 - accuracy: 0.8121 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6200 - accuracy: 0.8126 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6161 - accuracy: 0.8133 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6118 - accuracy: 0.8145 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6081 - accuracy: 0.8154 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6047 - accuracy: 0.8153 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6010 - accuracy: 0.8173 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.5990 - accuracy: 0.8174 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.5965 - accuracy: 0.8175 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5937 - accuracy: 0.8180 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5930 - accuracy: 0.8182 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5885 - accuracy: 0.8196 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5882 - accuracy: 0.8199 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5859 - accuracy: 0.8197 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5849 - accuracy: 0.8206 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5827 - accuracy: 0.8204 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5807 - accuracy: 0.8221 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5798 - accuracy: 0.8222 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5789 - accuracy: 0.8227 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5780 - accuracy: 0.8222 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5767 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5753 - accuracy: 0.8230 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5748 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5733 - accuracy: 0.8239 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5726 - accuracy: 0.8241 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5719 - accuracy: 0.8246 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5711 - accuracy: 0.8240 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5705 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5700 - accuracy: 0.8239 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5692 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5686 - accuracy: 0.8244 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5678 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 7s - loss: 0.5682 - accuracy: 0.8248 - 7s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 7s - loss: 0.5664 - accuracy: 0.8252 - 7s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5666 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5655 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5653 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5639 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5649 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5645 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5646 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5640 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5635 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5630 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5626 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5629 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5621 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5620 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5592 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5608 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5596 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5587 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5597 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5591 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5590 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5590 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5583 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5576 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5571 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5576 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5571 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5568 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5575 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5579 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5573 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5577 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5577 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5570 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5565 - accuracy: 0.8280 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5564 - accuracy: 0.8281 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5568 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5565 - accuracy: 0.8281 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5562 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5567 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5556 - accuracy: 0.8284 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5563 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5567 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5564 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5560 - accuracy: 0.8282 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5563 - accuracy: 0.8281 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5568 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5562 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5559 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5557 - accuracy: 0.8285 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5560 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5559 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5557 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 10s - loss: 0.7531 - accuracy: 0.7719 - 10s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6602 - accuracy: 0.8013 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6435 - accuracy: 0.8071 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6338 - accuracy: 0.8102 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6266 - accuracy: 0.8115 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6213 - accuracy: 0.8129 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6165 - accuracy: 0.8139 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6139 - accuracy: 0.8145 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6090 - accuracy: 0.8156 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6063 - accuracy: 0.8156 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6035 - accuracy: 0.8162 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6008 - accuracy: 0.8165 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.5977 - accuracy: 0.8174 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5952 - accuracy: 0.8177 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5944 - accuracy: 0.8185 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5918 - accuracy: 0.8192 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5906 - accuracy: 0.8196 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5878 - accuracy: 0.8199 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5859 - accuracy: 0.8207 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5861 - accuracy: 0.8208 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5838 - accuracy: 0.8207 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5823 - accuracy: 0.8208 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5812 - accuracy: 0.8216 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5787 - accuracy: 0.8232 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5785 - accuracy: 0.8225 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5774 - accuracy: 0.8226 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5768 - accuracy: 0.8229 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5755 - accuracy: 0.8236 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5743 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5747 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5735 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5725 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5719 - accuracy: 0.8240 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5714 - accuracy: 0.8246 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5706 - accuracy: 0.8250 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5707 - accuracy: 0.8238 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5700 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5699 - accuracy: 0.8240 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5692 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5684 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5684 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5692 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5675 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5674 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5670 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5664 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5657 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5660 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5667 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5667 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 7s - loss: 0.5659 - accuracy: 0.8263 - 7s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 7s - loss: 0.5650 - accuracy: 0.8263 - 7s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5649 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5647 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5649 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5646 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5652 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5644 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5644 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5635 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5630 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5640 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5633 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5629 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5631 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5639 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5633 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5633 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5617 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5612 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5604 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5608 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5597 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5594 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5592 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5592 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5602 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5586 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 11s - loss: 0.7506 - accuracy: 0.7733 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6581 - accuracy: 0.8021 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6413 - accuracy: 0.8082 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6311 - accuracy: 0.8105 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6249 - accuracy: 0.8116 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6191 - accuracy: 0.8129 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6145 - accuracy: 0.8131 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6101 - accuracy: 0.8147 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6078 - accuracy: 0.8153 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6036 - accuracy: 0.8160 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6003 - accuracy: 0.8168 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.5978 - accuracy: 0.8174 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.5957 - accuracy: 0.8176 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5912 - accuracy: 0.8188 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5892 - accuracy: 0.8202 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5872 - accuracy: 0.8199 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5866 - accuracy: 0.8206 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5853 - accuracy: 0.8205 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5837 - accuracy: 0.8214 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5832 - accuracy: 0.8216 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5821 - accuracy: 0.8217 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5811 - accuracy: 0.8219 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5793 - accuracy: 0.8219 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5783 - accuracy: 0.8226 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5772 - accuracy: 0.8228 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5765 - accuracy: 0.8230 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5755 - accuracy: 0.8230 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5745 - accuracy: 0.8232 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5732 - accuracy: 0.8233 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5730 - accuracy: 0.8238 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5727 - accuracy: 0.8240 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5711 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5703 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5697 - accuracy: 0.8246 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5703 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5691 - accuracy: 0.8241 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5680 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5684 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5673 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5673 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5666 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5669 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 7s - loss: 0.5657 - accuracy: 0.8254 - 7s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 7s - loss: 0.5669 - accuracy: 0.8247 - 7s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "2675/2675 - 7s - loss: 0.5653 - accuracy: 0.8257 - 7s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 7s - loss: 0.5654 - accuracy: 0.8260 - 7s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5656 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5651 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5652 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5650 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5643 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5646 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5645 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5638 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5635 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5640 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5635 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5637 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5632 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5625 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5630 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5628 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5628 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 7s - loss: 0.5625 - accuracy: 0.8262 - 7s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5612 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5619 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5617 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5608 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5604 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5597 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5602 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5592 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5589 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5585 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5597 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5594 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5587 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 11s - loss: 0.7497 - accuracy: 0.7725 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6571 - accuracy: 0.8027 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6402 - accuracy: 0.8078 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6290 - accuracy: 0.8110 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6228 - accuracy: 0.8122 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6176 - accuracy: 0.8131 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6133 - accuracy: 0.8142 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6102 - accuracy: 0.8147 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6063 - accuracy: 0.8153 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6034 - accuracy: 0.8161 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6003 - accuracy: 0.8159 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.5968 - accuracy: 0.8173 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.5941 - accuracy: 0.8180 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5898 - accuracy: 0.8195 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5874 - accuracy: 0.8200 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5857 - accuracy: 0.8213 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5841 - accuracy: 0.8208 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5824 - accuracy: 0.8213 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5818 - accuracy: 0.8216 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5801 - accuracy: 0.8216 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5795 - accuracy: 0.8220 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5789 - accuracy: 0.8223 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5785 - accuracy: 0.8223 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5776 - accuracy: 0.8219 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5757 - accuracy: 0.8233 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5745 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5740 - accuracy: 0.8227 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5742 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5724 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5704 - accuracy: 0.8237 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5708 - accuracy: 0.8239 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5697 - accuracy: 0.8239 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5681 - accuracy: 0.8243 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5686 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5679 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5673 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5678 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5666 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5663 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5652 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5649 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5643 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5650 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5636 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5648 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5648 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5639 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5626 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5626 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5623 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5630 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5616 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5621 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5615 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5601 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5601 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5597 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5587 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5578 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5577 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5575 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5578 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5577 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5580 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5577 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5589 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 7s - loss: 0.5578 - accuracy: 0.8271 - 7s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5571 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5573 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5583 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5575 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5571 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5565 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5563 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5560 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5564 - accuracy: 0.8280 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5570 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5561 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5569 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5564 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5554 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5552 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5561 - accuracy: 0.8280 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5556 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5550 - accuracy: 0.8280 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5555 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5553 - accuracy: 0.8282 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5566 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5558 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 11s - loss: 0.7518 - accuracy: 0.7721 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6594 - accuracy: 0.8020 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6423 - accuracy: 0.8073 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6331 - accuracy: 0.8104 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6262 - accuracy: 0.8121 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6205 - accuracy: 0.8131 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6183 - accuracy: 0.8135 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6134 - accuracy: 0.8146 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6106 - accuracy: 0.8144 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6075 - accuracy: 0.8152 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6027 - accuracy: 0.8167 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.6017 - accuracy: 0.8165 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.5980 - accuracy: 0.8180 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5969 - accuracy: 0.8184 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5947 - accuracy: 0.8189 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5930 - accuracy: 0.8181 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5898 - accuracy: 0.8198 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5886 - accuracy: 0.8201 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5870 - accuracy: 0.8204 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5856 - accuracy: 0.8204 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5834 - accuracy: 0.8211 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5818 - accuracy: 0.8209 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5798 - accuracy: 0.8219 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5791 - accuracy: 0.8227 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5774 - accuracy: 0.8232 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5764 - accuracy: 0.8223 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5750 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5741 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5733 - accuracy: 0.8238 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5730 - accuracy: 0.8236 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5716 - accuracy: 0.8244 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5709 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5697 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5697 - accuracy: 0.8246 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5690 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5682 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5683 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5673 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5677 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5671 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5660 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5661 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5669 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5661 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5649 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5649 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5643 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5647 - accuracy: 0.8256 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5652 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5635 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5642 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5639 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5631 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5644 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5631 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5630 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5628 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5628 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5629 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5612 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5615 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5627 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5622 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5608 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5608 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5596 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5594 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5602 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5589 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5592 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5587 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5586 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5591 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5592 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5585 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5595 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5586 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 7s - loss: 0.5589 - accuracy: 0.8278 - 7s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 7s - loss: 0.5591 - accuracy: 0.8279 - 7s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5579 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5587 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5583 - accuracy: 0.8279 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5572 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5570 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5575 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 12s - loss: 0.7444 - accuracy: 0.7756 - 12s/epoch - 5ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6580 - accuracy: 0.8030 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6420 - accuracy: 0.8071 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6310 - accuracy: 0.8106 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6241 - accuracy: 0.8121 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6179 - accuracy: 0.8129 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6143 - accuracy: 0.8139 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6108 - accuracy: 0.8148 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6078 - accuracy: 0.8155 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6045 - accuracy: 0.8153 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6001 - accuracy: 0.8170 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.5977 - accuracy: 0.8177 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.5945 - accuracy: 0.8177 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5935 - accuracy: 0.8187 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5903 - accuracy: 0.8192 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5872 - accuracy: 0.8203 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5864 - accuracy: 0.8199 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5844 - accuracy: 0.8208 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5836 - accuracy: 0.8212 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5826 - accuracy: 0.8217 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5811 - accuracy: 0.8216 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5797 - accuracy: 0.8218 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5783 - accuracy: 0.8226 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5781 - accuracy: 0.8227 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5774 - accuracy: 0.8226 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5757 - accuracy: 0.8225 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5744 - accuracy: 0.8238 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5740 - accuracy: 0.8236 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5739 - accuracy: 0.8236 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5732 - accuracy: 0.8241 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5724 - accuracy: 0.8238 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5721 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5708 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5712 - accuracy: 0.8241 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5700 - accuracy: 0.8245 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5695 - accuracy: 0.8246 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5687 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5684 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5682 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5680 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5673 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5676 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5665 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5672 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5666 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5664 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5658 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5664 - accuracy: 0.8250 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5659 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5651 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5657 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5656 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5659 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5647 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5654 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5652 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5648 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5652 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5644 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5639 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5634 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5639 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5636 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5631 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5640 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5642 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5629 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5632 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5626 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5634 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5616 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5631 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5620 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5627 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5622 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5619 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5624 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5616 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 7s - loss: 0.5608 - accuracy: 0.8265 - 7s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5611 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5604 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5602 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5608 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8278 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5596 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 10s - loss: 0.7405 - accuracy: 0.7763 - 10s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6536 - accuracy: 0.8034 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 7s - loss: 0.6372 - accuracy: 0.8081 - 7s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 7s - loss: 0.6272 - accuracy: 0.8105 - 7s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6214 - accuracy: 0.8124 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6172 - accuracy: 0.8139 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6135 - accuracy: 0.8143 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6105 - accuracy: 0.8146 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6066 - accuracy: 0.8155 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6041 - accuracy: 0.8155 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.6014 - accuracy: 0.8158 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.5989 - accuracy: 0.8164 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.5971 - accuracy: 0.8170 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5959 - accuracy: 0.8174 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5939 - accuracy: 0.8171 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5916 - accuracy: 0.8182 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 8s - loss: 0.5896 - accuracy: 0.8182 - 8s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5885 - accuracy: 0.8188 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5868 - accuracy: 0.8194 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5850 - accuracy: 0.8203 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5838 - accuracy: 0.8203 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5821 - accuracy: 0.8211 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5806 - accuracy: 0.8209 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5796 - accuracy: 0.8217 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5782 - accuracy: 0.8218 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5781 - accuracy: 0.8218 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5764 - accuracy: 0.8226 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5764 - accuracy: 0.8222 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5753 - accuracy: 0.8225 - 8s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5740 - accuracy: 0.8226 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5726 - accuracy: 0.8234 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5714 - accuracy: 0.8238 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5716 - accuracy: 0.8235 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5706 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5690 - accuracy: 0.8243 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5690 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5684 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5677 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5667 - accuracy: 0.8251 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5670 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5665 - accuracy: 0.8250 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5662 - accuracy: 0.8250 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5671 - accuracy: 0.8246 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5651 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5652 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5648 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5647 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5649 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5641 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5641 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5643 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5632 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5635 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5629 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5623 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5631 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5630 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5626 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5622 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5622 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5613 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5617 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5604 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5615 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5612 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5606 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5605 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5603 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5596 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5592 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5588 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5592 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5586 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5583 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5593 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5583 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5586 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5572 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5582 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5585 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5584 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5579 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5579 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5574 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5584 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5570 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5565 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 - 11s - loss: 0.7445 - accuracy: 0.7749 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2675/2675 - 8s - loss: 0.6575 - accuracy: 0.8021 - 8s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "2675/2675 - 8s - loss: 0.6406 - accuracy: 0.8077 - 8s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "2675/2675 - 8s - loss: 0.6306 - accuracy: 0.8104 - 8s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "2675/2675 - 8s - loss: 0.6246 - accuracy: 0.8117 - 8s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "2675/2675 - 8s - loss: 0.6186 - accuracy: 0.8126 - 8s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "2675/2675 - 8s - loss: 0.6151 - accuracy: 0.8134 - 8s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "2675/2675 - 8s - loss: 0.6108 - accuracy: 0.8150 - 8s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "2675/2675 - 8s - loss: 0.6079 - accuracy: 0.8155 - 8s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "2675/2675 - 8s - loss: 0.6034 - accuracy: 0.8153 - 8s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "2675/2675 - 8s - loss: 0.5993 - accuracy: 0.8165 - 8s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "2675/2675 - 8s - loss: 0.5969 - accuracy: 0.8175 - 8s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "2675/2675 - 8s - loss: 0.5937 - accuracy: 0.8181 - 8s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "2675/2675 - 8s - loss: 0.5908 - accuracy: 0.8188 - 8s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "2675/2675 - 8s - loss: 0.5882 - accuracy: 0.8192 - 8s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "2675/2675 - 8s - loss: 0.5876 - accuracy: 0.8190 - 8s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "2675/2675 - 7s - loss: 0.5858 - accuracy: 0.8206 - 7s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "2675/2675 - 8s - loss: 0.5841 - accuracy: 0.8204 - 8s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "2675/2675 - 8s - loss: 0.5833 - accuracy: 0.8200 - 8s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "2675/2675 - 8s - loss: 0.5823 - accuracy: 0.8209 - 8s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "2675/2675 - 8s - loss: 0.5814 - accuracy: 0.8211 - 8s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "2675/2675 - 8s - loss: 0.5792 - accuracy: 0.8221 - 8s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "2675/2675 - 8s - loss: 0.5791 - accuracy: 0.8217 - 8s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "2675/2675 - 8s - loss: 0.5781 - accuracy: 0.8220 - 8s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "2675/2675 - 8s - loss: 0.5766 - accuracy: 0.8223 - 8s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "2675/2675 - 8s - loss: 0.5768 - accuracy: 0.8232 - 8s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "2675/2675 - 8s - loss: 0.5751 - accuracy: 0.8230 - 8s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "2675/2675 - 8s - loss: 0.5750 - accuracy: 0.8225 - 8s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "2675/2675 - 8s - loss: 0.5733 - accuracy: 0.8238 - 8s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "2675/2675 - 8s - loss: 0.5737 - accuracy: 0.8231 - 8s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "2675/2675 - 8s - loss: 0.5715 - accuracy: 0.8239 - 8s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "2675/2675 - 8s - loss: 0.5712 - accuracy: 0.8244 - 8s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "2675/2675 - 8s - loss: 0.5699 - accuracy: 0.8242 - 8s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "2675/2675 - 8s - loss: 0.5698 - accuracy: 0.8255 - 8s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "2675/2675 - 8s - loss: 0.5692 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "2675/2675 - 8s - loss: 0.5688 - accuracy: 0.8247 - 8s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "2675/2675 - 8s - loss: 0.5677 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "2675/2675 - 8s - loss: 0.5679 - accuracy: 0.8248 - 8s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "2675/2675 - 8s - loss: 0.5680 - accuracy: 0.8249 - 8s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "2675/2675 - 8s - loss: 0.5676 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "2675/2675 - 8s - loss: 0.5681 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "2675/2675 - 8s - loss: 0.5670 - accuracy: 0.8253 - 8s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "2675/2675 - 8s - loss: 0.5670 - accuracy: 0.8252 - 8s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "2675/2675 - 8s - loss: 0.5662 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "2675/2675 - 8s - loss: 0.5653 - accuracy: 0.8262 - 8s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "2675/2675 - 8s - loss: 0.5656 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2675/2675 - 8s - loss: 0.5649 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "2675/2675 - 8s - loss: 0.5651 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "2675/2675 - 8s - loss: 0.5644 - accuracy: 0.8261 - 8s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "2675/2675 - 8s - loss: 0.5645 - accuracy: 0.8260 - 8s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "2675/2675 - 8s - loss: 0.5657 - accuracy: 0.8254 - 8s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "2675/2675 - 8s - loss: 0.5637 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "2675/2675 - 8s - loss: 0.5638 - accuracy: 0.8263 - 8s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "2675/2675 - 8s - loss: 0.5647 - accuracy: 0.8257 - 8s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "2675/2675 - 8s - loss: 0.5635 - accuracy: 0.8259 - 8s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "2675/2675 - 8s - loss: 0.5626 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "2675/2675 - 8s - loss: 0.5637 - accuracy: 0.8267 - 8s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "2675/2675 - 8s - loss: 0.5634 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "2675/2675 - 8s - loss: 0.5627 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "2675/2675 - 8s - loss: 0.5632 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "2675/2675 - 8s - loss: 0.5622 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "2675/2675 - 7s - loss: 0.5629 - accuracy: 0.8261 - 7s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "2675/2675 - 7s - loss: 0.5631 - accuracy: 0.8262 - 7s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "2675/2675 - 7s - loss: 0.5616 - accuracy: 0.8274 - 7s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "2675/2675 - 8s - loss: 0.5620 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "2675/2675 - 8s - loss: 0.5619 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "2675/2675 - 8s - loss: 0.5623 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "2675/2675 - 8s - loss: 0.5628 - accuracy: 0.8258 - 8s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "2675/2675 - 8s - loss: 0.5622 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "2675/2675 - 8s - loss: 0.5609 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "2675/2675 - 8s - loss: 0.5610 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "2675/2675 - 8s - loss: 0.5614 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "2675/2675 - 8s - loss: 0.5618 - accuracy: 0.8264 - 8s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "2675/2675 - 8s - loss: 0.5601 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "2675/2675 - 8s - loss: 0.5602 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "2675/2675 - 8s - loss: 0.5602 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "2675/2675 - 8s - loss: 0.5599 - accuracy: 0.8265 - 8s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "2675/2675 - 8s - loss: 0.5604 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "2675/2675 - 8s - loss: 0.5600 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2675/2675 - 8s - loss: 0.5586 - accuracy: 0.8277 - 8s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "2675/2675 - 8s - loss: 0.5602 - accuracy: 0.8266 - 8s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "2675/2675 - 8s - loss: 0.5598 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "2675/2675 - 8s - loss: 0.5607 - accuracy: 0.8268 - 8s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "2675/2675 - 8s - loss: 0.5589 - accuracy: 0.8269 - 8s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "2675/2675 - 8s - loss: 0.5596 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "2675/2675 - 8s - loss: 0.5601 - accuracy: 0.8271 - 8s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "2675/2675 - 8s - loss: 0.5585 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "2675/2675 - 8s - loss: 0.5596 - accuracy: 0.8272 - 8s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "2675/2675 - 8s - loss: 0.5594 - accuracy: 0.8270 - 8s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "2675/2675 - 8s - loss: 0.5590 - accuracy: 0.8275 - 8s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "2675/2675 - 8s - loss: 0.5589 - accuracy: 0.8273 - 8s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "2675/2675 - 8s - loss: 0.5585 - accuracy: 0.8276 - 8s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "2675/2675 - 8s - loss: 0.5586 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "2675/2675 - 8s - loss: 0.5579 - accuracy: 0.8282 - 8s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "2675/2675 - 8s - loss: 0.5581 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "2675/2675 - 8s - loss: 0.5582 - accuracy: 0.8274 - 8s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "2675/2675 - 8s - loss: 0.5586 - accuracy: 0.8282 - 8s/epoch - 3ms/step\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "Epoch 1/100\n",
      "4012/4012 - 14s - loss: 0.7169 - accuracy: 0.7833 - 14s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "4012/4012 - 12s - loss: 0.6431 - accuracy: 0.8069 - 12s/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "4012/4012 - 12s - loss: 0.6295 - accuracy: 0.8111 - 12s/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "4012/4012 - 12s - loss: 0.6205 - accuracy: 0.8138 - 12s/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "4012/4012 - 12s - loss: 0.6129 - accuracy: 0.8142 - 12s/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "4012/4012 - 12s - loss: 0.6081 - accuracy: 0.8148 - 12s/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "4012/4012 - 12s - loss: 0.6035 - accuracy: 0.8160 - 12s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "4012/4012 - 12s - loss: 0.5983 - accuracy: 0.8167 - 12s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "4012/4012 - 12s - loss: 0.5953 - accuracy: 0.8178 - 12s/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "4012/4012 - 12s - loss: 0.5916 - accuracy: 0.8188 - 12s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "4012/4012 - 12s - loss: 0.5869 - accuracy: 0.8203 - 12s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "4012/4012 - 12s - loss: 0.5848 - accuracy: 0.8208 - 12s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "4012/4012 - 12s - loss: 0.5831 - accuracy: 0.8210 - 12s/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "4012/4012 - 12s - loss: 0.5801 - accuracy: 0.8217 - 12s/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "4012/4012 - 12s - loss: 0.5795 - accuracy: 0.8220 - 12s/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "4012/4012 - 12s - loss: 0.5768 - accuracy: 0.8225 - 12s/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "4012/4012 - 12s - loss: 0.5762 - accuracy: 0.8230 - 12s/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "4012/4012 - 12s - loss: 0.5739 - accuracy: 0.8234 - 12s/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "4012/4012 - 12s - loss: 0.5732 - accuracy: 0.8236 - 12s/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "4012/4012 - 12s - loss: 0.5713 - accuracy: 0.8239 - 12s/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "4012/4012 - 10s - loss: 0.5701 - accuracy: 0.8245 - 10s/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "4012/4012 - 12s - loss: 0.5699 - accuracy: 0.8245 - 12s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "4012/4012 - 12s - loss: 0.5686 - accuracy: 0.8249 - 12s/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "4012/4012 - 12s - loss: 0.5680 - accuracy: 0.8249 - 12s/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "4012/4012 - 12s - loss: 0.5676 - accuracy: 0.8251 - 12s/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "4012/4012 - 12s - loss: 0.5662 - accuracy: 0.8256 - 12s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "4012/4012 - 12s - loss: 0.5659 - accuracy: 0.8252 - 12s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "4012/4012 - 12s - loss: 0.5663 - accuracy: 0.8249 - 12s/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "4012/4012 - 12s - loss: 0.5649 - accuracy: 0.8256 - 12s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "4012/4012 - 12s - loss: 0.5649 - accuracy: 0.8257 - 12s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "4012/4012 - 12s - loss: 0.5647 - accuracy: 0.8258 - 12s/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "4012/4012 - 12s - loss: 0.5643 - accuracy: 0.8255 - 12s/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "4012/4012 - 12s - loss: 0.5631 - accuracy: 0.8263 - 12s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "4012/4012 - 12s - loss: 0.5635 - accuracy: 0.8258 - 12s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "4012/4012 - 12s - loss: 0.5628 - accuracy: 0.8266 - 12s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "4012/4012 - 12s - loss: 0.5631 - accuracy: 0.8258 - 12s/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "4012/4012 - 12s - loss: 0.5625 - accuracy: 0.8262 - 12s/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "4012/4012 - 12s - loss: 0.5618 - accuracy: 0.8259 - 12s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "4012/4012 - 12s - loss: 0.5630 - accuracy: 0.8262 - 12s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "4012/4012 - 12s - loss: 0.5618 - accuracy: 0.8266 - 12s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "4012/4012 - 12s - loss: 0.5620 - accuracy: 0.8264 - 12s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "4012/4012 - 12s - loss: 0.5617 - accuracy: 0.8267 - 12s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "4012/4012 - 12s - loss: 0.5609 - accuracy: 0.8271 - 12s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "4012/4012 - 12s - loss: 0.5610 - accuracy: 0.8269 - 12s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "4012/4012 - 12s - loss: 0.5612 - accuracy: 0.8264 - 12s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "4012/4012 - 12s - loss: 0.5616 - accuracy: 0.8268 - 12s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "4012/4012 - 12s - loss: 0.5602 - accuracy: 0.8274 - 12s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "4012/4012 - 12s - loss: 0.5603 - accuracy: 0.8269 - 12s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "4012/4012 - 12s - loss: 0.5597 - accuracy: 0.8269 - 12s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "4012/4012 - 12s - loss: 0.5596 - accuracy: 0.8274 - 12s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "4012/4012 - 12s - loss: 0.5599 - accuracy: 0.8273 - 12s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "4012/4012 - 12s - loss: 0.5587 - accuracy: 0.8276 - 12s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "4012/4012 - 12s - loss: 0.5595 - accuracy: 0.8267 - 12s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "4012/4012 - 12s - loss: 0.5594 - accuracy: 0.8271 - 12s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "4012/4012 - 12s - loss: 0.5586 - accuracy: 0.8275 - 12s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "4012/4012 - 12s - loss: 0.5593 - accuracy: 0.8270 - 12s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "4012/4012 - 12s - loss: 0.5593 - accuracy: 0.8268 - 12s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "4012/4012 - 12s - loss: 0.5593 - accuracy: 0.8269 - 12s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "4012/4012 - 12s - loss: 0.5593 - accuracy: 0.8272 - 12s/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "4012/4012 - 12s - loss: 0.5589 - accuracy: 0.8270 - 12s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "4012/4012 - 12s - loss: 0.5582 - accuracy: 0.8271 - 12s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "4012/4012 - 12s - loss: 0.5584 - accuracy: 0.8270 - 12s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "4012/4012 - 12s - loss: 0.5580 - accuracy: 0.8277 - 12s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "4012/4012 - 12s - loss: 0.5586 - accuracy: 0.8275 - 12s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "4012/4012 - 12s - loss: 0.5575 - accuracy: 0.8276 - 12s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "4012/4012 - 12s - loss: 0.5577 - accuracy: 0.8271 - 12s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "4012/4012 - 12s - loss: 0.5573 - accuracy: 0.8268 - 12s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "4012/4012 - 12s - loss: 0.5579 - accuracy: 0.8273 - 12s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "4012/4012 - 12s - loss: 0.5576 - accuracy: 0.8275 - 12s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "4012/4012 - 12s - loss: 0.5580 - accuracy: 0.8272 - 12s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "4012/4012 - 12s - loss: 0.5576 - accuracy: 0.8278 - 12s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "4012/4012 - 12s - loss: 0.5570 - accuracy: 0.8282 - 12s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "4012/4012 - 12s - loss: 0.5571 - accuracy: 0.8271 - 12s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "4012/4012 - 12s - loss: 0.5571 - accuracy: 0.8273 - 12s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "4012/4012 - 12s - loss: 0.5573 - accuracy: 0.8275 - 12s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "4012/4012 - 12s - loss: 0.5569 - accuracy: 0.8276 - 12s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "4012/4012 - 12s - loss: 0.5567 - accuracy: 0.8278 - 12s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "4012/4012 - 12s - loss: 0.5567 - accuracy: 0.8271 - 12s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "4012/4012 - 12s - loss: 0.5569 - accuracy: 0.8271 - 12s/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "4012/4012 - 12s - loss: 0.5563 - accuracy: 0.8278 - 12s/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "4012/4012 - 12s - loss: 0.5565 - accuracy: 0.8276 - 12s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "4012/4012 - 12s - loss: 0.5567 - accuracy: 0.8277 - 12s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "4012/4012 - 12s - loss: 0.5562 - accuracy: 0.8277 - 12s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "4012/4012 - 12s - loss: 0.5563 - accuracy: 0.8280 - 12s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "4012/4012 - 12s - loss: 0.5561 - accuracy: 0.8274 - 12s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "4012/4012 - 11s - loss: 0.5555 - accuracy: 0.8276 - 11s/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "4012/4012 - 12s - loss: 0.5557 - accuracy: 0.8281 - 12s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "4012/4012 - 12s - loss: 0.5558 - accuracy: 0.8279 - 12s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "4012/4012 - 12s - loss: 0.5562 - accuracy: 0.8279 - 12s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "4012/4012 - 12s - loss: 0.5563 - accuracy: 0.8277 - 12s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "4012/4012 - 12s - loss: 0.5557 - accuracy: 0.8284 - 12s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "4012/4012 - 12s - loss: 0.5560 - accuracy: 0.8277 - 12s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "4012/4012 - 11s - loss: 0.5552 - accuracy: 0.8280 - 11s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "4012/4012 - 12s - loss: 0.5553 - accuracy: 0.8281 - 12s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "4012/4012 - 12s - loss: 0.5553 - accuracy: 0.8279 - 12s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "4012/4012 - 12s - loss: 0.5557 - accuracy: 0.8279 - 12s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "4012/4012 - 12s - loss: 0.5557 - accuracy: 0.8280 - 12s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "4012/4012 - 10s - loss: 0.5553 - accuracy: 0.8279 - 10s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "4012/4012 - 12s - loss: 0.5552 - accuracy: 0.8278 - 12s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "4012/4012 - 12s - loss: 0.5558 - accuracy: 0.8282 - 12s/epoch - 3ms/step\n",
      "Best Results with Grid Search:\n",
      "0.833126100437838\n",
      "{'nb_filters': 300}\n"
     ]
    }
   ],
   "source": [
    "#CNN Filters\n",
    "\n",
    "def create_model(nb_filters):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=nb_filters, kernel_size=3, padding='same', activation='tanh'))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=80, input_shape=(1, 11), activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=2, epochs = 100, batch_size = 80)\n",
    "\n",
    "parameters = {\n",
    "    'nb_filters': [100,125,150,175,200,225,250,300],\n",
    "    #'unit': [10,20,30,40,50,60,70,80,90,100],\n",
    "    #'activation': ['relu','tanh'], \n",
    "    #'solver': ['adam','sgd'], \n",
    "    #'last_act': ['sigmoid','softmax'],\n",
    "    #'epochs': [70,100],\n",
    "    #'batch_size': [5,10] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3) # run 1 job at a time\n",
    "\n",
    "grid_search = grid_search.fit(X_train_L, y_train_L)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07710a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xaxis_filters = [100,125,150,175,200,225,250,300]\n",
    "plt.plot(xaxis_filters,means,'.-')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Filters')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"Figures/No.OfFilter_CNN(ConvLSTM).png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7faca105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f190806\\AppData\\Local\\Temp\\2\\ipykernel_3408\\2473273660.py:37: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=1, epochs = 100, batch_size = 80)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7451 - accuracy: 0.7750\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6595 - accuracy: 0.8019\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6409 - accuracy: 0.8075\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6307 - accuracy: 0.8106\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6237 - accuracy: 0.8126\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6182 - accuracy: 0.8133\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6150 - accuracy: 0.8140\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6111 - accuracy: 0.8143\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6067 - accuracy: 0.8150\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6029 - accuracy: 0.8161\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6000 - accuracy: 0.8165\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5968 - accuracy: 0.8181\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5933 - accuracy: 0.8179\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5908 - accuracy: 0.8192\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5882 - accuracy: 0.8203\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5866 - accuracy: 0.8202\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5851 - accuracy: 0.8202\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5839 - accuracy: 0.8206\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5836 - accuracy: 0.8207\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5818 - accuracy: 0.8217\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5810 - accuracy: 0.8212\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5800 - accuracy: 0.8215\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5791 - accuracy: 0.8223\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5782 - accuracy: 0.8222\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5771 - accuracy: 0.8220\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5760 - accuracy: 0.8226\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5749 - accuracy: 0.8236\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5739 - accuracy: 0.8232\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5727 - accuracy: 0.8238\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5712 - accuracy: 0.8243\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5720 - accuracy: 0.8235\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5705 - accuracy: 0.8246\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5702 - accuracy: 0.8242\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5695 - accuracy: 0.8239\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5695 - accuracy: 0.8252\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5686 - accuracy: 0.8245\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5689 - accuracy: 0.8247\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5683 - accuracy: 0.8249\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5676 - accuracy: 0.8253\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5678 - accuracy: 0.8246\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5674 - accuracy: 0.8257\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5658 - accuracy: 0.8254\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5664 - accuracy: 0.8248\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5666 - accuracy: 0.8246\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5660 - accuracy: 0.8258\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5661 - accuracy: 0.8257\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5653 - accuracy: 0.8259\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5658 - accuracy: 0.8253\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5645 - accuracy: 0.8253\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5647 - accuracy: 0.8255\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5653 - accuracy: 0.8259\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5653 - accuracy: 0.8255\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5642 - accuracy: 0.8260\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5637 - accuracy: 0.8265\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5652 - accuracy: 0.8257\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5644 - accuracy: 0.8260\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5637 - accuracy: 0.8260\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5632 - accuracy: 0.8265\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5637 - accuracy: 0.8265\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5630 - accuracy: 0.8258\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5631 - accuracy: 0.8265\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5619 - accuracy: 0.8265\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5629 - accuracy: 0.8261\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5631 - accuracy: 0.8265\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5616 - accuracy: 0.8272\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5620 - accuracy: 0.8268\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5615 - accuracy: 0.8271\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5622 - accuracy: 0.8260\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5615 - accuracy: 0.8263\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5611 - accuracy: 0.8268\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5616 - accuracy: 0.8265\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5619 - accuracy: 0.8258\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5612 - accuracy: 0.8268\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5614 - accuracy: 0.8264\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5612 - accuracy: 0.8262\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5615 - accuracy: 0.8263\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5607 - accuracy: 0.8259\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5607 - accuracy: 0.8268\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5604 - accuracy: 0.8266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5610 - accuracy: 0.8265\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5598 - accuracy: 0.8266\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5592 - accuracy: 0.8268\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5596 - accuracy: 0.8268\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5602 - accuracy: 0.8270\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5604 - accuracy: 0.8273\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5604 - accuracy: 0.8268\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5598 - accuracy: 0.8274\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5602 - accuracy: 0.8271\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5595 - accuracy: 0.8271\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5597 - accuracy: 0.8271\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5599 - accuracy: 0.8268\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5599 - accuracy: 0.8266\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5599 - accuracy: 0.8271\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5603 - accuracy: 0.8270\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5586 - accuracy: 0.8276\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5595 - accuracy: 0.8279\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5593 - accuracy: 0.8261\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5593 - accuracy: 0.8269\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5590 - accuracy: 0.8270\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5593 - accuracy: 0.8272\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7427 - accuracy: 0.7747\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6560 - accuracy: 0.8031\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6391 - accuracy: 0.8083\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6293 - accuracy: 0.8111\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6230 - accuracy: 0.8118\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6184 - accuracy: 0.8131\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6147 - accuracy: 0.8141\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6106 - accuracy: 0.8145\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6071 - accuracy: 0.8154\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6049 - accuracy: 0.8159\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6012 - accuracy: 0.8164\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5981 - accuracy: 0.8174\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5963 - accuracy: 0.8176\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5946 - accuracy: 0.8177\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5914 - accuracy: 0.8183\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5892 - accuracy: 0.8198\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5872 - accuracy: 0.8194\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5844 - accuracy: 0.8205\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5837 - accuracy: 0.8213\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5820 - accuracy: 0.8211\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5801 - accuracy: 0.8221\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5787 - accuracy: 0.8220\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5772 - accuracy: 0.8227\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5765 - accuracy: 0.8223\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5756 - accuracy: 0.8232\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5731 - accuracy: 0.8240\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5740 - accuracy: 0.8230\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5725 - accuracy: 0.8234\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5719 - accuracy: 0.8233\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5714 - accuracy: 0.8236\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5707 - accuracy: 0.8243\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5703 - accuracy: 0.8238\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5693 - accuracy: 0.8250\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5697 - accuracy: 0.8245\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5685 - accuracy: 0.8243\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5685 - accuracy: 0.8249\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5678 - accuracy: 0.8248\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5678 - accuracy: 0.8250\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5669 - accuracy: 0.8242\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5676 - accuracy: 0.8247\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5666 - accuracy: 0.8247\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5659 - accuracy: 0.8250\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5655 - accuracy: 0.8253\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5646 - accuracy: 0.8261\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5651 - accuracy: 0.8258\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5641 - accuracy: 0.8258\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5645 - accuracy: 0.8258\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5653 - accuracy: 0.8252\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5629 - accuracy: 0.8257\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5631 - accuracy: 0.8256\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5635 - accuracy: 0.8261\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5626 - accuracy: 0.8262\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5642 - accuracy: 0.8258\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5638 - accuracy: 0.8258\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5625 - accuracy: 0.8255\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5620 - accuracy: 0.8254\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5625 - accuracy: 0.8268\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5622 - accuracy: 0.8260\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5635 - accuracy: 0.8256\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5622 - accuracy: 0.8260\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5622 - accuracy: 0.8258\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5612 - accuracy: 0.8262\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5615 - accuracy: 0.8267\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5610 - accuracy: 0.8263\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5614 - accuracy: 0.8264\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5607 - accuracy: 0.8270\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5601 - accuracy: 0.8263\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5615 - accuracy: 0.8260\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5604 - accuracy: 0.8270\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5606 - accuracy: 0.8261\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5598 - accuracy: 0.8265\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5599 - accuracy: 0.8266\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5613 - accuracy: 0.8260\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5603 - accuracy: 0.8266\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5601 - accuracy: 0.8276\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5605 - accuracy: 0.8264\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5608 - accuracy: 0.8265\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5596 - accuracy: 0.8262\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5589 - accuracy: 0.8271\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5595 - accuracy: 0.8268\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5594 - accuracy: 0.8264\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5588 - accuracy: 0.8272\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5593 - accuracy: 0.8269\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5585 - accuracy: 0.8273\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5573 - accuracy: 0.8276\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5594 - accuracy: 0.8270\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5579 - accuracy: 0.8277\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5587 - accuracy: 0.8269\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5584 - accuracy: 0.8268\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5588 - accuracy: 0.8266\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5583 - accuracy: 0.8271\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5578 - accuracy: 0.8265\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5583 - accuracy: 0.8273\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5580 - accuracy: 0.8271\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5584 - accuracy: 0.8274\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5576 - accuracy: 0.8275\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5585 - accuracy: 0.8269\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5566 - accuracy: 0.8279\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5569 - accuracy: 0.8273\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5586 - accuracy: 0.8274\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7442 - accuracy: 0.7748\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6572 - accuracy: 0.8030\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6406 - accuracy: 0.8081\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6309 - accuracy: 0.8108\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6241 - accuracy: 0.8119\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6189 - accuracy: 0.8130\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6147 - accuracy: 0.8144\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6119 - accuracy: 0.8151\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6080 - accuracy: 0.8160\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6057 - accuracy: 0.8156\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6022 - accuracy: 0.8158\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5984 - accuracy: 0.8172\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5962 - accuracy: 0.8173\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5934 - accuracy: 0.8183\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5918 - accuracy: 0.8186\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5893 - accuracy: 0.8194\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5884 - accuracy: 0.8199\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5860 - accuracy: 0.8207\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5846 - accuracy: 0.8207\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5838 - accuracy: 0.8210\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5826 - accuracy: 0.8210\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5820 - accuracy: 0.8210\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5811 - accuracy: 0.8214\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5797 - accuracy: 0.8209\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5789 - accuracy: 0.8220\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5758 - accuracy: 0.8230\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5761 - accuracy: 0.8227\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5748 - accuracy: 0.8236\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5747 - accuracy: 0.8230\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5730 - accuracy: 0.8239\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5730 - accuracy: 0.8241\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5717 - accuracy: 0.8243\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5699 - accuracy: 0.8246\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5709 - accuracy: 0.8243\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5701 - accuracy: 0.8246\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5697 - accuracy: 0.8250\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5685 - accuracy: 0.8247\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5681 - accuracy: 0.8252\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5684 - accuracy: 0.8251\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5678 - accuracy: 0.8255\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5671 - accuracy: 0.8255\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5666 - accuracy: 0.8258\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5669 - accuracy: 0.8256\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5660 - accuracy: 0.8255\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5655 - accuracy: 0.8262\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5653 - accuracy: 0.8261\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5663 - accuracy: 0.8261\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5658 - accuracy: 0.8254\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5652 - accuracy: 0.8260\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5650 - accuracy: 0.8261\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5640 - accuracy: 0.8258\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5645 - accuracy: 0.8257\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5644 - accuracy: 0.8262\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5648 - accuracy: 0.8262\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5644 - accuracy: 0.8260\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5633 - accuracy: 0.8262\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5634 - accuracy: 0.8257\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5636 - accuracy: 0.8262\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5639 - accuracy: 0.8258\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5638 - accuracy: 0.8260\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5631 - accuracy: 0.8266\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5634 - accuracy: 0.8256\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5628 - accuracy: 0.8264\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5630 - accuracy: 0.8264\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5629 - accuracy: 0.8266\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5630 - accuracy: 0.8260\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5628 - accuracy: 0.8259\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5624 - accuracy: 0.8262\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5623 - accuracy: 0.8263\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5628 - accuracy: 0.8261\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5613 - accuracy: 0.8267\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5624 - accuracy: 0.8263\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5610 - accuracy: 0.8267\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5603 - accuracy: 0.8269\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5614 - accuracy: 0.8263\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5611 - accuracy: 0.8266\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5612 - accuracy: 0.8270\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5609 - accuracy: 0.8269\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5607 - accuracy: 0.8268\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5603 - accuracy: 0.8273\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5611 - accuracy: 0.8271\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5607 - accuracy: 0.8271\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5607 - accuracy: 0.8271\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5607 - accuracy: 0.8266\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5598 - accuracy: 0.8273\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5604 - accuracy: 0.8271\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5606 - accuracy: 0.8271\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5597 - accuracy: 0.8270\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5601 - accuracy: 0.8272\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5593 - accuracy: 0.8277\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5600 - accuracy: 0.8268\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5609 - accuracy: 0.8269\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5598 - accuracy: 0.8273\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5592 - accuracy: 0.8274\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5611 - accuracy: 0.8264\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5601 - accuracy: 0.8270\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5593 - accuracy: 0.8275\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5597 - accuracy: 0.8270\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5598 - accuracy: 0.8274\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5599 - accuracy: 0.8269\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 17s 5ms/step - loss: 0.7110 - accuracy: 0.7836\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6558 - accuracy: 0.8004\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6442 - accuracy: 0.8039\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6381 - accuracy: 0.8065\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6338 - accuracy: 0.8076\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6306 - accuracy: 0.8087\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6263 - accuracy: 0.8100\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6249 - accuracy: 0.8105\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6229 - accuracy: 0.8106\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6213 - accuracy: 0.8117\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6185 - accuracy: 0.8120\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6163 - accuracy: 0.8139\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6144 - accuracy: 0.8132\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6131 - accuracy: 0.8130\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6121 - accuracy: 0.8138\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6108 - accuracy: 0.8146\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6099 - accuracy: 0.8148\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6088 - accuracy: 0.8149\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6079 - accuracy: 0.8150\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6060 - accuracy: 0.8150\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6032 - accuracy: 0.8162\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6034 - accuracy: 0.8147\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6004 - accuracy: 0.8154\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5996 - accuracy: 0.8163\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5985 - accuracy: 0.8169\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5971 - accuracy: 0.8170\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5953 - accuracy: 0.8170\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5946 - accuracy: 0.8174\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5939 - accuracy: 0.8174\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5921 - accuracy: 0.8180\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5930 - accuracy: 0.8179\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5918 - accuracy: 0.8184\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5901 - accuracy: 0.8187\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5907 - accuracy: 0.8173\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5887 - accuracy: 0.8190\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5886 - accuracy: 0.8190\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5876 - accuracy: 0.8196\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5870 - accuracy: 0.8193\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5858 - accuracy: 0.8200\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5856 - accuracy: 0.8200\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5844 - accuracy: 0.8199\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5842 - accuracy: 0.8193\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5836 - accuracy: 0.8202\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5833 - accuracy: 0.8206\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5837 - accuracy: 0.8204\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5830 - accuracy: 0.8203\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5803 - accuracy: 0.8213\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5813 - accuracy: 0.8204\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5803 - accuracy: 0.8214\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5799 - accuracy: 0.8211\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5799 - accuracy: 0.8208\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5786 - accuracy: 0.8221\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5810 - accuracy: 0.8209\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5786 - accuracy: 0.8214\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5787 - accuracy: 0.8210\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5784 - accuracy: 0.8212\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5778 - accuracy: 0.8213\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5778 - accuracy: 0.8220\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5789 - accuracy: 0.8208\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5774 - accuracy: 0.8219\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5772 - accuracy: 0.8217\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5773 - accuracy: 0.8210\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5775 - accuracy: 0.8219\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5749 - accuracy: 0.8223\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5757 - accuracy: 0.8224\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5753 - accuracy: 0.8217\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5745 - accuracy: 0.8221\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5759 - accuracy: 0.8227\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5741 - accuracy: 0.8229\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5753 - accuracy: 0.8225\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5738 - accuracy: 0.8229\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5738 - accuracy: 0.8228\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5734 - accuracy: 0.8222\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5740 - accuracy: 0.8222\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5750 - accuracy: 0.8224\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5719 - accuracy: 0.8235\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5737 - accuracy: 0.8225\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5744 - accuracy: 0.8224\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5720 - accuracy: 0.8231\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5735 - accuracy: 0.8226\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5734 - accuracy: 0.8228\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5733 - accuracy: 0.8226\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5717 - accuracy: 0.8230\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5734 - accuracy: 0.8232\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5723 - accuracy: 0.8233\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5719 - accuracy: 0.8238\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5721 - accuracy: 0.8235\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5713 - accuracy: 0.8236\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5707 - accuracy: 0.8236\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5721 - accuracy: 0.8229\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5714 - accuracy: 0.8234\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5704 - accuracy: 0.8234\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5709 - accuracy: 0.8239\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5715 - accuracy: 0.8229\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5709 - accuracy: 0.8232\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5697 - accuracy: 0.8241\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5710 - accuracy: 0.8236\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5700 - accuracy: 0.8243\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5705 - accuracy: 0.8237\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5710 - accuracy: 0.8234\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 16s 5ms/step - loss: 0.7095 - accuracy: 0.7834\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6546 - accuracy: 0.8000\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6423 - accuracy: 0.8038\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6354 - accuracy: 0.8055\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6313 - accuracy: 0.8083\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6276 - accuracy: 0.8085\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6251 - accuracy: 0.8093\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6216 - accuracy: 0.8104\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6205 - accuracy: 0.8102\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6179 - accuracy: 0.8113\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6159 - accuracy: 0.8116\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6127 - accuracy: 0.8131\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6109 - accuracy: 0.8129\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6083 - accuracy: 0.8144\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6067 - accuracy: 0.8145\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6046 - accuracy: 0.8144\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6027 - accuracy: 0.8147\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5999 - accuracy: 0.8152\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5998 - accuracy: 0.8155\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5984 - accuracy: 0.8161\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5974 - accuracy: 0.8168\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5947 - accuracy: 0.8170\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5948 - accuracy: 0.8176\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5928 - accuracy: 0.8172\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5924 - accuracy: 0.8172\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5925 - accuracy: 0.8182\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5903 - accuracy: 0.8180\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5899 - accuracy: 0.8186\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5889 - accuracy: 0.8181\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5877 - accuracy: 0.8187\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5894 - accuracy: 0.8179\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5876 - accuracy: 0.8189\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5871 - accuracy: 0.8188\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5864 - accuracy: 0.8196\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5844 - accuracy: 0.8199\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5835 - accuracy: 0.8200\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5832 - accuracy: 0.8208\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5817 - accuracy: 0.8205\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5821 - accuracy: 0.8202\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5795 - accuracy: 0.8211\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5803 - accuracy: 0.8205\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5793 - accuracy: 0.8203\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5779 - accuracy: 0.8207\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5778 - accuracy: 0.8223\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5776 - accuracy: 0.8218\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5773 - accuracy: 0.8211\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5761 - accuracy: 0.8220\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5761 - accuracy: 0.8219\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5749 - accuracy: 0.8226\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5749 - accuracy: 0.8220\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5740 - accuracy: 0.8235\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5744 - accuracy: 0.8220\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5749 - accuracy: 0.8225\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5734 - accuracy: 0.8228\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5739 - accuracy: 0.8218\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5739 - accuracy: 0.8221\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5733 - accuracy: 0.8222\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5729 - accuracy: 0.8231\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5728 - accuracy: 0.8232\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5730 - accuracy: 0.8223\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5727 - accuracy: 0.8230\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5714 - accuracy: 0.8231\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5721 - accuracy: 0.8223\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5716 - accuracy: 0.8222\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5718 - accuracy: 0.8222\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5713 - accuracy: 0.8231\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5709 - accuracy: 0.8234\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5704 - accuracy: 0.8234\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5706 - accuracy: 0.8232\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5709 - accuracy: 0.8230\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5705 - accuracy: 0.8230\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5705 - accuracy: 0.8224\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5696 - accuracy: 0.8240\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5703 - accuracy: 0.8230\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5692 - accuracy: 0.8239\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5684 - accuracy: 0.8231\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5693 - accuracy: 0.8231\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5677 - accuracy: 0.8241\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5692 - accuracy: 0.8229\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5692 - accuracy: 0.8237\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5680 - accuracy: 0.8245\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5692 - accuracy: 0.8231\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5675 - accuracy: 0.8248\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5676 - accuracy: 0.8248\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5683 - accuracy: 0.8233\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5681 - accuracy: 0.8235\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5683 - accuracy: 0.8239\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5670 - accuracy: 0.8246\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5688 - accuracy: 0.8239\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5686 - accuracy: 0.8239\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5678 - accuracy: 0.8243\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5674 - accuracy: 0.8232\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5678 - accuracy: 0.8235\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5668 - accuracy: 0.8240\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5661 - accuracy: 0.8247\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5667 - accuracy: 0.8243\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5672 - accuracy: 0.8239\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5663 - accuracy: 0.8243\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5661 - accuracy: 0.8243\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5668 - accuracy: 0.8240\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 16s 5ms/step - loss: 0.7122 - accuracy: 0.7826\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6553 - accuracy: 0.8007\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6436 - accuracy: 0.8044\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6371 - accuracy: 0.8069\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6323 - accuracy: 0.8075\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6294 - accuracy: 0.8085\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6270 - accuracy: 0.8096\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6243 - accuracy: 0.8105\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6230 - accuracy: 0.8104\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6201 - accuracy: 0.8115\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6189 - accuracy: 0.8118\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6162 - accuracy: 0.8122\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6156 - accuracy: 0.8126\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6144 - accuracy: 0.8126\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6123 - accuracy: 0.8135\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6096 - accuracy: 0.8137\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6081 - accuracy: 0.8144\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6074 - accuracy: 0.8146\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6044 - accuracy: 0.8152\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6036 - accuracy: 0.8145\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6037 - accuracy: 0.8143\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6020 - accuracy: 0.8150\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6008 - accuracy: 0.8160\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.6012 - accuracy: 0.8143\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5985 - accuracy: 0.8159\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5975 - accuracy: 0.8163\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5973 - accuracy: 0.8157\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5962 - accuracy: 0.8175\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5948 - accuracy: 0.8178\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5938 - accuracy: 0.8180\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5938 - accuracy: 0.8185\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5937 - accuracy: 0.8173\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5924 - accuracy: 0.8177\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5922 - accuracy: 0.8181\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5901 - accuracy: 0.8186\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5902 - accuracy: 0.8190\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5889 - accuracy: 0.8191\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5875 - accuracy: 0.8190\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5872 - accuracy: 0.8195\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5861 - accuracy: 0.8195\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5856 - accuracy: 0.8199\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5853 - accuracy: 0.8198\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5838 - accuracy: 0.8207\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5837 - accuracy: 0.8197\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5829 - accuracy: 0.8203\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5832 - accuracy: 0.8205\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5812 - accuracy: 0.8212\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5820 - accuracy: 0.8213\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5816 - accuracy: 0.8215\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5804 - accuracy: 0.8203\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5815 - accuracy: 0.8207\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5797 - accuracy: 0.8212\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5784 - accuracy: 0.8218\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5795 - accuracy: 0.8211\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5783 - accuracy: 0.8217\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5777 - accuracy: 0.8214\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5770 - accuracy: 0.8219\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5765 - accuracy: 0.8217\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5777 - accuracy: 0.8216\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5759 - accuracy: 0.8219\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5766 - accuracy: 0.8219\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5759 - accuracy: 0.8224\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5770 - accuracy: 0.8217\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5759 - accuracy: 0.8214\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5774 - accuracy: 0.8209\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5755 - accuracy: 0.8228\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5754 - accuracy: 0.8224\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5756 - accuracy: 0.8223\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5751 - accuracy: 0.8221\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5736 - accuracy: 0.8225\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5745 - accuracy: 0.8223\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5737 - accuracy: 0.8226\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5737 - accuracy: 0.8226\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5740 - accuracy: 0.8227\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5732 - accuracy: 0.8229\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5731 - accuracy: 0.8221\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5729 - accuracy: 0.8227\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5717 - accuracy: 0.8232\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5717 - accuracy: 0.8232\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5715 - accuracy: 0.8228\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5713 - accuracy: 0.8233\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5703 - accuracy: 0.8240\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5714 - accuracy: 0.8242\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5708 - accuracy: 0.8235\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5696 - accuracy: 0.8246\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5709 - accuracy: 0.8234\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5709 - accuracy: 0.8231\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5700 - accuracy: 0.8241\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5697 - accuracy: 0.8236\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5695 - accuracy: 0.8236\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5691 - accuracy: 0.8241\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5702 - accuracy: 0.8240\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5704 - accuracy: 0.8235\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5685 - accuracy: 0.8242\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5700 - accuracy: 0.8235\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5686 - accuracy: 0.8241\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5681 - accuracy: 0.8242\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5684 - accuracy: 0.8240\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5676 - accuracy: 0.8243\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 13s 5ms/step - loss: 0.5690 - accuracy: 0.8239\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 1.0062 - accuracy: 0.6841\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.8953 - accuracy: 0.7241\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.8250 - accuracy: 0.7528\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7889 - accuracy: 0.7711\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7719 - accuracy: 0.7776\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7571 - accuracy: 0.7815\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7415 - accuracy: 0.7849\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7274 - accuracy: 0.7885\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7171 - accuracy: 0.7900\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7081 - accuracy: 0.7911\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7000 - accuracy: 0.7923\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6930 - accuracy: 0.7937\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6880 - accuracy: 0.7942\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6830 - accuracy: 0.7956\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6768 - accuracy: 0.7973\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6713 - accuracy: 0.7974\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6670 - accuracy: 0.7986\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6635 - accuracy: 0.7993\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6598 - accuracy: 0.8001\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6559 - accuracy: 0.8006\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6529 - accuracy: 0.8011\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6499 - accuracy: 0.8016\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6465 - accuracy: 0.8026\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6450 - accuracy: 0.8033\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6423 - accuracy: 0.8035\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6402 - accuracy: 0.8042\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6373 - accuracy: 0.8046\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6360 - accuracy: 0.8050\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6342 - accuracy: 0.8060\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6318 - accuracy: 0.8060\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6302 - accuracy: 0.8064\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6288 - accuracy: 0.8072\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6270 - accuracy: 0.8075\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6253 - accuracy: 0.8079\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6246 - accuracy: 0.8082\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6228 - accuracy: 0.8087\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6219 - accuracy: 0.8093\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6205 - accuracy: 0.8087\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6198 - accuracy: 0.8096\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6183 - accuracy: 0.8096\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6174 - accuracy: 0.8099\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6172 - accuracy: 0.8097\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6160 - accuracy: 0.8107\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6155 - accuracy: 0.8104\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6143 - accuracy: 0.8112\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6130 - accuracy: 0.8113\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6124 - accuracy: 0.8109\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6114 - accuracy: 0.8111\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6116 - accuracy: 0.8113\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6113 - accuracy: 0.8118\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6098 - accuracy: 0.8110\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6095 - accuracy: 0.8120\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6093 - accuracy: 0.8118\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6077 - accuracy: 0.8122\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6089 - accuracy: 0.8115\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6074 - accuracy: 0.8124\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6075 - accuracy: 0.8121\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6064 - accuracy: 0.8128\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6062 - accuracy: 0.8126\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6048 - accuracy: 0.8129\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6064 - accuracy: 0.8123\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6051 - accuracy: 0.8131\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6044 - accuracy: 0.8134\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6050 - accuracy: 0.8132\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6043 - accuracy: 0.8135\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6036 - accuracy: 0.8135\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6033 - accuracy: 0.8134\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6026 - accuracy: 0.8134\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6025 - accuracy: 0.8139\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6016 - accuracy: 0.8139\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6018 - accuracy: 0.8145\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6008 - accuracy: 0.8146\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6014 - accuracy: 0.8146\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6009 - accuracy: 0.8142\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6011 - accuracy: 0.8146\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6002 - accuracy: 0.8145\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5999 - accuracy: 0.8140\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6009 - accuracy: 0.8146\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5997 - accuracy: 0.8147\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5991 - accuracy: 0.8145\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5985 - accuracy: 0.8152\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5993 - accuracy: 0.8151\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5988 - accuracy: 0.8153\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5980 - accuracy: 0.8156\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5982 - accuracy: 0.8155\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5976 - accuracy: 0.8155\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5970 - accuracy: 0.8153\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5976 - accuracy: 0.8161\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5974 - accuracy: 0.8158\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5969 - accuracy: 0.8155\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5969 - accuracy: 0.8161\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5958 - accuracy: 0.8161\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5965 - accuracy: 0.8159\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5955 - accuracy: 0.8156\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5956 - accuracy: 0.8162\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5945 - accuracy: 0.8166\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5958 - accuracy: 0.8164\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5944 - accuracy: 0.8168\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5949 - accuracy: 0.8164\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5950 - accuracy: 0.8159\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 10s 3ms/step - loss: 1.0001 - accuracy: 0.6852\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.8983 - accuracy: 0.7238\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.8189 - accuracy: 0.7563\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7828 - accuracy: 0.7738\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7667 - accuracy: 0.7791\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7512 - accuracy: 0.7832\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7354 - accuracy: 0.7863\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7226 - accuracy: 0.7885\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7126 - accuracy: 0.7890\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7040 - accuracy: 0.7912\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6966 - accuracy: 0.7930\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6910 - accuracy: 0.7938\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6850 - accuracy: 0.7947\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6791 - accuracy: 0.7966\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6740 - accuracy: 0.7970\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6688 - accuracy: 0.7979\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6652 - accuracy: 0.7987\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6609 - accuracy: 0.7996\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6575 - accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6545 - accuracy: 0.8008\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6512 - accuracy: 0.8014\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6481 - accuracy: 0.8025\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6460 - accuracy: 0.8021\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6434 - accuracy: 0.8032\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6419 - accuracy: 0.8039\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6395 - accuracy: 0.8040\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6374 - accuracy: 0.8045\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6354 - accuracy: 0.8055\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6338 - accuracy: 0.8057\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6323 - accuracy: 0.8061\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6303 - accuracy: 0.8068\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6292 - accuracy: 0.8069\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6280 - accuracy: 0.8072\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6264 - accuracy: 0.8074\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6256 - accuracy: 0.8080\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6243 - accuracy: 0.8082\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6228 - accuracy: 0.8080\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6211 - accuracy: 0.8091\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6206 - accuracy: 0.8091\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6202 - accuracy: 0.8090\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6186 - accuracy: 0.8096\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6177 - accuracy: 0.8095\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6164 - accuracy: 0.8101\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6164 - accuracy: 0.8099\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6144 - accuracy: 0.8106\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6146 - accuracy: 0.8104\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6134 - accuracy: 0.8110\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6126 - accuracy: 0.8114\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6120 - accuracy: 0.8111\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6113 - accuracy: 0.8115\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6112 - accuracy: 0.8110\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6100 - accuracy: 0.8114\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6094 - accuracy: 0.8118\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6089 - accuracy: 0.8119\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6083 - accuracy: 0.8121\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6081 - accuracy: 0.8118\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6067 - accuracy: 0.8133\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6068 - accuracy: 0.8125\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6057 - accuracy: 0.8126\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6057 - accuracy: 0.8126\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6050 - accuracy: 0.8132\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6039 - accuracy: 0.8131\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6044 - accuracy: 0.8136\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6033 - accuracy: 0.8133\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6038 - accuracy: 0.8136\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6029 - accuracy: 0.8139\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6031 - accuracy: 0.8138\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6017 - accuracy: 0.8142\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6016 - accuracy: 0.8138\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6017 - accuracy: 0.8140\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6013 - accuracy: 0.8140\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6005 - accuracy: 0.8145\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6002 - accuracy: 0.8142\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5996 - accuracy: 0.8147\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6006 - accuracy: 0.8150\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5997 - accuracy: 0.8144\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5990 - accuracy: 0.8151\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5983 - accuracy: 0.8149\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5981 - accuracy: 0.8148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5979 - accuracy: 0.8154\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5970 - accuracy: 0.8156\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5980 - accuracy: 0.8152\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5972 - accuracy: 0.8153\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5971 - accuracy: 0.8155\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5962 - accuracy: 0.8155\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5964 - accuracy: 0.8163\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5957 - accuracy: 0.8158\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5951 - accuracy: 0.8169\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5946 - accuracy: 0.8159\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5951 - accuracy: 0.8162\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5944 - accuracy: 0.8164\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5945 - accuracy: 0.8162\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5939 - accuracy: 0.8164\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5945 - accuracy: 0.8163\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5938 - accuracy: 0.8169\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5936 - accuracy: 0.8168\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5939 - accuracy: 0.8168\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5930 - accuracy: 0.8170\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5931 - accuracy: 0.8169\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5931 - accuracy: 0.8165\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 1.0090 - accuracy: 0.6829\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.9035 - accuracy: 0.7216\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.8267 - accuracy: 0.7526\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7870 - accuracy: 0.7719\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7695 - accuracy: 0.7790\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7557 - accuracy: 0.7831\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7423 - accuracy: 0.7855\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7293 - accuracy: 0.7868\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7187 - accuracy: 0.7886\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7087 - accuracy: 0.7911\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.7000 - accuracy: 0.7926\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6939 - accuracy: 0.7939\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6882 - accuracy: 0.7951\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6820 - accuracy: 0.7955\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6771 - accuracy: 0.7968\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6720 - accuracy: 0.7979\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6667 - accuracy: 0.7985\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6621 - accuracy: 0.7994\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6581 - accuracy: 0.7997\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6546 - accuracy: 0.8010\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6514 - accuracy: 0.8015\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6484 - accuracy: 0.8023\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6463 - accuracy: 0.8031\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6442 - accuracy: 0.8035\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6415 - accuracy: 0.8039\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6399 - accuracy: 0.8046\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6370 - accuracy: 0.8053\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6352 - accuracy: 0.8061\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6337 - accuracy: 0.8060\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6312 - accuracy: 0.8062\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6293 - accuracy: 0.8070\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6287 - accuracy: 0.8070\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6273 - accuracy: 0.8081\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6252 - accuracy: 0.8078\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6241 - accuracy: 0.8082\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6238 - accuracy: 0.8084\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6220 - accuracy: 0.8084\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6213 - accuracy: 0.8089\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6197 - accuracy: 0.8093\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6195 - accuracy: 0.8091\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6187 - accuracy: 0.8103\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6178 - accuracy: 0.8097\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6161 - accuracy: 0.8100\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6150 - accuracy: 0.8112\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6147 - accuracy: 0.8111\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6143 - accuracy: 0.8109\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6134 - accuracy: 0.8111\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6129 - accuracy: 0.8111\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6123 - accuracy: 0.8123\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6115 - accuracy: 0.8115\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6104 - accuracy: 0.8117\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6109 - accuracy: 0.8122\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6103 - accuracy: 0.8122\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6095 - accuracy: 0.8128\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6084 - accuracy: 0.8125\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6085 - accuracy: 0.8120\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6071 - accuracy: 0.8125\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6073 - accuracy: 0.8127\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6069 - accuracy: 0.8130\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6065 - accuracy: 0.8132\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6059 - accuracy: 0.8137\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6049 - accuracy: 0.8135\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6049 - accuracy: 0.8132\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6040 - accuracy: 0.8138\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6041 - accuracy: 0.8139\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6035 - accuracy: 0.8144\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6026 - accuracy: 0.8142\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6038 - accuracy: 0.8132\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6026 - accuracy: 0.8142\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6020 - accuracy: 0.8141\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6017 - accuracy: 0.8145\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6013 - accuracy: 0.8142\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6015 - accuracy: 0.8147\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6002 - accuracy: 0.8152\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6006 - accuracy: 0.8144\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.6000 - accuracy: 0.8146\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5997 - accuracy: 0.8150\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5991 - accuracy: 0.8157\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5996 - accuracy: 0.8152\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5986 - accuracy: 0.8155\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5981 - accuracy: 0.8155\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5973 - accuracy: 0.8157\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5974 - accuracy: 0.8155\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5974 - accuracy: 0.8158\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5969 - accuracy: 0.8153\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5966 - accuracy: 0.8158\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5970 - accuracy: 0.8154\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5963 - accuracy: 0.8159\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5951 - accuracy: 0.8168\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5952 - accuracy: 0.8166\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5953 - accuracy: 0.8167\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5952 - accuracy: 0.8163\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5946 - accuracy: 0.8165\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5945 - accuracy: 0.8167\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5944 - accuracy: 0.8168\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5949 - accuracy: 0.8169\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5939 - accuracy: 0.8173\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5935 - accuracy: 0.8174\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5926 - accuracy: 0.8170\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 7s 3ms/step - loss: 0.5927 - accuracy: 0.8172\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "4012/4012 [==============================] - 16s 3ms/step - loss: 0.7150 - accuracy: 0.7837\n",
      "Epoch 2/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.6430 - accuracy: 0.8064\n",
      "Epoch 3/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.6275 - accuracy: 0.8110\n",
      "Epoch 4/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.6185 - accuracy: 0.8129\n",
      "Epoch 5/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.6120 - accuracy: 0.8147\n",
      "Epoch 6/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.6077 - accuracy: 0.8149\n",
      "Epoch 7/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.6033 - accuracy: 0.8154\n",
      "Epoch 8/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5996 - accuracy: 0.8167\n",
      "Epoch 9/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5958 - accuracy: 0.8176\n",
      "Epoch 10/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5925 - accuracy: 0.8185\n",
      "Epoch 11/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5908 - accuracy: 0.8190\n",
      "Epoch 12/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5868 - accuracy: 0.8199\n",
      "Epoch 13/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5841 - accuracy: 0.8208\n",
      "Epoch 14/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5829 - accuracy: 0.8209\n",
      "Epoch 15/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5802 - accuracy: 0.8221\n",
      "Epoch 16/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5784 - accuracy: 0.8224\n",
      "Epoch 17/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5763 - accuracy: 0.8228\n",
      "Epoch 18/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5755 - accuracy: 0.8231\n",
      "Epoch 19/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5735 - accuracy: 0.8232\n",
      "Epoch 20/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5726 - accuracy: 0.8241\n",
      "Epoch 21/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5718 - accuracy: 0.8248\n",
      "Epoch 22/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5704 - accuracy: 0.8242\n",
      "Epoch 23/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5694 - accuracy: 0.8247\n",
      "Epoch 24/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5698 - accuracy: 0.8247\n",
      "Epoch 25/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5691 - accuracy: 0.8252\n",
      "Epoch 26/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5679 - accuracy: 0.8253\n",
      "Epoch 27/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5674 - accuracy: 0.8253\n",
      "Epoch 28/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5671 - accuracy: 0.8256\n",
      "Epoch 29/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5667 - accuracy: 0.8252\n",
      "Epoch 30/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5655 - accuracy: 0.8261\n",
      "Epoch 31/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5653 - accuracy: 0.8260\n",
      "Epoch 32/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5655 - accuracy: 0.8258\n",
      "Epoch 33/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5650 - accuracy: 0.8260\n",
      "Epoch 34/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5645 - accuracy: 0.8260\n",
      "Epoch 35/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5641 - accuracy: 0.8256\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5636 - accuracy: 0.8262\n",
      "Epoch 37/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5631 - accuracy: 0.8261\n",
      "Epoch 38/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5630 - accuracy: 0.8261\n",
      "Epoch 39/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5625 - accuracy: 0.8267\n",
      "Epoch 40/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5630 - accuracy: 0.8260\n",
      "Epoch 41/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5618 - accuracy: 0.8266\n",
      "Epoch 42/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5620 - accuracy: 0.8266\n",
      "Epoch 43/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5617 - accuracy: 0.8267\n",
      "Epoch 44/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5618 - accuracy: 0.8265\n",
      "Epoch 45/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5615 - accuracy: 0.8268\n",
      "Epoch 46/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5621 - accuracy: 0.8267\n",
      "Epoch 47/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5607 - accuracy: 0.8264\n",
      "Epoch 48/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5605 - accuracy: 0.8269\n",
      "Epoch 49/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5608 - accuracy: 0.8270\n",
      "Epoch 50/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5611 - accuracy: 0.8268\n",
      "Epoch 51/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5604 - accuracy: 0.8271\n",
      "Epoch 52/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5601 - accuracy: 0.8273\n",
      "Epoch 53/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5599 - accuracy: 0.8267\n",
      "Epoch 54/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5597 - accuracy: 0.8270\n",
      "Epoch 55/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5606 - accuracy: 0.8270\n",
      "Epoch 56/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5586 - accuracy: 0.8273\n",
      "Epoch 57/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5594 - accuracy: 0.8270\n",
      "Epoch 58/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5596 - accuracy: 0.8271\n",
      "Epoch 59/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5591 - accuracy: 0.8269\n",
      "Epoch 60/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5592 - accuracy: 0.8271\n",
      "Epoch 61/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5587 - accuracy: 0.8266\n",
      "Epoch 62/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5581 - accuracy: 0.8274\n",
      "Epoch 63/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5582 - accuracy: 0.8272\n",
      "Epoch 64/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5579 - accuracy: 0.8272\n",
      "Epoch 65/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5586 - accuracy: 0.8273\n",
      "Epoch 66/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5577 - accuracy: 0.8271\n",
      "Epoch 67/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5576 - accuracy: 0.8276\n",
      "Epoch 68/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5571 - accuracy: 0.8279\n",
      "Epoch 69/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5579 - accuracy: 0.8276\n",
      "Epoch 70/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5578 - accuracy: 0.8276\n",
      "Epoch 71/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5579 - accuracy: 0.8272\n",
      "Epoch 72/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5576 - accuracy: 0.8271\n",
      "Epoch 73/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5575 - accuracy: 0.8273\n",
      "Epoch 74/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5571 - accuracy: 0.8278\n",
      "Epoch 75/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5568 - accuracy: 0.8278\n",
      "Epoch 76/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5573 - accuracy: 0.8276\n",
      "Epoch 77/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5562 - accuracy: 0.8276\n",
      "Epoch 78/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5568 - accuracy: 0.8274\n",
      "Epoch 79/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5570 - accuracy: 0.8275\n",
      "Epoch 80/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5572 - accuracy: 0.8278\n",
      "Epoch 81/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5565 - accuracy: 0.8279\n",
      "Epoch 82/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5568 - accuracy: 0.8282\n",
      "Epoch 83/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5563 - accuracy: 0.8276\n",
      "Epoch 84/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5567 - accuracy: 0.8278\n",
      "Epoch 85/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5573 - accuracy: 0.8274\n",
      "Epoch 86/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5560 - accuracy: 0.8277\n",
      "Epoch 87/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5573 - accuracy: 0.8268\n",
      "Epoch 88/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5555 - accuracy: 0.8280\n",
      "Epoch 89/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5558 - accuracy: 0.8284\n",
      "Epoch 90/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5549 - accuracy: 0.8280\n",
      "Epoch 91/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5558 - accuracy: 0.8276\n",
      "Epoch 92/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5560 - accuracy: 0.8284\n",
      "Epoch 93/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5558 - accuracy: 0.8280\n",
      "Epoch 94/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5552 - accuracy: 0.8286\n",
      "Epoch 95/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5553 - accuracy: 0.8279\n",
      "Epoch 96/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5552 - accuracy: 0.8278\n",
      "Epoch 97/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5554 - accuracy: 0.8283\n",
      "Epoch 98/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5553 - accuracy: 0.8281\n",
      "Epoch 99/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5555 - accuracy: 0.8281\n",
      "Epoch 100/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5559 - accuracy: 0.8284\n",
      "Best Results with Grid Search:\n",
      "0.8324374016422817\n",
      "{'No_Of_layers': 1}\n"
     ]
    }
   ],
   "source": [
    "#Layers Tuning for CNN Layer\n",
    "\n",
    "def create_model(No_Of_layers):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if No_Of_layers == 1:\n",
    "        model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='tanh'))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(Dropout(0.2))\n",
    "    elif No_Of_layers == 2:\n",
    "        model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='tanh'))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='tanh'))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(Dropout(0.2))\n",
    "    elif No_Of_layers == 2:\n",
    "        model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='tanh'))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='tanh'))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='tanh'))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(units=80, input_shape=(1, 11), activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Add an output layer \n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    #compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1, epochs = 100, batch_size = 80)\n",
    "\n",
    "parameters = {\n",
    "    #'unit': [80],\n",
    "    'No_Of_layers': [1,2,3]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_L, y_train_L)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b68e781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzDklEQVR4nO3de5yWc/7H8ddnpuk4I1FGKpWKSgqTdEKTUyxyKAohknRY67Sxu7/dtfaExS5FyFlrhKJol9SESjrpoFJN57ZQRA06TH1+f1zXcJumuu/qnvuemffz8bgf3dfhe92f63K5P3Nd1/39fM3dERERiVZKogMQEZHSRYlDRERiosQhIiIxUeIQEZGYKHGIiEhMKiQ6gJJQs2ZNb9CgwX61/e6776hWrdrBDeggUFyxUVyxUVyxSda44MBimzVr1kZ3r7XbAncv86+srCzfX7m5ufvdNp4UV2wUV2wUV2ySNS73A4sNmOnFfKfqVpWIiMREiUNERGKixCEiIjFR4hARkZgocYiISEyUOEREJCZKHHsxa9Um3lq2nVmrNiU6FBGRpKHEsQezVm2i55PTeG3pDq56apqSh4hISIljD6Yt/4rtO3cBsLVgF/96bwlbtu5IcFQiIomnxLEHbY85nMppKRiQYvDB0o10+PtEHhq/hE3fbU90eCIiCVMualXtj6z6NRjRpy0vvzeDnmedQlqqMTQ3j0cmLGX4h8u5um19+pzWkCMyKic6VBGREqXEsRdZ9WuwpVFFsurXAOCJXq1Z8sUWHsvNY/iHy3lu6kquaF2Pm844hro1qiY4WhGRkhHXW1Vm1sXMFptZnpndVczy6mY21szmmtkCM+sdzq9sZtMj5t8T0eYBM/vMzOaZ2WgzOzSe+1DUsZkZ/LPHSUy8vROXnlSHnBmr6fTAJO58dS7LN+SXZCgiIgkRt8RhZqnAUOA8oDnQ08yaF1ltALDQ3VsBnYAHzawisA3oHM4/EehiZm3DNuOBFu7eElgC3B2vfdibBjWr8ffLWvL+ndlc3bY+Y+au46yH3mfQy5/w2eebExGSiEiJiOcVRxsgz92Xu/t2IAfoWmQdBzLMzIB04GugIKzoW/jne1r4cgB3f9fdC8Jl04C6cdyHfTrq0Cr88aLjmTy4M31Pb8TERV/Q5Z8f0uf5mcxZ800iQxMRiQsLSq7HYcNm3YAu7t4nnO4FnOruAyPWyQDGAE2BDOAKd387XJYKzAIaA0PdfXAxnzEWeMXdXypmWV+gL0BmZmZWTk7Ofu1Hfn4+6enpUa//3Q7nvVU7eHfVDr7bAccfnsKFjSpyXI0Ugvx4cMQaV0lRXLFRXLFRXLE7kNiys7NnuXvr3RYUN0jHwXgB3YHhEdO9gEeLrNMNeBgwggSxAjikyDqHArkEt6ci5/8WGE2Y/Pb2SsRATlu27vBhk/I8697xXn/wW37ZY1N84mdf+K5du/Y7loMRV7wprtgortgortiVtoGc1gL1IqbrAuuKrNMbGBXGmBcmjqaRK7j7N8AkoEvhPDO7FrgAuCrcuaSTXqkCN53RiMmDs/lT1+NZ/+1Wej87gwuHTOa/n65n166kDFtEZJ/imThmAE3MrGH4wLsHwW2pSKuBMwHMLBM4DlhuZrUKfy1lZlWAs4DPwukuwGDgInf/Po7xHxSV01K5pl0Dcu/oxP2XtSR/awH9XprNuf/8gNGfrKUg7J0uIlJaxC1xePAAeyDwDrAIGOnuC8ysn5n1C1e7F2hvZvOBCcBgd98I1AZyzWweQQIa7+5vhW2GEDwPGW9mc8xsWLz24WCqWCGFy0+px4TbO/FIz5NIMePWV+bS+cH3eXn6arYV7Ex0iCIiUYlrB0B3HweMKzJvWMT7dcA5xbSbB5y0h202PshhlqjUFOOiVkdxwQm1eW/RFwzNzePuUfP513tL6Xv6MfRsczRVKqYmOkwRkT1SraoESUkxzjn+SN4Y0IEXb2hD/cOr8qe3FtLxvokMzc1TQUURSVoqOZJgZsZpTWpxWpNazFj5NUMm5vHAO4t54v1lXNe+Ab07NKRGtYqJDlNE5Ee64kgipzQ4jOevb8PYgR1p36gmj0zMo8N9E/nruEV8uXlrosMTEQF0xZGUTqhbnWG9slRQUUSSkhJHEissqHjr2ccy7P1l5MxYzcvTV3PxSXVoXVU/4xWRxFDiKAXqH16Nv13akkGdm/DkB8vJmbGa13fsYvK3sxmQ3ZhmtQ9JdIgiUo7oGUcpEllQ8fyGaUxavIHz/vUhfZ6fwSerNSa6iJQMJY5SqGZ6JbofV5Epgztz61nHMnPVJi55bCpXD/+Yj5Z9RZJWYRGRMkKJoxSrXjWNW85qwuTBnfnN+U357PMt9HxqGt2GfUTuZ18qgYhIXChxlAHplSrQ9/SfCip+/u1Wej83gwsencx/5qugoogcXEocZcjPCip2a8n323dy84jZnKOCiiJyEClxlEEVK6Rweet6vHfbGTzS8yQqpPxUUPHfH6ugoogcGCWOMqywoOK4X57GU9e0pkbVNH4zej5n3D+Jpyev4IftSiAiEjsljnIgJcU4u3nmzwoq3htRUHGzCiqKSAzUAbAciSyoOHPl1wzJDQoqDosoqHiYCiqKyD7oiqOcat3gMJ7rHRRU7NCoJo9OzKPjfRP5y9sLVVBRRPZKVxzlXNGCik9PXsHzH63i8tZ1uen0RtQ7TAUVReTndMUhwE8FFXPv6MRlJ9fhlRlryP7HJO54dS7LNuQnOjwRSSJKHPIzhQUVP/h1Nr3a1eetees466H3GfDv2SxctznR4YlIElDikGLVrl6FP1wYFFTsd0Yj3l+8gfMfUUFFEVHikH2omV6JwV2aMmVwZ247+6eCilcNn6aCiiLllBKHRKV61TR+eWYTpoQFFZd8ka+CiiLllH5VJTGpFhZUvKZdA16duYZh7y+n93MzOP6oQxiQ3ZjKSiAiZV5crzjMrIuZLTazPDO7q5jl1c1srJnNNbMFZtY7nF/ZzKZHzL8nos1hZjbezJaG/9aI5z5I8SqnpdKrXQMm3flTQcX+I2bzu8k/MGq2CiqKlGVxSxxmlgoMBc4DmgM9zax5kdUGAAvdvRXQCXjQzCoC24DO4fwTgS5m1jZscxcwwd2bABPCaUmQtNSfCio+2vMkUlOM20bOJfvBSYz4eJUKKoqUQfG84mgD5Ln7cnffDuQAXYus40CGmRmQDnwNFHigsPNAWvgqvAfSFXg+fP88cHH8dkGilZpiXNjqKP7UvjLDr2nNYdUq8dvRn/5YUPH77QWJDlFEDpJ4Jo46wJqI6bXhvEhDgGbAOmA+cIu774LgisXM5gBfAuPd/eOwTaa7rwcI/z0ibnsgMTMzzmqeyRv92/PSDafSoGZhQcVcFVQUKSMsXr+GMbPuwLnu3iec7gW0cfdBEet0AzoAtwGNgPFAK3ffHLHOocBoYJC7f2pm37j7oRHLN7n7bs85zKwv0BcgMzMzKycnZ7/2Iz8/n/T09P1qG0+lKa6lm3YydtkO5m3cSZUKcFb9NM6pn0ZGRUtoXMlAccVGccXuQGLLzs6e5e6td1vg7nF5Ae2AdyKm7wbuLrLO28BpEdMTCZJL0W39AbgjfL8YqB2+rw0s3lcsWVlZvr9yc3P3u208lca45q/9xvu9ONMb3PWWN/3df/zesQv8829/SHhciaS4YqO4YncgsQEzvZjv1HjeqpoBNDGzhuED7x7AmCLrrAbOBDCzTOA4YLmZ1QqvNDCzKsBZwGdhmzHAteH7a4E347gPchC1qFOdx6/O4t1fnU6XFkfy7NSVnHZfLr97Yz5rvv4+0eGJSJTi1o/D3QvMbCDwDpAKPOPuC8ysX7h8GHAv8JyZzQcMGOzuG82sJfB8+MusFGCku78VbvrvwEgzu4Eg8XSP1z5IfDTJzODhK07k1rOO5fH3l/HKjDXkTF9D1xPr0D+7EY1qJeclv4gE4toB0N3HAeOKzBsW8X4dcE4x7eYBJ+1hm18RXqVI6Xb04VX526Un8MszG/PkB8t5efpqRn2ylvNPqM2ATo1pftQhiQ5RRIqhkiOScJEFFW+OKKh4w3MzmK2CiiJJR4lDkkbN9Er8OqKg4qzVm7g0LKg4ddlG1cMSSRJKHJJ0Igsq/vb8Ziz5Ip8rn/qYyx6fysTPvlACEUkwJQ5JWtUqVeDG04/hw19nc2/X4/li8zauf24mFzw6mXHz17NrlxKISCIocUjSiyyo+EC3lvwQFlQ8++H3eX3WWnaooKJIiVLikFIjLTWF7q3rMT4sqJiWmsLtr84l+x8qqChSkpQ4pNQpLKj4n1tOY/g1ramZHhRUPP3+XIZ/uFwFFUXiTIlDSq3Cgoqjw4KKDWtW489vL1JBRZE40wiAUuqZGR2b1KRjk5rMWvU1Qybm8cA7ixn2/jKubdeA6zs2THSIImWKEoeUKVn1D+PZ3m349H/fMjQ3j6GT8nh68gpOr2M0O3krmYdUTnSIIqWeblVJmVRYUHH8radzXosjGb+qgNPuy+W3o1VQUeRA6YpDyrTGR2Tw0BUn0jbjaz7ZWotXZ64lZ8YaLlZBRZH9pisOKReOqJrC3y49gQ9+nc217Rrw9vx1nPXQ+wwYMZsF675NdHgipYquOKRcObJ6ZX5/YXP6ZzfimckrePGjVbw9fz1nNj2CAZ0bc/LRuw0mKSJF6IpDyqXCgoqT7+rM7Wcfy+ywoOKVT01jap4KKorsjRKHlGvVq6Qx6MwmTB7cmd/9ohlLv8znyuEqqCiyN0ocIgQFFfucFhZUvLjFjwUVf/HIZN6et56dKqgo8iMlDpEIldNS6dW2/o8FFbfu2MmAf8/mHBVUFPmREodIMSILKg658ucFFV+atoqtO1RQUcovJQ6RvUhNMS5oGRRUfPraoKDi795QQUUp35Q4RKJgZpzZLCioOKLPqTSqlf5jQcUhE5eqoKKUK+rHIRIDM6ND45p0aPxTQcV/vLuEJz5Y/mNBxcOqVUx0mCJxpSsOkf1UWFDxrUEdOa1JTYZOyqPD3ydy71sL+WLz1kSHJxI3uuIQOUAt6lTnsauyyPtyC4/lLuO5qSt58aNVdGtdl5vPaES9w6omOkSRgyquVxxm1sXMFptZnpndVczy6mY21szmmtkCM+sdzq9nZrlmtiicf0tEmxPNbJqZzTGzmWbWJp77IBKtwoKKubd3olvrurw2cy2d/jGJ20bOIe/L/ESHJ3LQxC1xmFkqMBQ4D2gO9DSz5kVWGwAsdPdWQCfgQTOrCBQAt7t7M6AtMCCi7f3APe5+IvD7cFokaRx9eFX+eklQUPG69g0YN389Zz+sgopSdsTziqMNkOfuy919O5ADdC2yjgMZZmZAOvA1UODu6919NoC7bwEWAXUi2hwSvq8OrIvjPojstyOrV+b/LmjOlMGd6d+pER8s2cAvHpnM9c/NYNaqTYkOT2S/Wbxq8ZhZN6CLu/cJp3sBp7r7wIh1MoAxQFMgA7jC3d8usp0GwAdAC3ffbGbNgHcAI0h87d19VTGf3xfoC5CZmZmVk5OzX/uRn59PenryjdmguGKTDHF9t8OZsHoH767cQf4OqJ9hHFV1F2c2qELjGqkJja2oZDhexVFcsTuQ2LKzs2e5e+vdFrh7XF5Ad2B4xHQv4NEi63QDHiZIAo2BFcAhEcvTgVnApRHzHgEuC99fDry3r1iysrJ8f+Xm5u5323hSXLFJprjyt+7wP7w53+sPfsvrD37LG939tk9f8VWiw/qZZDpekRRX7A4kNmCmF/OdGs9bVWuBehHTddn9tlJvYFQYY16YOJoCmFka8Dowwt1HRbS5FiicfpXglphIqVGtUgVqZVQmxYLpgl3O4NfnsUWdCKWUiGfimAE0MbOG4QPvHgS3pSKtBs4EMLNM4DhgefjM42lgkbs/VKTNOuCM8H1nYGmc4heJm7bHHE7FCimkABVSjFUbv+OSx6ayYuN3iQ5NZJ/iljjcvQAYSPA8YhEw0t0XmFk/M+sXrnYv0N7M5gMTgMHuvhHoQHBrq3P4s9s5ZnZ+2OZGgl9fzQX+SvgcQ6Q0yapfgxF92nJpkzReuakdL/Vpy1f52+g6ZDIfLNmQ6PBE9iquHQDdfRwwrsi8YRHv1wHnFNNuMsFzj+K2ORnIOriRipS8rPo12NKoIln1g+FqxwzsyI0vzOS6Z6fzm/ObcUPHhgQX3yLJRSVHRJJEvcOq8vrN7Tm7eSZ/fnsRd742j20FKt8uyWeficPMLjAzJRiRElCtUgUevyqLW85swmuz1tLjyWl8qbpXkmSiSQg9gKVmdn/Yh0JE4iglxbj17GN5/KqT+Wz9Fi4aMoW5a75JdFgiP9pn4nD3q4GTgGXAs2b2kZn1DTvviUicnHdCbV6/uT2pKcblT3zEm3P+l+iQRIAon3G4+2aCPhU5QG3gEmC2mQ2KY2wi5V7zow5hzMAOnFjvUG7JmcPf/rOInbviU+1BJFrRPOO40MxGAxOBNKCNu58HtALuiHN8IuXe4emVeKnPqVzd9mieeH85fZ6foREHJaGiueLoDjzs7i3d/QF3/xLA3b8Hro9rdCICQFpqCn+++AT+fHELPly6kYuHTmH5BpVql8SIJnH8AZheOGFmVcLCg7j7hDjFJSLFuLptfV7qcyrffL+DrkOn8L46C0oCRJM4XgV2RUzvDOeJSAK0PeZw3hzQgTqHVqH3s9MZ/uHywgKgIiUimsRRwYPxNAAI31eMX0gisi+FnQXPPf5I/vz2Im5/dS5bd6izoJSMaBLHBjO7qHDCzLoCG+MXkohEo1qlCgy98mR+dVYTRs3+Hz2enMYX6iwoJSCaxNEP+I2ZrTazNcBg4Kb4hiUi0UhJMX511rEMu/pklnyxhYuGTFZnQYm7aDoALnP3tgTjhjd39/bh2BkikiS6tKjNqP7tSUtNofsTHzH6k7WJDknKsKiq45rZL4DjgcqF1Trd/U9xjEtEYtT0yEMYM7Aj/UfM4tZX5rJo/RYGd2lKaooq7MrBFU0HwGHAFcAgglLn3YH6cY5LRPbDYdUq8uINp9KrbX2e/GA51z83g29/UGdBObiiecbR3t2vATa5+z1AO34+JKyIJJG01BTuvbgFf73kBKbkbeSSoVNYps6CchBFkzgKf6bxvZkdBewAGsYvJBE5GK489WhG9DmVb37YwcVDp5C7+MtEhyRlRDSJY6yZHQo8AMwGVgIvxzEmETlITj3mcMYM7EDdGlW54bkZPPnBMnUWlAO218QRDuA0wd2/cffXCZ5tNHX335dIdCJywOrWqMrrN7fjvBa1+eu4z7htpDoLyoHZa+Jw913AgxHT29z927hHJSIHVdWKFRhy5UncfvaxjP7kf1yhzoJyAKK5VfWumV1mhb/DFZFSycwYdGYTnuiVRd4XW7jw0cl8snpTosOSUiiaxHEbQVHDbWa22cy2mNnmOMclInFy7vFHMqp/ByqlpXDFk9N4fZY6C0psouk5nuHuKe5e0d0PCacPKYngRCQ+jjsygzEDOpJ1dA1uf3Uuf35rIQU7d+27oQjRdQA8vbhXNBs3sy5mttjM8szsrmKWVzezsWY218wWmFnvcH49M8s1s0Xh/FuKtBsUbneBmd0f7c6KyE9qVKvICze04dp29Rk+eQXXPz+Tb79XZ0HZt2hKjtwZ8b4y0AaYBXTeWyMzSwWGAmcDa4EZZjbG3RdGrDYAWOjuF5pZLWCxmY0ACoDb3X22mWUAs8xsvLsvNLNsoCvQ0t23mdkRUe6riBSRlprCPV1b0LT2Ifz+zU+5+LEpPHVN60SHJUkumltVF0a8zgZaAF9Ese02QJ67Lw/H8Mgh+ML/2eaBjPDBezrwNVDg7uvdfXb4+VuARUCdsM3NwN/dfVu4XL2aRA5QzzZH8+8b27L5hx1cMnQKczcUJDokSWIWa2eg8Et+nrufsI/1ugFd3L1PON0LONXdB0askwGMAZoCGcAV7v52ke00AD4AWrj7ZjObA7wJdCHo1X6Hu88o5vP7An0BMjMzs3JycmLaz0L5+fmkp6fvV9t4UlyxUVzR+eqHXTzyyTZWb95J92Mrcl7DNJLpB5XJdrwKJWtccGCxZWdnz3L33S5B93mrysweJbgygOAK5URgbhSfWdzZVjRLnQvMIbjt1QgYb2Yfuvvm8LPTgdeBXxXOC2OuAbQFTgFGmtkxXiQDuvuTwJMArVu39k6dOkUR8u4mTZrE/raNJ8UVG8UVvfPP3Mm1j41n5JIdbK9ai79f1pLKaamJDgtIzuMFyRsXxCe2aJ5xzIx4XwC87O5Tomi3lp8XQ6wLrCuyTm+C204O5JnZCoKrj+lmlkaQNEa4+6gi2x0VtpluZruAmsCGKGISkX2oUjGVm1tV4oxW9XjgncUs3/gdT/TKonb1KokOTZJENP04XgNecvfn3X0EMM3MqkbRbgbQxMwamllFoAfBbalIq4EzAcwsEzgOWB7eDnsaWOTuDxVp8wbhg3kzO5Zg/HMNZStyEJkZA7Ib89Q1rVn2ZT4XDZnCbHUWlFA0iWMCEPmnRhXgvX01cvcCYCDwDsHD7ZHuvsDM+plZv3C1e4H2ZjY//JzB7r4R6AD0Ajqb2ZzwdX7Y5hngGDP7lOCB+7VFb1OJyMFxdvNMRg/oQJW0VHo8MY1XZ65JdEiSBKK5VVXZ3X8s5u/u+VFeceDu44BxReYNi3i/DjinmHaTKf4ZCeEvtK6O5vNF5MAdm5nBmwM6MODfs7nztXl89vkW7j6vKRVSo/m7U8qiaP7Lf2dmJxdOmFkW8EP8QhKRZFOjWkVeuL4N17VvwNOTV9D7uRnqLFiORZM4fgW8amYfmtmHwCsEt6BEpBypkJrCHy86nvsuO4Fpy7+i69DJ5H25JdFhSQJE0wFwBsEvnW4G+gPN3H1WvAMTkeR0xSlH8/KNbcnfVsDFQ6cyYVE0/YGlLImmVtUAoJq7f+ru84F0M+sf/9BEJFm1bnAYYwZ2pEHNqvR5YSaPTcrTyILlSDS3qm50928KJ9x9E3Bj3CISkVLhqEOr8OpN7bmg5VHc/9/F3JIzhx+2a2TB8iCaX1WlmJkV/uQ1LF5YMb5hiUhpUKViKo/0OJGmR2bwj3cXs2Ljdzx5jToLlnXRXHG8Q1DW40wz6wy8DPwnvmGJSGnxY2fBXq1ZsfE7Lnx0CrNWfZ3osCSOokkcgwk6591MUAZ9Hj/vECgiwlnNMxndvz3VKqXS88mPGTlDnQXLqmh+VbULmAYsB1oTlAhZFOe4RKQUahJ2FmzT8DB+/fo87hm7QCMLlkF7fMYR1oHqAfQEviLov4G7Z5dMaCJSGh1atSLP9T6Fv477jGemrGDpF/kMufIkDq2qR6Nlxd6uOD4juLq40N07uvujgH4yISL7VCE1hd9f2Jz7u7Vk+oqv6Tp0Cku+UGfBsmJvieMy4HMg18yeMrMz2UP9KBGR4lzeuh4v923Ld9t2csnQKby3UJ0Fy4I9Jg53H+3uVxD0Gp8E3ApkmtnjZrZbYUIRkeJk1a/B2EEdOKZWOje+OJOhueosWNpF83D8O3cf4e4XEAzGNAe4K96BiUjZUbt6FV7t144LWx7FA+8sZtDLn6izYCkWU11kd//a3Z9w987xCkhEyqbKaan8q8eJDO7SlLfnr6f7E1NZ940KbZdGKqgvIiXGzLi5UyOGX9OalRu/56Ihk5m5Up0FSxslDhEpcWc2y+SNAe1Jr1SBnk9NI2f66kSHJDFQ4hCRhGh8RAZvDuhI22MO565R8/njmAXsUGfBUkGJQ0QSpnrVNJ697hT6dGzIc1NXcu0z09n03fZEhyX7oMQhIglVITWF313QnH90b8XMlZvoOnQKiz9XZ8FkpsQhIkmhW1Zdcm5qyw87dnLpY1N4d8HniQ5J9kCJQ0SSxslH12DswI40OiKdvi/OYsjEpeosmISUOEQkqRxZvTIjb2rHxScexT/eXcLAlz/h++0FiQ5LIsQ1cZhZFzNbbGZ5ZrZbb3Mzq25mY81srpktMLPe4fx6ZpZrZovC+bcU0/YOM3MzqxnPfRCRklc5LZWHrziRu85ryrj56+n2+Ef8T50Fk0bcEkc4xOxQ4DygOdDTzJoXWW0AsNDdWwGdgAfNrCJQANzu7s2AtsCAyLZmVg84G9CPv0XKKDOj3xmNeObaU1jz9fdc9OhkFn+tMiXJIJ5XHG2APHdf7u7bgRyga5F1HMgwMwPSga+BAndf7+6zAdx9C8HAUXUi2j0M/DpsLyJlWHbTIxg9oAPVq6Rx/4ytvKzOggkXz8RRB4gcO3ItP//yBxgCNAPWAfOBW8IRB39kZg2Ak4CPw+mLgP+5+9z4hC0iyabxEemMHtCBZoencveo+fz+zU/VWTCBLF6/WDCz7sC57t4nnO4FtHH3QRHrdAM6ALcBjYDxQCt33xwuTwfeB/7i7qPMrCqQC5zj7t+a2UqgtbtvLObz+wJ9ATIzM7NycnL2az/y8/NJT0/fr7bxpLhio7hik6xxbd6Sz7j/pfHflQU0OyyF/idWJqNi4ocJStbjBQcWW3Z29ix3b73bAnePywtoB7wTMX03cHeRdd4GTouYnkiQXADSgHeA2yKWnwB8CawMXwUEzzmO3FssWVlZvr9yc3P3u208Ka7YKK7YJHtcr81c401+O8473jfBF63/NrFBefIeL/cDiw2Y6cV8p8bzVtUMoImZNQwfePcAxhRZZzXB8LSYWSZwHLA8fObxNLDI3R8qXNnd57v7Ee7ewN0bENz+Otnd1VNIpBy5LKsur/Rty7Ydu7j0sam8o86CJSpuicPdC4CBBFcNi4CR7r7AzPqZWb9wtXuB9mY2H5gADPbgtlMHoBfQ2czmhK/z4xWriJQ+Jx1dg7GDOtLkiHRuenEWj0xQZ8GSUiGeG3f3ccC4IvOGRbxfB+w2DK27TyaK8c3Dqw4RKacyD6nMKze14+5R83lo/BI++3wz/+jeiqoV4/rVVu6p57iIlGqV01J56PJW/Ob8pvz308+57PGPWLvp+0SHVaYpcYhIqWdm9D29Ec9cdwprN33PRUOm8PHyrxIdVpmlxCEiZUan447gjQEdOLRqGlcN/5gRH69KdEhlkhKHiJQpjWqlM7p/Bzo0rslvR3/K796Yr86CB5kSh4iUOdWrpPHMdadw0+nH8NK01fR6+mO+1siCB40Sh4iUSakpxt3nN+PhK1oxe/U3XDRkMovWb050WGWCEoeIlGmXnFSXkTe1Y8fOXVz2+FT+++n6RIdU6ilxiEiZd2K9QxkzsCPHZmbQ76XZPDx+Cbt2qbPg/lLiEJFyIfOQyuT0bctlJ9flXxOW0n/EbL7bppEF94cSh4iUG5XTUvlH95b87hfNeHfh51z2+FTWfK3OgrFS4hCRcsXM6HPaMTzbuw3rvvmBrkOnME2dBWOixCEi5dIZx9b6sbPg1cM/5sVp6iwYLSUOESm3jqmVzhsDOnBak5r83xuf8tvR89leoM6C+6LEISLl2iGV0xh+7Sn0O6MRIz5ezdVPf8xX+dsSHVZSU+IQkXIvNcW467ym/POKE5m75hsuGjKFhevUWXBPlDhEREIXn1SHV/u1Y+cu57LHpzJuvjoLFkeJQ0QkQsu6hzJmYAea1s6g/4jZPKTOgrtR4hARKeKIsLNgt6y6PDJhKTePmKXOghGUOEREilGpQioPdGvJ/13QnPELv1BnwQhKHCIie2Bm3NCxIc+FnQUvGjKZqcs2JjqshFPiEBHZh9OPrcWbAztyeHolej09nRc+Wol7+X3uocQhIhKFhjWrMbp/e844tha/f3MBvynHnQWVOEREopRROY2nrmlN/06NeHn6Gq4aPo2N5bCzoBKHiEgMUlOMX3dpyr96nMi8td/SdcgUVm3emeiwSlRcE4eZdTGzxWaWZ2Z3FbO8upmNNbO5ZrbAzHqH8+uZWa6ZLQrn3xLR5gEz+8zM5pnZaDM7NJ77ICJSnK4n1uG1fu3Z5c5fpm3l7Xnlp7Ng3BKHmaUCQ4HzgOZATzNrXmS1AcBCd28FdAIeNLOKQAFwu7s3A9oCAyLajgdauHtLYAlwd7z2QURkb06oW503B3bg6ENSGPDv2Tz47uJy0VkwnlccbYA8d1/u7tuBHKBrkXUcyDAzA9KBr4ECd1/v7rMB3H0LsAioE06/6+6FPXGmAXXjuA8iInt1REZlBrepzOWt6/LoxDxuemkW+WW8s6DF6ydlZtYN6OLufcLpXsCp7j4wYp0MYAzQFMgArnD3t4tspwHwAcFVxuYiy8YCr7j7S8V8fl+gL0BmZmZWTk7Ofu1Hfn4+6enp+9U2nhRXbBRXbBRXbPLz86lWrRrvrSrg5cXbqV3NuOXkyhxRNfGPkQ/kmGVnZ89y99a7LXD3uLyA7sDwiOlewKNF1ukGPAwY0BhYARwSsTwdmAVcWsz2fwuMJkx+e3tlZWX5/srNzd3vtvGkuGKjuGKjuGITGdeHSzZ4yz++463ueccnL92QuKBCB3LMgJlezHdqPNPhWqBexHRdYF2RdXoDo8IY88LE0RTAzNKA14ER7j4qspGZXQtcAFwV7pyISFLo2KQmbw7oQK30SlzzzHSem7KizHUWjGfimAE0MbOG4QPvHgS3pSKtBs4EMLNM4DhgefjM42lgkbs/FNnAzLoAg4GL3F2FY0Qk6TSoWY1R/duTfVwt/jh2IXePKludBeOWODx4gD0QeIfg4fZId19gZv3MrF+42r1AezObD0wABrv7RqADwa2tzmY2J3ydH7YZQvA8ZHw4f1i89kFEZH9lVE7jyV6tGZjdmJwZa7jyqWls2FI2OgtWiOfG3X0cMK7IvGER79cB5xTTbjLBc4/ittn4IIcpIhIXKSnGHecex3FHZnDna3PpOmQyT17TmhZ1qic6tAOS+Ef+IiJl3IWtjuK1fu0B6DZsKmPnFn3cW7oocYiIlIAWdarz5sCOtDiqOoNe/oQH3vms1HYWVOIQESkhtTIqMeLGU7midT2G5i6j74sz2bJ1R6LDipkSh4hICapUIZW/X3YCf7ywObmLN3DpY1NZufG7RIcVEyUOEZESZmZc16EhL1zfhg352+g6dAqTl5aekQWVOEREEqRD45qMGdCRzEMqce2z03m2lHQWVOIQEUmgow+vyqj+Hejc9AjuGbuQwa/PY1tBco/vocQhIpJg6ZUq8MTVWQzq3JiRM9dy5VMf8+WWrYkOa4+UOEREkkBKinH7Occx9MqTWbAuGFlw/tpvEx1WsZQ4RESSyC9a1ua1fu0xgs6Cb875X6JD2o0Sh4hIkmlRpzpjBnWkZd3q3JIzh/v++xk7k6izoBKHiEgSqpleiRF92tKzTT0en7SMG19Ins6CShwiIkmqYoUU/nrJCfyp6/G8v2QDlzw2lRVJ0FlQiUNEJImZGde0a8CLN7Thq/xtdB0ymQ+XbkhoTEocIiKlQPtGNRkzsCO1q1fh2mem8/TkxHUWVOIQESkl6h1Wldf7t+esZpnc+9ZC7nwtMZ0FlThEREqR9EoVGHZ1Fr88swmvzVpLjyen8eXmku0sqMQhIlLKpKQYt519LI9ddTKfrd/CRUOmMHfNNyX3+SX2SSIiclCdf0JtXru5HakpxuVPfFRinQWVOERESrHjj6rOmIEdaFXvUG7JmcPf/rMo7p0FlThEREq5w9Mr8dINp3LVqUfzxPvL6fP8DDbHsbOgEoeISBlQsUIKf7nkBO69uAUfLt3IJUOnMHbu/3hr2XZmrdp0UD9LiUNEpAzp1bY+L/U5lS83b2XQy3N4fekOrho+7aAmj7gmDjPrYmaLzSzPzO4qZnl1MxtrZnPNbIGZ9Q7n1zOzXDNbFM6/JaLNYWY23syWhv/WiOc+iIiUNm2POZyep9YHwIEdBbuYtvyrg7b9uCUOM0sFhgLnAc2BnmbWvMhqA4CF7t4K6AQ8aGYVgQLgdndvBrQFBkS0vQuY4O5NgAnhtIiIRDj3+COpnJZCCpBWIYW2xxx+0LYdzyuONkCeuy939+1ADtC1yDoOZJiZAenA10CBu69399kA7r4FWATUCdt0BZ4P3z8PXBzHfRARKZWy6tdgRJ+2XNokjRF92pJV/+DdnLF41Toxs25AF3fvE073Ak5194ER62QAY4CmQAZwhbu/XWQ7DYAPgBbuvtnMvnH3QyOWb3L33Y6ImfUF+gJkZmZm5eTk7Nd+5Ofnk56evl9t40lxxUZxxUZxxSZZ44IDiy07O3uWu7febYG7x+UFdAeGR0z3Ah4tsk434GHAgMbACuCQiOXpwCzg0oh53xTZxqZ9xZKVleX7Kzc3d7/bxpPiio3iio3iik2yxuV+YLEBM72Y79R43qpaC9SLmK4LrCuyTm9gVBhjXpg4mgKYWRrwOjDC3UdFtPnCzGqH69QGvoxT/CIiUox4Jo4ZQBMzaxg+8O5BcFsq0mrgTAAzywSOA5aHzzyeBha5+0NF2owBrg3fXwu8Gaf4RUSkGHFLHO5eAAwE3iF4uD3S3ReYWT8z6xeudi/Q3szmE/xCarC7bwQ6ENza6mxmc8LX+WGbvwNnm9lS4OxwWkRESkiFeG7c3ccB44rMGxbxfh1wTjHtJhM89yhum18RXqWIiEjJU89xERGJSdx+jptMzGwDsGo/m9cENh7EcA4WxRUbxRUbxRWbZI0LDiy2+u5eq+jMcpE4DoSZzfTifsecYIorNoorNoorNskaF8QnNt2qEhGRmChxiIhITJQ49u3JRAewB4orNoorNoorNskaF8QhNj3jEBGRmOiKQ0REYqLEISIiMSm3icPMnjGzL83s0z0sNzN7JBy9cJ6ZnRyxbK8jG8Y5rqvCeOaZ2VQzaxWxbKWZzQ9LtMws4bg6mdm3ESVifh+xLJHH686ImD41s51mdli4LJ7Ha4+jWEasU+LnWJRxlfg5FmVcJX6ORRlXiZ9jZlbZzKbbT6On3lPMOvE7v4ormVseXsDpwMnAp3tYfj7wH4LSJ22Bj8P5qcAy4BigIjAXaF6CcbUHaoTvzyuMK5xeCdRM0PHqBLxVzPyEHq8i614ITCyh41UbODl8nwEsKbrfiTjHooyrxM+xKOMq8XMsmrgScY6F50x6+D4N+BhoW1LnV7m94nD3DwhGHNyTrsALHpgGHGpBGfdoRjaMW1zuPtXdC0edn0ZQrj7uojhee5LQ41VET+Dlg/XZe+N7H8WyUImfY9HElYhzLMrjtScJPV5FlMg5Fp4z+eFkWvgq+kunuJ1f5TZxRKEOsCZiem04b0/zE+EGgr8oCjnwrpnNsmAExJLWLrx0/o+ZHR/OS4rjZWZVgS4EY7wUKpHjZcEolicR/FUYKaHn2F7iilTi59g+4krYObav41XS55iZpZrZHIIxica7e4mdX3GtjlvKFVed1/cyv0SZWTbB/9QdI2Z3cPd1ZnYEMN7MPgv/Ii8Jswnq2uRbUAL/DaAJSXK8CG4hTHH3yKuTuB8vM0sn+CL5lbtvLrq4mCYlco7tI67CdUr8HNtHXAk7x6I5XpTwOebuO4ETzexQYLSZtXD3yGd9cTu/dMWxZ3sawTCakQ3jysxaAsOBrh6UmQd+LFOPu38JjCa4JC0R7r658NLZg3L6aWZWkyQ4XqEeFLmFEO/jZXsexbJQQs6xKOJKyDm2r7gSdY5Fc7xCJX6Ohdv+BphEcLUTKX7n18F6WFMaX0AD9vyw9xf8/MHS9HB+BWA50JCfHiwdX4JxHQ3kAe2LzK8GZES8nwp0KcG4juSnDqVtCEZ3tEQfr3B5dYLnINVK6niF+/4C8M+9rFPi51iUcZX4ORZlXCV+jkUTVyLOMaAWcGj4vgrwIXBBSZ1f5fZWlZm9TPArjZpmthb4A8EDJjwYbGocwa8S8oDvCcZHx90LzKxwZMNU4Bl3X1CCcf0eOBx4zMwACjyofJlJcLkKwYnxb3f/bwnG1Q242cwKgB+AHh6cpYk+XgCXAO+6+3cRTeN6vPhpFMv54X1ogN8QfCkn8hyLJq5EnGPRxJWIcyyauKDkz7HawPNmlkpw52iku79l4eiq8T6/VHJERERiomccIiISEyUOERGJiRKHiIjERIlDRERiosQhIiIxUeKQpGRmbmYPRkzfYWZ/PEjbfs7Muh2Mbe3jc7qHVVVzi8xvYMVU8zWztmb2cVhJdZGZ/dHMekdUXt0eUWn172Z2XXiczozYxiXhvN32r6T2W8q+ctuPQ5LeNuBSM/ubu29MdDCFzCzVg1IP0bgB6O/uuftcM/A8cLm7zw1/n3+cuy8Eng0/eyWQXXg8zOw6YD5BYb0J4TZ6EHToShgLOi6Yu+9KZBwSP7rikGRVQDBW8q1FFxT9y9nM8sN/O5nZ+2Y20syWhH+VX2XBuAXzzaxRxGbOMrMPw/UuCNunmtkDZjbDgvELborYbq6Z/Zvgi7poPD3D7X9qZveF835PUONpmJk9EOU+HwGsh6AOUZg09uVDoI2ZpYX1lBoDc6L8PMws3cwmmNnscB+6hvPvtYixJ8zsL2b2y/D9nRHH6J5wXoPwKukxgppS9cL/Tp+G293tv6OUXrrikGQ2FJhnZvfH0KYV0Iyg/MNyYLi7twm/BAcBvwrXawCcATQCcs2sMXAN8K27n2JmlYApZvZuuH4boIW7r4j8MDM7CrgPyAI2EVRCvdjd/2RmnYE73D3aAXweBhab2STgv8Dz7r51H20ceA84l6DsxRiCUhLR2gpc4u6bLaj7NM3MxgBPA6OAf5lZCsGVTBszO4egsGAbglIWY8zsdILyH8cBvd29v5llAXXcvQWABYX4pIzQFYckLQ+qkL4A/DKGZjM8GENhG8FgNYVf/PMJkkWhke6+y92XEiSYpsA5wDVhaYmPCcpuNAnXn140aYROASa5+wZ3LwBGEAwuFTN3/xPQOoz5SoLkEY0cgi/23YrsRcGAv5rZPIIEVAfIdPeVwFdmdhLBcfnEg2KH5xROE1xZNOWnY7TKg3EfIDimx5jZo2bWBdhTRVkphXTFIcnunwRfUM9GzCsg/KMnvJ9eMWLZtoj3uyKmd/Hz871orZ3CctOD3P2dyAVm1gn4juIVV6J6v7n7MuBxM3sK2GBmh3tEddo9tJluZi2AH9x9SVgbKVpXERTMy3L3HeFzlMrhsuHAdQTFBZ8J5xnwN3d/InIjFoxV8eMxcvdNFgw5ey4wALgcuD6WwCR56YpDkpoHYxuMJHjQXGglwa0hCEYuS9uPTXc3s5TwuccxwGKCom83W1BGGzM71syq7WM7HwNnmFnN8IF2T+D9/YgHM/uF/fSt3wTYCXwTZfO7CYrvxao68GWYNLKB+hHLRhOU6j6F4NgQ/nt9+DwFM6tjwVgTPxPe9kpx99eB/yMY3lfKCF1xSGnwIDAwYvop4E0zm07wa6I9XQ3szWKCL/hMoJ+7bzWz4QS3s2aHX+AbgIv3thF3X29mdwO5BH+Nj3P3N6P4/OMsqOZb6FbgMuBhM/ue4Krqqmh/weXu/9n3WgA8YWb/DN+vIRh8aKyZzSR4qP5ZxDa3W/BT4m8K43D3d82sGfBRmOPygasJklykOsCz4fMRCBKblBGqjisixQq/9GcD3cNnQSKAblWJSDHMrDnBOA4TlDSkKF1xiIhITHTFISIiMVHiEBGRmChxiIhITJQ4REQkJkocIiISk/8HMWlyJPA1L0wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xaxis_CNN_layers =[1,2,3]\n",
    "plt.plot(xaxis_CNN_layers,means,'.-')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of LSTM Layers')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"Figures/No.OfLayers_CNN(ConvLSTM).png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2b5073b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f190806\\AppData\\Local\\Temp\\2\\ipykernel_7416\\2418018321.py:14: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=1, epochs = 100, batch_size = 80)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 19s 3ms/step - loss: 0.8563 - accuracy: 0.7413\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.7408 - accuracy: 0.7803\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.7254 - accuracy: 0.7840\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.7148 - accuracy: 0.7888\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.7076 - accuracy: 0.7904\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.7006 - accuracy: 0.7924\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6966 - accuracy: 0.7929\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6945 - accuracy: 0.7937\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6911 - accuracy: 0.7938\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6873 - accuracy: 0.7946\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6879 - accuracy: 0.7946\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6870 - accuracy: 0.7950\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6840 - accuracy: 0.7961\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6844 - accuracy: 0.7956\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6821 - accuracy: 0.7963\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6833 - accuracy: 0.7958\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6807 - accuracy: 0.7971\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6809 - accuracy: 0.7964\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6807 - accuracy: 0.7970\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6795 - accuracy: 0.7976\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6790 - accuracy: 0.7983\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6781 - accuracy: 0.7978\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6774 - accuracy: 0.7980\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6772 - accuracy: 0.7989\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6745 - accuracy: 0.7989\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6754 - accuracy: 0.7994\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6759 - accuracy: 0.7988\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6751 - accuracy: 0.7990\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6749 - accuracy: 0.7989\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6751 - accuracy: 0.7988\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6742 - accuracy: 0.7993\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6744 - accuracy: 0.7999\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6750 - accuracy: 0.7987\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6760 - accuracy: 0.7990\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6734 - accuracy: 0.7991\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6738 - accuracy: 0.7990\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6744 - accuracy: 0.7993\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6744 - accuracy: 0.7997\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6731 - accuracy: 0.7998\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6732 - accuracy: 0.7992\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6724 - accuracy: 0.8001\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6718 - accuracy: 0.7996\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6716 - accuracy: 0.7996\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6717 - accuracy: 0.8001\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6731 - accuracy: 0.7998\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6722 - accuracy: 0.7999\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6705 - accuracy: 0.7998\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6721 - accuracy: 0.7997\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6717 - accuracy: 0.8002\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6717 - accuracy: 0.8001\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6715 - accuracy: 0.7998\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6676 - accuracy: 0.8008\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6660 - accuracy: 0.8015\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6673 - accuracy: 0.8016\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6671 - accuracy: 0.8007\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6667 - accuracy: 0.8016\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6663 - accuracy: 0.8011\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6653 - accuracy: 0.8015\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6661 - accuracy: 0.8022\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6663 - accuracy: 0.8008\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6649 - accuracy: 0.8022\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6651 - accuracy: 0.8020\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6654 - accuracy: 0.8017\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6656 - accuracy: 0.8020\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6653 - accuracy: 0.8019\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6653 - accuracy: 0.8027\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6661 - accuracy: 0.8014\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6654 - accuracy: 0.8013\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6645 - accuracy: 0.8019\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6641 - accuracy: 0.8021\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6643 - accuracy: 0.8018\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6654 - accuracy: 0.8019\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6644 - accuracy: 0.8021\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6649 - accuracy: 0.8023\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6643 - accuracy: 0.8021\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6627 - accuracy: 0.8024\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6634 - accuracy: 0.8022\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6632 - accuracy: 0.8025\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6640 - accuracy: 0.8030\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6634 - accuracy: 0.8020\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6638 - accuracy: 0.8020\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6634 - accuracy: 0.8028\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6642 - accuracy: 0.8026\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6647 - accuracy: 0.8023\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6630 - accuracy: 0.8027\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6619 - accuracy: 0.8030\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6632 - accuracy: 0.8031\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6636 - accuracy: 0.8030\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6653 - accuracy: 0.8015\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6624 - accuracy: 0.8025\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6633 - accuracy: 0.8024\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6633 - accuracy: 0.8026\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6629 - accuracy: 0.8031\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6635 - accuracy: 0.8019\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6624 - accuracy: 0.8030\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6634 - accuracy: 0.8027\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6635 - accuracy: 0.8030\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6616 - accuracy: 0.8030\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6619 - accuracy: 0.8037\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6630 - accuracy: 0.8034\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.8331 - accuracy: 0.7544\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.7196 - accuracy: 0.7868\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.7063 - accuracy: 0.7903\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.7005 - accuracy: 0.7933\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6967 - accuracy: 0.7949\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6940 - accuracy: 0.7960\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6913 - accuracy: 0.7967\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6867 - accuracy: 0.7975\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6854 - accuracy: 0.7973\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6851 - accuracy: 0.7967\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6820 - accuracy: 0.7974\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6817 - accuracy: 0.7977\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6797 - accuracy: 0.7991\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6798 - accuracy: 0.7986\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6785 - accuracy: 0.7994\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6778 - accuracy: 0.7996\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6768 - accuracy: 0.7992\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6765 - accuracy: 0.7997\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6758 - accuracy: 0.8001\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6752 - accuracy: 0.8001\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6755 - accuracy: 0.7995\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6744 - accuracy: 0.8003\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6744 - accuracy: 0.8003\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6737 - accuracy: 0.8004\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6737 - accuracy: 0.8004\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6741 - accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6734 - accuracy: 0.8007\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6726 - accuracy: 0.8010\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6733 - accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6722 - accuracy: 0.8016\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6729 - accuracy: 0.8013\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6720 - accuracy: 0.8014\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6724 - accuracy: 0.8007\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6712 - accuracy: 0.8014\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6718 - accuracy: 0.8013\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6714 - accuracy: 0.8018\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6726 - accuracy: 0.8004\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6711 - accuracy: 0.8010\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6701 - accuracy: 0.8012\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6702 - accuracy: 0.8016\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6714 - accuracy: 0.8015\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6702 - accuracy: 0.8014\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6700 - accuracy: 0.8019\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6700 - accuracy: 0.8016\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6695 - accuracy: 0.8015\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6696 - accuracy: 0.8014\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6696 - accuracy: 0.8013\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6692 - accuracy: 0.8020\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6701 - accuracy: 0.8026\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6701 - accuracy: 0.8019\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6691 - accuracy: 0.8016\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6675 - accuracy: 0.8020\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6698 - accuracy: 0.8018\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6682 - accuracy: 0.8016\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6687 - accuracy: 0.8019\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6680 - accuracy: 0.8016\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6680 - accuracy: 0.8029\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6674 - accuracy: 0.8020\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6697 - accuracy: 0.8013\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6674 - accuracy: 0.8022\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6669 - accuracy: 0.8021\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6693 - accuracy: 0.8016\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6676 - accuracy: 0.8021\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6670 - accuracy: 0.8027\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6672 - accuracy: 0.8021\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6684 - accuracy: 0.8024\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6685 - accuracy: 0.8022\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6674 - accuracy: 0.8018\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6664 - accuracy: 0.8021\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6672 - accuracy: 0.8024\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6673 - accuracy: 0.8018\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6666 - accuracy: 0.8025\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6671 - accuracy: 0.8022\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6674 - accuracy: 0.8021\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6672 - accuracy: 0.8014\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6678 - accuracy: 0.8021\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6672 - accuracy: 0.8019\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6678 - accuracy: 0.8016\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6665 - accuracy: 0.8020\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6672 - accuracy: 0.8021\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6659 - accuracy: 0.8021\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6667 - accuracy: 0.8023\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6662 - accuracy: 0.8026\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6668 - accuracy: 0.8015\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6675 - accuracy: 0.8019\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6670 - accuracy: 0.8020\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6665 - accuracy: 0.8020\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6657 - accuracy: 0.8021\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6648 - accuracy: 0.8021\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6659 - accuracy: 0.8026\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6648 - accuracy: 0.8021\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6660 - accuracy: 0.8014\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6661 - accuracy: 0.8023\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6650 - accuracy: 0.8032\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6656 - accuracy: 0.8023\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6672 - accuracy: 0.8018\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6651 - accuracy: 0.8032\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6649 - accuracy: 0.8018\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6651 - accuracy: 0.8014\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6642 - accuracy: 0.8019\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.8402 - accuracy: 0.7482\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.7280 - accuracy: 0.7841\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.7128 - accuracy: 0.7902\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.7062 - accuracy: 0.7928\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.7005 - accuracy: 0.7943\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6976 - accuracy: 0.7945\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6947 - accuracy: 0.7956\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6928 - accuracy: 0.7960\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6913 - accuracy: 0.7970\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6919 - accuracy: 0.7966\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6895 - accuracy: 0.7977\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6888 - accuracy: 0.7972\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6883 - accuracy: 0.7978\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6881 - accuracy: 0.7986\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6871 - accuracy: 0.7986\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6871 - accuracy: 0.7984\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6856 - accuracy: 0.7994\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6842 - accuracy: 0.7991\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6846 - accuracy: 0.7995\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6843 - accuracy: 0.7995\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6847 - accuracy: 0.7991\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6837 - accuracy: 0.7996\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6841 - accuracy: 0.7989\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6839 - accuracy: 0.7991\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6812 - accuracy: 0.8002\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6816 - accuracy: 0.7993\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6809 - accuracy: 0.7996\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6807 - accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6792 - accuracy: 0.8006\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6792 - accuracy: 0.8004\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6802 - accuracy: 0.7999\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6802 - accuracy: 0.7992\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6787 - accuracy: 0.8001\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6785 - accuracy: 0.8002\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6803 - accuracy: 0.7992\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6799 - accuracy: 0.7998\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6787 - accuracy: 0.7996\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6799 - accuracy: 0.7999\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6784 - accuracy: 0.8001\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6770 - accuracy: 0.8006\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6783 - accuracy: 0.8009\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6778 - accuracy: 0.8003\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6776 - accuracy: 0.8006\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6779 - accuracy: 0.7999\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6772 - accuracy: 0.7999\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6771 - accuracy: 0.8004\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6766 - accuracy: 0.8005\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6769 - accuracy: 0.8005\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6766 - accuracy: 0.8003\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6766 - accuracy: 0.8000\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6768 - accuracy: 0.8018\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6765 - accuracy: 0.8009\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6759 - accuracy: 0.8008\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6750 - accuracy: 0.8008\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6753 - accuracy: 0.8008\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6770 - accuracy: 0.8003\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6778 - accuracy: 0.7999\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6746 - accuracy: 0.8005\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6767 - accuracy: 0.8003\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6763 - accuracy: 0.8007\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6756 - accuracy: 0.8008\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6761 - accuracy: 0.8013\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6770 - accuracy: 0.8002\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6755 - accuracy: 0.8013\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6764 - accuracy: 0.8007\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6744 - accuracy: 0.8017\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6764 - accuracy: 0.8005\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6753 - accuracy: 0.8011\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6757 - accuracy: 0.8018\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6744 - accuracy: 0.8023\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6740 - accuracy: 0.8015\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6728 - accuracy: 0.8017\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6746 - accuracy: 0.8011\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6745 - accuracy: 0.8013\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6737 - accuracy: 0.8009\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6742 - accuracy: 0.8018\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6733 - accuracy: 0.8019\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6736 - accuracy: 0.8013\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6721 - accuracy: 0.8016\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6729 - accuracy: 0.8013\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6726 - accuracy: 0.8020\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6746 - accuracy: 0.8019\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6732 - accuracy: 0.8018\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6713 - accuracy: 0.8030\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6735 - accuracy: 0.8016\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6723 - accuracy: 0.8015\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6733 - accuracy: 0.8018\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6733 - accuracy: 0.8017\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6726 - accuracy: 0.8028\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6738 - accuracy: 0.8019\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6717 - accuracy: 0.8023\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6732 - accuracy: 0.8015\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6726 - accuracy: 0.8025\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6728 - accuracy: 0.8022\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6722 - accuracy: 0.8018\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6728 - accuracy: 0.8023\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6722 - accuracy: 0.8020\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6724 - accuracy: 0.8020\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6729 - accuracy: 0.8023\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6723 - accuracy: 0.8026\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7841 - accuracy: 0.7650\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6864 - accuracy: 0.7983\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6739 - accuracy: 0.8010\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6639 - accuracy: 0.8037\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6573 - accuracy: 0.8056\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6534 - accuracy: 0.8063\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6500 - accuracy: 0.8071\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6481 - accuracy: 0.8078\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6470 - accuracy: 0.8073\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6431 - accuracy: 0.8082\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6421 - accuracy: 0.8086\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6402 - accuracy: 0.8088\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6388 - accuracy: 0.8094\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6363 - accuracy: 0.8101\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6353 - accuracy: 0.8097\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6354 - accuracy: 0.8097\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6340 - accuracy: 0.8101\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6329 - accuracy: 0.8098\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6326 - accuracy: 0.8104\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6321 - accuracy: 0.8105\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6311 - accuracy: 0.8111\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6319 - accuracy: 0.8104\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6294 - accuracy: 0.8114\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6302 - accuracy: 0.8104\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6290 - accuracy: 0.8112\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6285 - accuracy: 0.8113\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6287 - accuracy: 0.8113\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6284 - accuracy: 0.8113\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6276 - accuracy: 0.8120\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6266 - accuracy: 0.8122\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6287 - accuracy: 0.8113\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6277 - accuracy: 0.8112\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6252 - accuracy: 0.8125\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6280 - accuracy: 0.8111\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6259 - accuracy: 0.8126\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6272 - accuracy: 0.8115\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6264 - accuracy: 0.8119\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6254 - accuracy: 0.8124\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6252 - accuracy: 0.8126\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6268 - accuracy: 0.8121\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6257 - accuracy: 0.8122\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6261 - accuracy: 0.8126\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6254 - accuracy: 0.8124\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6255 - accuracy: 0.8124\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6247 - accuracy: 0.8131\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6246 - accuracy: 0.8126\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6242 - accuracy: 0.8135\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6249 - accuracy: 0.8127\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6238 - accuracy: 0.8133\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6238 - accuracy: 0.8132\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6232 - accuracy: 0.8131\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6244 - accuracy: 0.8125\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6233 - accuracy: 0.8131\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6242 - accuracy: 0.8132\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6241 - accuracy: 0.8127\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6247 - accuracy: 0.8129\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6234 - accuracy: 0.8133\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6235 - accuracy: 0.8135\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6225 - accuracy: 0.8128\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6219 - accuracy: 0.8133\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6220 - accuracy: 0.8140\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6240 - accuracy: 0.8132\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6231 - accuracy: 0.8133\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6217 - accuracy: 0.8135\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6230 - accuracy: 0.8136\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6219 - accuracy: 0.8137\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6230 - accuracy: 0.8137\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6225 - accuracy: 0.8141\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6221 - accuracy: 0.8134\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6223 - accuracy: 0.8134\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6218 - accuracy: 0.8139\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6224 - accuracy: 0.8133\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6222 - accuracy: 0.8143\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6214 - accuracy: 0.8139\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6221 - accuracy: 0.8142\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6227 - accuracy: 0.8143\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6215 - accuracy: 0.8144\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6231 - accuracy: 0.8136\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6214 - accuracy: 0.8142\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6226 - accuracy: 0.8129\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6214 - accuracy: 0.8141\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6217 - accuracy: 0.8137\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6208 - accuracy: 0.8142\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6224 - accuracy: 0.8143\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6207 - accuracy: 0.8144\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6214 - accuracy: 0.8144\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6204 - accuracy: 0.8147\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6204 - accuracy: 0.8145\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6198 - accuracy: 0.8141\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6205 - accuracy: 0.8142\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6205 - accuracy: 0.8145\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6205 - accuracy: 0.8150\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6203 - accuracy: 0.8149\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6206 - accuracy: 0.8146\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6202 - accuracy: 0.8148\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6203 - accuracy: 0.8150\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6207 - accuracy: 0.8144\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6209 - accuracy: 0.8153\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6198 - accuracy: 0.8145\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6197 - accuracy: 0.8147\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7849 - accuracy: 0.7657\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6890 - accuracy: 0.7964\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6714 - accuracy: 0.8030\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6608 - accuracy: 0.8049\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6542 - accuracy: 0.8070\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6513 - accuracy: 0.8073\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6478 - accuracy: 0.8081\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6450 - accuracy: 0.8085\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6438 - accuracy: 0.8090\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6398 - accuracy: 0.8093\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6395 - accuracy: 0.8096\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6373 - accuracy: 0.8098\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6373 - accuracy: 0.8099\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6345 - accuracy: 0.8106\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6337 - accuracy: 0.8106\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6343 - accuracy: 0.8106\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6330 - accuracy: 0.8114\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6322 - accuracy: 0.8107\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6329 - accuracy: 0.8105\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6317 - accuracy: 0.8115\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6300 - accuracy: 0.8112\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6297 - accuracy: 0.8118\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6302 - accuracy: 0.8111\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6290 - accuracy: 0.8118\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6276 - accuracy: 0.8122\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6276 - accuracy: 0.8126\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6275 - accuracy: 0.8118\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6266 - accuracy: 0.8124\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6258 - accuracy: 0.8115\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6260 - accuracy: 0.8120\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6256 - accuracy: 0.8129\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6242 - accuracy: 0.8124\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6252 - accuracy: 0.8118\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6262 - accuracy: 0.8118\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6255 - accuracy: 0.8129\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6240 - accuracy: 0.8129\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6235 - accuracy: 0.8132\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6252 - accuracy: 0.8116\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6246 - accuracy: 0.8124\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6235 - accuracy: 0.8130\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6245 - accuracy: 0.8125\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6235 - accuracy: 0.8132\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6237 - accuracy: 0.8127\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6234 - accuracy: 0.8132\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6241 - accuracy: 0.8122\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6249 - accuracy: 0.8122\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6227 - accuracy: 0.8128\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6237 - accuracy: 0.8125\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6223 - accuracy: 0.8130\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6237 - accuracy: 0.8122\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6225 - accuracy: 0.8138\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6217 - accuracy: 0.8133\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6225 - accuracy: 0.8133\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6215 - accuracy: 0.8136\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6231 - accuracy: 0.8125\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6221 - accuracy: 0.8129\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6219 - accuracy: 0.8137\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6214 - accuracy: 0.8132\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6209 - accuracy: 0.8139\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6211 - accuracy: 0.8135\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6216 - accuracy: 0.8134\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6213 - accuracy: 0.8136\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6213 - accuracy: 0.8130\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6205 - accuracy: 0.8139\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6214 - accuracy: 0.8133\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6205 - accuracy: 0.8142\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6210 - accuracy: 0.8146\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6194 - accuracy: 0.8139\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6200 - accuracy: 0.8139\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6204 - accuracy: 0.8146\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6188 - accuracy: 0.8149\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6201 - accuracy: 0.8147\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6190 - accuracy: 0.8141\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6185 - accuracy: 0.8154\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6189 - accuracy: 0.8147\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6188 - accuracy: 0.8150\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6178 - accuracy: 0.8151\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6194 - accuracy: 0.8144\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6182 - accuracy: 0.8149\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6182 - accuracy: 0.8144\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6189 - accuracy: 0.8141\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6179 - accuracy: 0.8154\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6191 - accuracy: 0.8139\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6181 - accuracy: 0.8147\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6177 - accuracy: 0.8151\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6177 - accuracy: 0.8156\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6183 - accuracy: 0.8153\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6182 - accuracy: 0.8149\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6176 - accuracy: 0.8152\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6190 - accuracy: 0.8143\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6181 - accuracy: 0.8156\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6165 - accuracy: 0.8156\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6176 - accuracy: 0.8151\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6167 - accuracy: 0.8161\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6164 - accuracy: 0.8153\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6163 - accuracy: 0.8159\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6174 - accuracy: 0.8159\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6171 - accuracy: 0.8150\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6164 - accuracy: 0.8156\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6165 - accuracy: 0.8158\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7844 - accuracy: 0.7660\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6905 - accuracy: 0.7966\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6779 - accuracy: 0.8001\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6686 - accuracy: 0.8028\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6626 - accuracy: 0.8045\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6589 - accuracy: 0.8062\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6551 - accuracy: 0.8070\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6530 - accuracy: 0.8070\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6494 - accuracy: 0.8078\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6486 - accuracy: 0.8074\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6459 - accuracy: 0.8084\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6446 - accuracy: 0.8083\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6431 - accuracy: 0.8095\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6406 - accuracy: 0.8102\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6395 - accuracy: 0.8097\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6380 - accuracy: 0.8103\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6373 - accuracy: 0.8109\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6361 - accuracy: 0.8106\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6346 - accuracy: 0.8118\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6339 - accuracy: 0.8109\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6333 - accuracy: 0.8117\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6325 - accuracy: 0.8116\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6310 - accuracy: 0.8123\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6314 - accuracy: 0.8120\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6305 - accuracy: 0.8128\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6305 - accuracy: 0.8119\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6298 - accuracy: 0.8129\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6295 - accuracy: 0.8132\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6290 - accuracy: 0.8128\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6280 - accuracy: 0.8129\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6282 - accuracy: 0.8136\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6288 - accuracy: 0.8135\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6268 - accuracy: 0.8143\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6271 - accuracy: 0.8132\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6277 - accuracy: 0.8141\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6272 - accuracy: 0.8138\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6278 - accuracy: 0.8141\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6251 - accuracy: 0.8144\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6252 - accuracy: 0.8143\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6266 - accuracy: 0.8135\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6261 - accuracy: 0.8137\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6262 - accuracy: 0.8141\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6256 - accuracy: 0.8144\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6245 - accuracy: 0.8141\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6246 - accuracy: 0.8147\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6256 - accuracy: 0.8139\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6253 - accuracy: 0.8141\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6248 - accuracy: 0.8143\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6252 - accuracy: 0.8143\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6250 - accuracy: 0.8145\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6255 - accuracy: 0.8141\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6248 - accuracy: 0.8141\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6238 - accuracy: 0.8150\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6233 - accuracy: 0.8152\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6246 - accuracy: 0.8147\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6226 - accuracy: 0.8150\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6231 - accuracy: 0.8149\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6235 - accuracy: 0.8138\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6234 - accuracy: 0.8145\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6229 - accuracy: 0.8145\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6234 - accuracy: 0.8147\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6232 - accuracy: 0.8141\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6227 - accuracy: 0.8151\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6228 - accuracy: 0.8151\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6233 - accuracy: 0.8152\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6226 - accuracy: 0.8151\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6231 - accuracy: 0.8150\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6228 - accuracy: 0.8141\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6222 - accuracy: 0.8144\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6218 - accuracy: 0.8150\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6220 - accuracy: 0.8149\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6211 - accuracy: 0.8152\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6219 - accuracy: 0.8153\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6203 - accuracy: 0.8156\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6217 - accuracy: 0.8152\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6203 - accuracy: 0.8158\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6217 - accuracy: 0.8151\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6207 - accuracy: 0.8158\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6208 - accuracy: 0.8154\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6194 - accuracy: 0.8158\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6200 - accuracy: 0.8163\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6208 - accuracy: 0.8154\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6210 - accuracy: 0.8152\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6197 - accuracy: 0.8164\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6208 - accuracy: 0.8160\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6208 - accuracy: 0.8156\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6200 - accuracy: 0.8155\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6185 - accuracy: 0.8163\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6195 - accuracy: 0.8150\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6196 - accuracy: 0.8158\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6200 - accuracy: 0.8157\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6201 - accuracy: 0.8159\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6199 - accuracy: 0.8153\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6203 - accuracy: 0.8163\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6197 - accuracy: 0.8161\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6197 - accuracy: 0.8158\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6197 - accuracy: 0.8157\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6202 - accuracy: 0.8158\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6194 - accuracy: 0.8162\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6196 - accuracy: 0.8166\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7664 - accuracy: 0.7697\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6758 - accuracy: 0.8005\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6615 - accuracy: 0.8047\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6516 - accuracy: 0.8076\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6459 - accuracy: 0.8089\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6416 - accuracy: 0.8097\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6393 - accuracy: 0.8096\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6361 - accuracy: 0.8105\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6332 - accuracy: 0.8117\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6310 - accuracy: 0.8117\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6298 - accuracy: 0.8115\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6271 - accuracy: 0.8117\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6258 - accuracy: 0.8127\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6246 - accuracy: 0.8127\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6232 - accuracy: 0.8126\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6208 - accuracy: 0.8133\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6199 - accuracy: 0.8133\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6190 - accuracy: 0.8141\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6189 - accuracy: 0.8138\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6175 - accuracy: 0.8135\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6171 - accuracy: 0.8140\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6158 - accuracy: 0.8140\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6154 - accuracy: 0.8145\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6152 - accuracy: 0.8144\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6147 - accuracy: 0.8144\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6139 - accuracy: 0.8145\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6125 - accuracy: 0.8150\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6137 - accuracy: 0.8149\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6133 - accuracy: 0.8144\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6131 - accuracy: 0.8141\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6114 - accuracy: 0.8147\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6121 - accuracy: 0.8144\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6113 - accuracy: 0.8155\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6118 - accuracy: 0.8154\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6120 - accuracy: 0.8151\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6102 - accuracy: 0.8153\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6101 - accuracy: 0.8149\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6092 - accuracy: 0.8162\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6096 - accuracy: 0.8150\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6091 - accuracy: 0.8155\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6088 - accuracy: 0.8152\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6093 - accuracy: 0.8161\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6088 - accuracy: 0.8155\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6079 - accuracy: 0.8157\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6084 - accuracy: 0.8155\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6090 - accuracy: 0.8152\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6074 - accuracy: 0.8155\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6073 - accuracy: 0.8162\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6081 - accuracy: 0.8157\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6071 - accuracy: 0.8164\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6080 - accuracy: 0.8152\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6069 - accuracy: 0.8163\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6071 - accuracy: 0.8163\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6081 - accuracy: 0.8160\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6067 - accuracy: 0.8156\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6066 - accuracy: 0.8159\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6074 - accuracy: 0.8165\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6063 - accuracy: 0.8161\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6050 - accuracy: 0.8164\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6075 - accuracy: 0.8163\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6064 - accuracy: 0.8165\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6054 - accuracy: 0.8167\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6053 - accuracy: 0.8167\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6054 - accuracy: 0.8161\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6053 - accuracy: 0.8168\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6042 - accuracy: 0.8167\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6053 - accuracy: 0.8164\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6060 - accuracy: 0.8167\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6043 - accuracy: 0.8167\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6034 - accuracy: 0.8172\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6046 - accuracy: 0.8174\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6048 - accuracy: 0.8170\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6037 - accuracy: 0.8167\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6041 - accuracy: 0.8172\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6034 - accuracy: 0.8173\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6027 - accuracy: 0.8175\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6044 - accuracy: 0.8174\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6024 - accuracy: 0.8177\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6034 - accuracy: 0.8178\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6024 - accuracy: 0.8179\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6038 - accuracy: 0.8172\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6034 - accuracy: 0.8169\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6024 - accuracy: 0.8176\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6023 - accuracy: 0.8185\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6020 - accuracy: 0.8183\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6022 - accuracy: 0.8179\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6038 - accuracy: 0.8174\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6012 - accuracy: 0.8180\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6019 - accuracy: 0.8180\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6016 - accuracy: 0.8181\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6017 - accuracy: 0.8189\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6019 - accuracy: 0.8180\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6018 - accuracy: 0.8178\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6022 - accuracy: 0.8182\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6011 - accuracy: 0.8180\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6013 - accuracy: 0.8185\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6018 - accuracy: 0.8182\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6013 - accuracy: 0.8184\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6025 - accuracy: 0.8181\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6010 - accuracy: 0.8184\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7643 - accuracy: 0.7709\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6730 - accuracy: 0.7998\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6594 - accuracy: 0.8038\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6513 - accuracy: 0.8053\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6431 - accuracy: 0.8082\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6387 - accuracy: 0.8098\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6351 - accuracy: 0.8103\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6318 - accuracy: 0.8108\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6297 - accuracy: 0.8118\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6260 - accuracy: 0.8120\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6253 - accuracy: 0.8132\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6237 - accuracy: 0.8132\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6223 - accuracy: 0.8128\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6217 - accuracy: 0.8131\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6190 - accuracy: 0.8139\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6183 - accuracy: 0.8139\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6183 - accuracy: 0.8136\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6168 - accuracy: 0.8148\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6152 - accuracy: 0.8140\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6153 - accuracy: 0.8144\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6140 - accuracy: 0.8152\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6128 - accuracy: 0.8153\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6129 - accuracy: 0.8148\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6122 - accuracy: 0.8153\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6118 - accuracy: 0.8147\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6108 - accuracy: 0.8159\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6100 - accuracy: 0.8159\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6094 - accuracy: 0.8156\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6098 - accuracy: 0.8162\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6090 - accuracy: 0.8158\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6087 - accuracy: 0.8162\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6084 - accuracy: 0.8165\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6079 - accuracy: 0.8162\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6065 - accuracy: 0.8164\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6060 - accuracy: 0.8160\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6060 - accuracy: 0.8171\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6046 - accuracy: 0.8167\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6048 - accuracy: 0.8169\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6034 - accuracy: 0.8174\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6032 - accuracy: 0.8165\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6036 - accuracy: 0.8174\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6032 - accuracy: 0.8171\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6032 - accuracy: 0.8176\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6023 - accuracy: 0.8174\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6011 - accuracy: 0.8178\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6014 - accuracy: 0.8179\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6022 - accuracy: 0.8179\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6011 - accuracy: 0.8179\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6007 - accuracy: 0.8189\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6008 - accuracy: 0.8186\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5994 - accuracy: 0.8187\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5992 - accuracy: 0.8193\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5999 - accuracy: 0.8188\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5997 - accuracy: 0.8187\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5997 - accuracy: 0.8191\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5982 - accuracy: 0.8196\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5993 - accuracy: 0.8190\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5984 - accuracy: 0.8197\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5986 - accuracy: 0.8190\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5986 - accuracy: 0.8193\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5986 - accuracy: 0.8198\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5973 - accuracy: 0.8191\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5968 - accuracy: 0.8200\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5977 - accuracy: 0.8200\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5982 - accuracy: 0.8199\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5973 - accuracy: 0.8196\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5972 - accuracy: 0.8196\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5973 - accuracy: 0.8199\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5969 - accuracy: 0.8194\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5975 - accuracy: 0.8192\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5969 - accuracy: 0.8197\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5958 - accuracy: 0.8201\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5977 - accuracy: 0.8194\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5963 - accuracy: 0.8196\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5962 - accuracy: 0.8199\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5969 - accuracy: 0.8205\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5957 - accuracy: 0.8202\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5971 - accuracy: 0.8194\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5969 - accuracy: 0.8201\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5970 - accuracy: 0.8195\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5958 - accuracy: 0.8203\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5959 - accuracy: 0.8194\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5964 - accuracy: 0.8199\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5961 - accuracy: 0.8204\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5966 - accuracy: 0.8200\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5952 - accuracy: 0.8203\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5953 - accuracy: 0.8205\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5951 - accuracy: 0.8203\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5951 - accuracy: 0.8201\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5949 - accuracy: 0.8208\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5965 - accuracy: 0.8202\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5960 - accuracy: 0.8201\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5947 - accuracy: 0.8202\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5963 - accuracy: 0.8198\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5943 - accuracy: 0.8202\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5962 - accuracy: 0.8199\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5962 - accuracy: 0.8196\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5945 - accuracy: 0.8203\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5945 - accuracy: 0.8209\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5954 - accuracy: 0.8200\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7635 - accuracy: 0.7712\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6758 - accuracy: 0.7993\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6611 - accuracy: 0.8036\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6512 - accuracy: 0.8065\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6456 - accuracy: 0.8086\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6405 - accuracy: 0.8103\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6384 - accuracy: 0.8107\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6356 - accuracy: 0.8111\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6330 - accuracy: 0.8125\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6314 - accuracy: 0.8120\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6299 - accuracy: 0.8125\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6279 - accuracy: 0.8128\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6269 - accuracy: 0.8125\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6263 - accuracy: 0.8129\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6249 - accuracy: 0.8140\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6240 - accuracy: 0.8133\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6227 - accuracy: 0.8138\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6219 - accuracy: 0.8135\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6206 - accuracy: 0.8141\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6204 - accuracy: 0.8140\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6186 - accuracy: 0.8143\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6190 - accuracy: 0.8139\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6178 - accuracy: 0.8149\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6180 - accuracy: 0.8147\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6166 - accuracy: 0.8149\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6170 - accuracy: 0.8142\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6163 - accuracy: 0.8147\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6165 - accuracy: 0.8149\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6152 - accuracy: 0.8152\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6157 - accuracy: 0.8151\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6142 - accuracy: 0.8152\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6145 - accuracy: 0.8153\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6147 - accuracy: 0.8147\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6119 - accuracy: 0.8156\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6141 - accuracy: 0.8156\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6127 - accuracy: 0.8157\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6128 - accuracy: 0.8164\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6119 - accuracy: 0.8157\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6112 - accuracy: 0.8160\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6115 - accuracy: 0.8169\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6108 - accuracy: 0.8164\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6102 - accuracy: 0.8169\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6093 - accuracy: 0.8170\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6090 - accuracy: 0.8170\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6083 - accuracy: 0.8167\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6083 - accuracy: 0.8167\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6079 - accuracy: 0.8168\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6076 - accuracy: 0.8177\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6082 - accuracy: 0.8174\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6079 - accuracy: 0.8169\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6075 - accuracy: 0.8174\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6071 - accuracy: 0.8179\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6070 - accuracy: 0.8180\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6062 - accuracy: 0.8183\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6061 - accuracy: 0.8185\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6068 - accuracy: 0.8176\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6062 - accuracy: 0.8178\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6070 - accuracy: 0.8175\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6059 - accuracy: 0.8180\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6056 - accuracy: 0.8186\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6062 - accuracy: 0.8184\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6061 - accuracy: 0.8179\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6054 - accuracy: 0.8186\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6056 - accuracy: 0.8191\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6056 - accuracy: 0.8181\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6050 - accuracy: 0.8177\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6052 - accuracy: 0.8189\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6043 - accuracy: 0.8185\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6038 - accuracy: 0.8184\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6050 - accuracy: 0.8191\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6042 - accuracy: 0.8192\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6044 - accuracy: 0.8191\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6046 - accuracy: 0.8189\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6027 - accuracy: 0.8192\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6039 - accuracy: 0.8186\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6035 - accuracy: 0.8188\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6037 - accuracy: 0.8198\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6041 - accuracy: 0.8194\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6037 - accuracy: 0.8182\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6034 - accuracy: 0.8193\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6036 - accuracy: 0.8191\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6040 - accuracy: 0.8187\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6026 - accuracy: 0.8195\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6037 - accuracy: 0.8191\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6036 - accuracy: 0.8186\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6028 - accuracy: 0.8190\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6045 - accuracy: 0.8188\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6022 - accuracy: 0.8201\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6020 - accuracy: 0.8195\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6040 - accuracy: 0.8191\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6022 - accuracy: 0.8190\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6019 - accuracy: 0.8194\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6033 - accuracy: 0.8190\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6027 - accuracy: 0.8191\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6029 - accuracy: 0.8194\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6012 - accuracy: 0.8197\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6025 - accuracy: 0.8194\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6029 - accuracy: 0.8196\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6016 - accuracy: 0.8193\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6015 - accuracy: 0.8192\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7575 - accuracy: 0.7723\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6680 - accuracy: 0.8017\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6519 - accuracy: 0.8059\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6439 - accuracy: 0.8083\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6367 - accuracy: 0.8102\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6317 - accuracy: 0.8116\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6279 - accuracy: 0.8128\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6252 - accuracy: 0.8129\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6228 - accuracy: 0.8135\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6201 - accuracy: 0.8133\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6180 - accuracy: 0.8144\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6169 - accuracy: 0.8139\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6144 - accuracy: 0.8150\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6119 - accuracy: 0.8155\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6124 - accuracy: 0.8143\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6093 - accuracy: 0.8158\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6097 - accuracy: 0.8155\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6080 - accuracy: 0.8157\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6066 - accuracy: 0.8162\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6062 - accuracy: 0.8155\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6042 - accuracy: 0.8173\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6034 - accuracy: 0.8171\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6038 - accuracy: 0.8169\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6003 - accuracy: 0.8177\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6007 - accuracy: 0.8174\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6010 - accuracy: 0.8174\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5987 - accuracy: 0.8177\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6004 - accuracy: 0.8179\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5973 - accuracy: 0.8184\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5971 - accuracy: 0.8185\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5972 - accuracy: 0.8186\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5956 - accuracy: 0.8188\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5963 - accuracy: 0.8187\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5957 - accuracy: 0.8190\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5953 - accuracy: 0.8194\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5936 - accuracy: 0.8194\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5953 - accuracy: 0.8187\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5940 - accuracy: 0.8195\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5934 - accuracy: 0.8199\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5943 - accuracy: 0.8193\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5934 - accuracy: 0.8191\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5937 - accuracy: 0.8196\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5927 - accuracy: 0.8200\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5913 - accuracy: 0.8204\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5926 - accuracy: 0.8199\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5933 - accuracy: 0.8194\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5927 - accuracy: 0.8197\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5919 - accuracy: 0.8197\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5918 - accuracy: 0.8205\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5915 - accuracy: 0.8202\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5907 - accuracy: 0.8208\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5908 - accuracy: 0.8205\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5909 - accuracy: 0.8199\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5908 - accuracy: 0.8198\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5901 - accuracy: 0.8208\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5894 - accuracy: 0.8212\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5896 - accuracy: 0.8211\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5896 - accuracy: 0.8210\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5898 - accuracy: 0.8208\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5881 - accuracy: 0.8213\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5887 - accuracy: 0.8205\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5905 - accuracy: 0.8206\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5883 - accuracy: 0.8212\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5896 - accuracy: 0.8205\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5880 - accuracy: 0.8211\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5881 - accuracy: 0.8208\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5886 - accuracy: 0.8209\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5879 - accuracy: 0.8218\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5888 - accuracy: 0.8206\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5880 - accuracy: 0.8209\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5888 - accuracy: 0.8203\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5890 - accuracy: 0.8209\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5882 - accuracy: 0.8207\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5878 - accuracy: 0.8212\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5881 - accuracy: 0.8210\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5879 - accuracy: 0.8210\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5886 - accuracy: 0.8215\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5887 - accuracy: 0.8218\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5868 - accuracy: 0.8215\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5886 - accuracy: 0.8212\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5877 - accuracy: 0.8218\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5887 - accuracy: 0.8209\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5876 - accuracy: 0.8215\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5872 - accuracy: 0.8218\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5875 - accuracy: 0.8215\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5862 - accuracy: 0.8218\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5868 - accuracy: 0.8219\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5868 - accuracy: 0.8219\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5866 - accuracy: 0.8219\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5873 - accuracy: 0.8211\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5868 - accuracy: 0.8221\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5862 - accuracy: 0.8221\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5860 - accuracy: 0.8217\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5863 - accuracy: 0.8217\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5866 - accuracy: 0.8213\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5858 - accuracy: 0.8218\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5852 - accuracy: 0.8220\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5848 - accuracy: 0.8226\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5857 - accuracy: 0.8216\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5866 - accuracy: 0.8215\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7509 - accuracy: 0.7749\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6635 - accuracy: 0.8019\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6450 - accuracy: 0.8072\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6390 - accuracy: 0.8091\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6331 - accuracy: 0.8110\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6305 - accuracy: 0.8114\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6275 - accuracy: 0.8123\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6262 - accuracy: 0.8125\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6242 - accuracy: 0.8127\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6228 - accuracy: 0.8136\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6208 - accuracy: 0.8134\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6190 - accuracy: 0.8137\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6178 - accuracy: 0.8139\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6162 - accuracy: 0.8139\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6139 - accuracy: 0.8143\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6126 - accuracy: 0.8152\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6117 - accuracy: 0.8152\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6094 - accuracy: 0.8158\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6078 - accuracy: 0.8154\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6064 - accuracy: 0.8162\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6060 - accuracy: 0.8162\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6050 - accuracy: 0.8162\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6046 - accuracy: 0.8164\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6028 - accuracy: 0.8168\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6023 - accuracy: 0.8176\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6006 - accuracy: 0.8183\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6008 - accuracy: 0.8176\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5997 - accuracy: 0.8177\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5978 - accuracy: 0.8188\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5987 - accuracy: 0.8183\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5964 - accuracy: 0.8190\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5985 - accuracy: 0.8187\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5966 - accuracy: 0.8185\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5961 - accuracy: 0.8190\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5961 - accuracy: 0.8192\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5960 - accuracy: 0.8199\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5950 - accuracy: 0.8192\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5951 - accuracy: 0.8194\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5950 - accuracy: 0.8193\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5940 - accuracy: 0.8201\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5935 - accuracy: 0.8207\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5935 - accuracy: 0.8201\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5936 - accuracy: 0.8198\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5930 - accuracy: 0.8194\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5919 - accuracy: 0.8203\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5919 - accuracy: 0.8205\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5924 - accuracy: 0.8201\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5918 - accuracy: 0.8210\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5906 - accuracy: 0.8203\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5915 - accuracy: 0.8207\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5911 - accuracy: 0.8205\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5902 - accuracy: 0.8209\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5903 - accuracy: 0.8211\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5901 - accuracy: 0.8210\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5899 - accuracy: 0.8206\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5893 - accuracy: 0.8217\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5887 - accuracy: 0.8213\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5898 - accuracy: 0.8209\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5896 - accuracy: 0.8213\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5898 - accuracy: 0.8216\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5899 - accuracy: 0.8211\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5892 - accuracy: 0.8218\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5887 - accuracy: 0.8215\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5883 - accuracy: 0.8215\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5896 - accuracy: 0.8210\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5882 - accuracy: 0.8213\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5876 - accuracy: 0.8214\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5888 - accuracy: 0.8216\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5879 - accuracy: 0.8218\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5888 - accuracy: 0.8220\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5880 - accuracy: 0.8211\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5885 - accuracy: 0.8214\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5873 - accuracy: 0.8218\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5874 - accuracy: 0.8222\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5875 - accuracy: 0.8221\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5874 - accuracy: 0.8220\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5879 - accuracy: 0.8214\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5869 - accuracy: 0.8218\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5867 - accuracy: 0.8220\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5882 - accuracy: 0.8215\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5870 - accuracy: 0.8222\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5873 - accuracy: 0.8224\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5872 - accuracy: 0.8216\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5875 - accuracy: 0.8219\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5869 - accuracy: 0.8212\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5851 - accuracy: 0.8218\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5860 - accuracy: 0.8226\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5866 - accuracy: 0.8219\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5882 - accuracy: 0.8214\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5869 - accuracy: 0.8217\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5852 - accuracy: 0.8223\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5856 - accuracy: 0.8219\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5875 - accuracy: 0.8216\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5869 - accuracy: 0.8223\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5854 - accuracy: 0.8217\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5863 - accuracy: 0.8223\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5850 - accuracy: 0.8222\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5858 - accuracy: 0.8220\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5855 - accuracy: 0.8225\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5856 - accuracy: 0.8224\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7590 - accuracy: 0.7721\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6692 - accuracy: 0.8000\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6540 - accuracy: 0.8050\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6461 - accuracy: 0.8077\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6396 - accuracy: 0.8094\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6360 - accuracy: 0.8102\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6324 - accuracy: 0.8119\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6296 - accuracy: 0.8128\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6281 - accuracy: 0.8127\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6258 - accuracy: 0.8130\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6245 - accuracy: 0.8130\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6224 - accuracy: 0.8137\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6207 - accuracy: 0.8137\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6185 - accuracy: 0.8146\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6173 - accuracy: 0.8144\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6155 - accuracy: 0.8145\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6141 - accuracy: 0.8148\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6129 - accuracy: 0.8153\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6131 - accuracy: 0.8150\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6111 - accuracy: 0.8155\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6100 - accuracy: 0.8153\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6096 - accuracy: 0.8154\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6083 - accuracy: 0.8160\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6076 - accuracy: 0.8163\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6081 - accuracy: 0.8159\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6065 - accuracy: 0.8165\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6063 - accuracy: 0.8166\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6049 - accuracy: 0.8176\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6038 - accuracy: 0.8168\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6040 - accuracy: 0.8176\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6041 - accuracy: 0.8167\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6029 - accuracy: 0.8173\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6030 - accuracy: 0.8174\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6008 - accuracy: 0.8190\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6015 - accuracy: 0.8179\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6014 - accuracy: 0.8180\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5997 - accuracy: 0.8191\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5989 - accuracy: 0.8187\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5993 - accuracy: 0.8189\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5982 - accuracy: 0.8195\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5982 - accuracy: 0.8192\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5974 - accuracy: 0.8189\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5976 - accuracy: 0.8187\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5958 - accuracy: 0.8202\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5967 - accuracy: 0.8200\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5966 - accuracy: 0.8200\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5945 - accuracy: 0.8198\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5940 - accuracy: 0.8202\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5941 - accuracy: 0.8194\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5940 - accuracy: 0.8209\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5937 - accuracy: 0.8207\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5941 - accuracy: 0.8204\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5928 - accuracy: 0.8208\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5941 - accuracy: 0.8208\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5926 - accuracy: 0.8211\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5924 - accuracy: 0.8212\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5911 - accuracy: 0.8212\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5921 - accuracy: 0.8213\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5926 - accuracy: 0.8210\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5923 - accuracy: 0.8215\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5913 - accuracy: 0.8215\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5921 - accuracy: 0.8213\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5920 - accuracy: 0.8215\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5914 - accuracy: 0.8212\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5912 - accuracy: 0.8213\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5902 - accuracy: 0.8213\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5911 - accuracy: 0.8210\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5904 - accuracy: 0.8216\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5913 - accuracy: 0.8211\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5889 - accuracy: 0.8217\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5909 - accuracy: 0.8215\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5903 - accuracy: 0.8214\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5885 - accuracy: 0.8217\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5895 - accuracy: 0.8209\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5897 - accuracy: 0.8206\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5882 - accuracy: 0.8220\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5890 - accuracy: 0.8213\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5886 - accuracy: 0.8216\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5881 - accuracy: 0.8222\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5880 - accuracy: 0.8219\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5882 - accuracy: 0.8221\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5882 - accuracy: 0.8219\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5882 - accuracy: 0.8223\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5874 - accuracy: 0.8224\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5877 - accuracy: 0.8230\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5871 - accuracy: 0.8223\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5876 - accuracy: 0.8221\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5869 - accuracy: 0.8223\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5873 - accuracy: 0.8225\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5882 - accuracy: 0.8225\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5874 - accuracy: 0.8222\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5873 - accuracy: 0.8228\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5876 - accuracy: 0.8219\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5876 - accuracy: 0.8220\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5874 - accuracy: 0.8221\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5861 - accuracy: 0.8221\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5864 - accuracy: 0.8228\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5865 - accuracy: 0.8227\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5873 - accuracy: 0.8223\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5867 - accuracy: 0.8225\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7519 - accuracy: 0.7732\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6617 - accuracy: 0.8032\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6446 - accuracy: 0.8077\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6355 - accuracy: 0.8097\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6301 - accuracy: 0.8116\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6266 - accuracy: 0.8116\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6243 - accuracy: 0.8124\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6202 - accuracy: 0.8135\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6179 - accuracy: 0.8140\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6159 - accuracy: 0.8142\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6132 - accuracy: 0.8142\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6125 - accuracy: 0.8146\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6107 - accuracy: 0.8145\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6090 - accuracy: 0.8152\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6088 - accuracy: 0.8154\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6055 - accuracy: 0.8163\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6043 - accuracy: 0.8166\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6023 - accuracy: 0.8168\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6010 - accuracy: 0.8175\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6005 - accuracy: 0.8170\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5983 - accuracy: 0.8182\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5978 - accuracy: 0.8180\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5968 - accuracy: 0.8177\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5965 - accuracy: 0.8183\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5961 - accuracy: 0.8180\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5953 - accuracy: 0.8185\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5944 - accuracy: 0.8188\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5947 - accuracy: 0.8191\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5937 - accuracy: 0.8200\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5934 - accuracy: 0.8196\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5925 - accuracy: 0.8195\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5904 - accuracy: 0.8208\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5906 - accuracy: 0.8200\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5891 - accuracy: 0.8201\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5881 - accuracy: 0.8213\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5874 - accuracy: 0.8210\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5881 - accuracy: 0.8207\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5873 - accuracy: 0.8215\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5871 - accuracy: 0.8207\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5865 - accuracy: 0.8212\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5862 - accuracy: 0.8209\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5843 - accuracy: 0.8218\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5851 - accuracy: 0.8217\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5845 - accuracy: 0.8213\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5842 - accuracy: 0.8226\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5829 - accuracy: 0.8223\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5830 - accuracy: 0.8224\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5827 - accuracy: 0.8222\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5818 - accuracy: 0.8227\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5823 - accuracy: 0.8229\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5809 - accuracy: 0.8227\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5811 - accuracy: 0.8227\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5817 - accuracy: 0.8232\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5821 - accuracy: 0.8224\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5803 - accuracy: 0.8229\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5814 - accuracy: 0.8225\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5799 - accuracy: 0.8229\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5818 - accuracy: 0.8222\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5808 - accuracy: 0.8220\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5785 - accuracy: 0.8229\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5791 - accuracy: 0.8235\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5794 - accuracy: 0.8236\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5786 - accuracy: 0.8237\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5800 - accuracy: 0.8225\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5799 - accuracy: 0.8231\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5793 - accuracy: 0.8234\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5790 - accuracy: 0.8236\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5787 - accuracy: 0.8241\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5784 - accuracy: 0.8235\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5780 - accuracy: 0.8234\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5786 - accuracy: 0.8238\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5785 - accuracy: 0.8230\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5784 - accuracy: 0.8235\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5772 - accuracy: 0.8237\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5782 - accuracy: 0.8234\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5779 - accuracy: 0.8234\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5777 - accuracy: 0.8236\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5770 - accuracy: 0.8240\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5778 - accuracy: 0.8234\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5774 - accuracy: 0.8240\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5774 - accuracy: 0.8239\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5777 - accuracy: 0.8240\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5762 - accuracy: 0.8236\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5774 - accuracy: 0.8244\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5771 - accuracy: 0.8238\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5759 - accuracy: 0.8238\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5758 - accuracy: 0.8239\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5754 - accuracy: 0.8241\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5757 - accuracy: 0.8241\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5763 - accuracy: 0.8243\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5756 - accuracy: 0.8238\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5759 - accuracy: 0.8242\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5759 - accuracy: 0.8244\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5754 - accuracy: 0.8240\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5752 - accuracy: 0.8244\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5752 - accuracy: 0.8241\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5758 - accuracy: 0.8243\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5744 - accuracy: 0.8245\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5747 - accuracy: 0.8237\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5751 - accuracy: 0.8251\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 12s 3ms/step - loss: 0.7488 - accuracy: 0.7743\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6581 - accuracy: 0.8037\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6435 - accuracy: 0.8077\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6341 - accuracy: 0.8096\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6283 - accuracy: 0.8119\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6250 - accuracy: 0.8121\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6223 - accuracy: 0.8127\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6185 - accuracy: 0.8134\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6164 - accuracy: 0.8143\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6151 - accuracy: 0.8134\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6133 - accuracy: 0.8143\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6112 - accuracy: 0.8146\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6099 - accuracy: 0.8150\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6080 - accuracy: 0.8153\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6055 - accuracy: 0.8154\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6044 - accuracy: 0.8163\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6030 - accuracy: 0.8158\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6013 - accuracy: 0.8162\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5997 - accuracy: 0.8168\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5997 - accuracy: 0.8170\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5976 - accuracy: 0.8171\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5957 - accuracy: 0.8179\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5935 - accuracy: 0.8185\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5939 - accuracy: 0.8185\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5921 - accuracy: 0.8190\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5925 - accuracy: 0.8186\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5909 - accuracy: 0.8197\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5912 - accuracy: 0.8191\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5895 - accuracy: 0.8192\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5886 - accuracy: 0.8197\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5888 - accuracy: 0.8201\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5885 - accuracy: 0.8207\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5879 - accuracy: 0.8203\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5870 - accuracy: 0.8201\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5864 - accuracy: 0.8209\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5880 - accuracy: 0.8196\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5869 - accuracy: 0.8210\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5869 - accuracy: 0.8201\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5850 - accuracy: 0.8209\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5857 - accuracy: 0.8207\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5848 - accuracy: 0.8212\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5842 - accuracy: 0.8215\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5836 - accuracy: 0.8228\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5844 - accuracy: 0.8216\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5840 - accuracy: 0.8215\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5843 - accuracy: 0.8214\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5827 - accuracy: 0.8224\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5832 - accuracy: 0.8209\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5829 - accuracy: 0.8217\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5820 - accuracy: 0.8223\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5817 - accuracy: 0.8227\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5824 - accuracy: 0.8218\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5815 - accuracy: 0.8228\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5814 - accuracy: 0.8222\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5810 - accuracy: 0.8221\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5808 - accuracy: 0.8223\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5806 - accuracy: 0.8226\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5803 - accuracy: 0.8232\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5810 - accuracy: 0.8222\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5793 - accuracy: 0.8231\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5804 - accuracy: 0.8221\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5802 - accuracy: 0.8232\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5794 - accuracy: 0.8225\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5808 - accuracy: 0.8219\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5793 - accuracy: 0.8222\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5803 - accuracy: 0.8224\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5791 - accuracy: 0.8233\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5786 - accuracy: 0.8231\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5775 - accuracy: 0.8232\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5785 - accuracy: 0.8232\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5768 - accuracy: 0.8242\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5780 - accuracy: 0.8231\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5778 - accuracy: 0.8234\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5782 - accuracy: 0.8232\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5777 - accuracy: 0.8232\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5781 - accuracy: 0.8231\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5778 - accuracy: 0.8233\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5769 - accuracy: 0.8233\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5779 - accuracy: 0.8233\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5768 - accuracy: 0.8235\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5768 - accuracy: 0.8233\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5763 - accuracy: 0.8230\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5760 - accuracy: 0.8231\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5770 - accuracy: 0.8234\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5770 - accuracy: 0.8232\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5763 - accuracy: 0.8229\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5768 - accuracy: 0.8232\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5763 - accuracy: 0.8235\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5752 - accuracy: 0.8241\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5764 - accuracy: 0.8235\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5762 - accuracy: 0.8234\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5756 - accuracy: 0.8240\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5759 - accuracy: 0.8235\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5754 - accuracy: 0.8238\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5756 - accuracy: 0.8232\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5745 - accuracy: 0.8245\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5758 - accuracy: 0.8234\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5750 - accuracy: 0.8236\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5746 - accuracy: 0.8241\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5759 - accuracy: 0.8240\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7528 - accuracy: 0.7736\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6629 - accuracy: 0.8027\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6470 - accuracy: 0.8070\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6388 - accuracy: 0.8091\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6324 - accuracy: 0.8113\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6294 - accuracy: 0.8119\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6245 - accuracy: 0.8136\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6212 - accuracy: 0.8136\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6173 - accuracy: 0.8144\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6166 - accuracy: 0.8146\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6139 - accuracy: 0.8150\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6129 - accuracy: 0.8148\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6102 - accuracy: 0.8154\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6087 - accuracy: 0.8157\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6078 - accuracy: 0.8161\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6055 - accuracy: 0.8162\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6037 - accuracy: 0.8167\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6026 - accuracy: 0.8168\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6022 - accuracy: 0.8175\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6016 - accuracy: 0.8172\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6002 - accuracy: 0.8175\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6003 - accuracy: 0.8181\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5998 - accuracy: 0.8183\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5981 - accuracy: 0.8184\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5982 - accuracy: 0.8184\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5974 - accuracy: 0.8182\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5970 - accuracy: 0.8185\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5967 - accuracy: 0.8186\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5949 - accuracy: 0.8200\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5956 - accuracy: 0.8191\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5942 - accuracy: 0.8196\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5939 - accuracy: 0.8194\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5926 - accuracy: 0.8194\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5925 - accuracy: 0.8194\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5907 - accuracy: 0.8201\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5910 - accuracy: 0.8201\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5909 - accuracy: 0.8203\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5909 - accuracy: 0.8201\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5910 - accuracy: 0.8203\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5902 - accuracy: 0.8212\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5891 - accuracy: 0.8203\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5888 - accuracy: 0.8212\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5884 - accuracy: 0.8211\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5885 - accuracy: 0.8207\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5880 - accuracy: 0.8210\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5874 - accuracy: 0.8209\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5875 - accuracy: 0.8213\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5868 - accuracy: 0.8218\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5856 - accuracy: 0.8220\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5870 - accuracy: 0.8212\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5863 - accuracy: 0.8218\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5856 - accuracy: 0.8219\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5862 - accuracy: 0.8214\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5859 - accuracy: 0.8218\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5855 - accuracy: 0.8215\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5857 - accuracy: 0.8215\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5840 - accuracy: 0.8225\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5845 - accuracy: 0.8220\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5846 - accuracy: 0.8214\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5842 - accuracy: 0.8217\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5834 - accuracy: 0.8220\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5837 - accuracy: 0.8225\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5840 - accuracy: 0.8230\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5835 - accuracy: 0.8220\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5829 - accuracy: 0.8222\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5835 - accuracy: 0.8229\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5830 - accuracy: 0.8223\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5813 - accuracy: 0.8228\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5830 - accuracy: 0.8227\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5823 - accuracy: 0.8228\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5827 - accuracy: 0.8220\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5833 - accuracy: 0.8223\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5816 - accuracy: 0.8234\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5818 - accuracy: 0.8226\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5824 - accuracy: 0.8232\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5813 - accuracy: 0.8238\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5826 - accuracy: 0.8230\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5820 - accuracy: 0.8226\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5815 - accuracy: 0.8235\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5820 - accuracy: 0.8225\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5814 - accuracy: 0.8235\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5810 - accuracy: 0.8234\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5817 - accuracy: 0.8227\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5821 - accuracy: 0.8226\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5820 - accuracy: 0.8229\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5811 - accuracy: 0.8239\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5812 - accuracy: 0.8231\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5808 - accuracy: 0.8234\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5801 - accuracy: 0.8236\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5797 - accuracy: 0.8229\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5807 - accuracy: 0.8236\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5815 - accuracy: 0.8230\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5814 - accuracy: 0.8227\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5804 - accuracy: 0.8233\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5803 - accuracy: 0.8238\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5798 - accuracy: 0.8238\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5800 - accuracy: 0.8238\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5799 - accuracy: 0.8234\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5791 - accuracy: 0.8239\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5797 - accuracy: 0.8238\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7468 - accuracy: 0.7755\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6610 - accuracy: 0.8022\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6436 - accuracy: 0.8081\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6355 - accuracy: 0.8098\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6276 - accuracy: 0.8113\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6223 - accuracy: 0.8121\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6190 - accuracy: 0.8133\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6164 - accuracy: 0.8138\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6129 - accuracy: 0.8141\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6115 - accuracy: 0.8146\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6079 - accuracy: 0.8151\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6058 - accuracy: 0.8155\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6015 - accuracy: 0.8166\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5990 - accuracy: 0.8181\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5953 - accuracy: 0.8187\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5936 - accuracy: 0.8194\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5931 - accuracy: 0.8191\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5909 - accuracy: 0.8196\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5904 - accuracy: 0.8194\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5895 - accuracy: 0.8199\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5877 - accuracy: 0.8204\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5876 - accuracy: 0.8197\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5855 - accuracy: 0.8210\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5869 - accuracy: 0.8205\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5845 - accuracy: 0.8206\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5836 - accuracy: 0.8215\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5832 - accuracy: 0.8213\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5822 - accuracy: 0.8210\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5821 - accuracy: 0.8217\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5810 - accuracy: 0.8218\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5807 - accuracy: 0.8221\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5794 - accuracy: 0.8221\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5789 - accuracy: 0.8226\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5788 - accuracy: 0.8226\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5772 - accuracy: 0.8227\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5775 - accuracy: 0.8217\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5773 - accuracy: 0.8225\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5770 - accuracy: 0.8233\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5763 - accuracy: 0.8227\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5754 - accuracy: 0.8237\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5747 - accuracy: 0.8235\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5739 - accuracy: 0.8238\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5755 - accuracy: 0.8227\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5744 - accuracy: 0.8230\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5739 - accuracy: 0.8239\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5738 - accuracy: 0.8238\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5731 - accuracy: 0.8241\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5724 - accuracy: 0.8237\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5735 - accuracy: 0.8241\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5732 - accuracy: 0.8239\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5725 - accuracy: 0.8242\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5719 - accuracy: 0.8245\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5725 - accuracy: 0.8235\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5718 - accuracy: 0.8252\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5708 - accuracy: 0.8251\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5707 - accuracy: 0.8252\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5716 - accuracy: 0.8241\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5712 - accuracy: 0.8242\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5712 - accuracy: 0.8243\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5706 - accuracy: 0.8243\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5708 - accuracy: 0.8243\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5696 - accuracy: 0.8253\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5711 - accuracy: 0.8241\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5698 - accuracy: 0.8251\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5705 - accuracy: 0.8248\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5701 - accuracy: 0.8243\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5691 - accuracy: 0.8255\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5700 - accuracy: 0.8246\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5688 - accuracy: 0.8247\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5689 - accuracy: 0.8253\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5699 - accuracy: 0.8249\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5685 - accuracy: 0.8249\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5692 - accuracy: 0.8250\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5690 - accuracy: 0.8260\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5699 - accuracy: 0.8248\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5687 - accuracy: 0.8248\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5683 - accuracy: 0.8257\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5680 - accuracy: 0.8250\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5685 - accuracy: 0.8259\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5689 - accuracy: 0.8245\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5679 - accuracy: 0.8251\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5679 - accuracy: 0.8253\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5673 - accuracy: 0.8256\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5678 - accuracy: 0.8252\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5676 - accuracy: 0.8258\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5675 - accuracy: 0.8250\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5680 - accuracy: 0.8248\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5661 - accuracy: 0.8257\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5675 - accuracy: 0.8260\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5663 - accuracy: 0.8258\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5674 - accuracy: 0.8252\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5665 - accuracy: 0.8258\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5668 - accuracy: 0.8257\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5661 - accuracy: 0.8257\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5659 - accuracy: 0.8260\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5662 - accuracy: 0.8259\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5671 - accuracy: 0.8253\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5668 - accuracy: 0.8254\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5666 - accuracy: 0.8255\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5666 - accuracy: 0.8251\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 12s 3ms/step - loss: 0.7466 - accuracy: 0.7737\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6591 - accuracy: 0.8024\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6422 - accuracy: 0.8076\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6327 - accuracy: 0.8092\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6259 - accuracy: 0.8113\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6205 - accuracy: 0.8127\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6171 - accuracy: 0.8134\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6152 - accuracy: 0.8140\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6111 - accuracy: 0.8146\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6085 - accuracy: 0.8148\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6071 - accuracy: 0.8152\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6044 - accuracy: 0.8158\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6022 - accuracy: 0.8161\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6005 - accuracy: 0.8171\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5985 - accuracy: 0.8164\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5955 - accuracy: 0.8180\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5947 - accuracy: 0.8182\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5912 - accuracy: 0.8185\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5904 - accuracy: 0.8195\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5889 - accuracy: 0.8204\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5884 - accuracy: 0.8195\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5874 - accuracy: 0.8203\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5866 - accuracy: 0.8205\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5854 - accuracy: 0.8213\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5840 - accuracy: 0.8209\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5834 - accuracy: 0.8215\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5830 - accuracy: 0.8211\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5818 - accuracy: 0.8215\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5813 - accuracy: 0.8219\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5799 - accuracy: 0.8228\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5800 - accuracy: 0.8227\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5782 - accuracy: 0.8223\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5779 - accuracy: 0.8232\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5787 - accuracy: 0.8220\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5779 - accuracy: 0.8227\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5781 - accuracy: 0.8229\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5767 - accuracy: 0.8228\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5764 - accuracy: 0.8234\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5758 - accuracy: 0.8234\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5772 - accuracy: 0.8229\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5754 - accuracy: 0.8237\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5756 - accuracy: 0.8235\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5753 - accuracy: 0.8232\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5743 - accuracy: 0.8235\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5750 - accuracy: 0.8229\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5735 - accuracy: 0.8234\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5741 - accuracy: 0.8239\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5748 - accuracy: 0.8236\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5729 - accuracy: 0.8241\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5735 - accuracy: 0.8243\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5726 - accuracy: 0.8242\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5721 - accuracy: 0.8245\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5730 - accuracy: 0.8247\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5718 - accuracy: 0.8247\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5723 - accuracy: 0.8247\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5723 - accuracy: 0.8242\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5721 - accuracy: 0.8244\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5725 - accuracy: 0.8243\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5708 - accuracy: 0.8251\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5718 - accuracy: 0.8249\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5718 - accuracy: 0.8250\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5706 - accuracy: 0.8247\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5717 - accuracy: 0.8245\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5715 - accuracy: 0.8246\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5713 - accuracy: 0.8243\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5701 - accuracy: 0.8249\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5698 - accuracy: 0.8258\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5703 - accuracy: 0.8249\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5699 - accuracy: 0.8256\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5702 - accuracy: 0.8257\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5705 - accuracy: 0.8256\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5702 - accuracy: 0.8244\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5696 - accuracy: 0.8251\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5703 - accuracy: 0.8248\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5692 - accuracy: 0.8255\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5687 - accuracy: 0.8254\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5693 - accuracy: 0.8251\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5685 - accuracy: 0.8258\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5692 - accuracy: 0.8249\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5695 - accuracy: 0.8248\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5676 - accuracy: 0.8261\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5685 - accuracy: 0.8255\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5687 - accuracy: 0.8250\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5673 - accuracy: 0.8259\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5682 - accuracy: 0.8252\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5683 - accuracy: 0.8259\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5677 - accuracy: 0.8254\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5674 - accuracy: 0.8259\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5674 - accuracy: 0.8249\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5671 - accuracy: 0.8252\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5669 - accuracy: 0.8255\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5683 - accuracy: 0.8257\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5676 - accuracy: 0.8254\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5679 - accuracy: 0.8254\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5678 - accuracy: 0.8258\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5673 - accuracy: 0.8258\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5677 - accuracy: 0.8250\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5675 - accuracy: 0.8260\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5669 - accuracy: 0.8259\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5670 - accuracy: 0.8260\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7480 - accuracy: 0.7745\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6591 - accuracy: 0.8024\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6417 - accuracy: 0.8082\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6351 - accuracy: 0.8099\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6275 - accuracy: 0.8110\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6240 - accuracy: 0.8124\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6211 - accuracy: 0.8132\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6190 - accuracy: 0.8132\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6146 - accuracy: 0.8145\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6130 - accuracy: 0.8146\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6103 - accuracy: 0.8149\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6080 - accuracy: 0.8153\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6047 - accuracy: 0.8162\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6032 - accuracy: 0.8159\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6022 - accuracy: 0.8165\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5988 - accuracy: 0.8176\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5965 - accuracy: 0.8185\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5965 - accuracy: 0.8186\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5942 - accuracy: 0.8187\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5927 - accuracy: 0.8190\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5909 - accuracy: 0.8195\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5906 - accuracy: 0.8194\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5889 - accuracy: 0.8202\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5894 - accuracy: 0.8200\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5879 - accuracy: 0.8206\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5869 - accuracy: 0.8211\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5860 - accuracy: 0.8204\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5860 - accuracy: 0.8214\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5849 - accuracy: 0.8216\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5840 - accuracy: 0.8216\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5837 - accuracy: 0.8214\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5833 - accuracy: 0.8220\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5827 - accuracy: 0.8223\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5820 - accuracy: 0.8222\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5809 - accuracy: 0.8227\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5811 - accuracy: 0.8220\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5803 - accuracy: 0.8229\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5800 - accuracy: 0.8227\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5794 - accuracy: 0.8228\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5789 - accuracy: 0.8229\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5800 - accuracy: 0.8224\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5786 - accuracy: 0.8226\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5777 - accuracy: 0.8235\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5781 - accuracy: 0.8231\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5776 - accuracy: 0.8233\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5764 - accuracy: 0.8235\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5768 - accuracy: 0.8229\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5757 - accuracy: 0.8240\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5769 - accuracy: 0.8235\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5751 - accuracy: 0.8237\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5758 - accuracy: 0.8236\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5750 - accuracy: 0.8243\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5754 - accuracy: 0.8240\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5749 - accuracy: 0.8240\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5739 - accuracy: 0.8238\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5748 - accuracy: 0.8239\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5736 - accuracy: 0.8250\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5731 - accuracy: 0.8248\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5741 - accuracy: 0.8237\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5735 - accuracy: 0.8245\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5729 - accuracy: 0.8247\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5738 - accuracy: 0.8250\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5741 - accuracy: 0.8241\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5730 - accuracy: 0.8247\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5738 - accuracy: 0.8236\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5725 - accuracy: 0.8247\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5730 - accuracy: 0.8249\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5716 - accuracy: 0.8247\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5722 - accuracy: 0.8247\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5724 - accuracy: 0.8248\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5722 - accuracy: 0.8244\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5731 - accuracy: 0.8248\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5719 - accuracy: 0.8246\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5719 - accuracy: 0.8251\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5715 - accuracy: 0.8258\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5722 - accuracy: 0.8244\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5708 - accuracy: 0.8253\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5704 - accuracy: 0.8252\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5711 - accuracy: 0.8254\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5698 - accuracy: 0.8260\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5707 - accuracy: 0.8250\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5709 - accuracy: 0.8252\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5702 - accuracy: 0.8250\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5700 - accuracy: 0.8252\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5700 - accuracy: 0.8252\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5700 - accuracy: 0.8252\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5694 - accuracy: 0.8256\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5710 - accuracy: 0.8251\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5709 - accuracy: 0.8248\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5699 - accuracy: 0.8260\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5706 - accuracy: 0.8250\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5705 - accuracy: 0.8255\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5702 - accuracy: 0.8255\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5691 - accuracy: 0.8257\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5690 - accuracy: 0.8258\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5685 - accuracy: 0.8257\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5693 - accuracy: 0.8257\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5697 - accuracy: 0.8255\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5690 - accuracy: 0.8256\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5688 - accuracy: 0.8258\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 12s 3ms/step - loss: 0.7468 - accuracy: 0.7745\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6604 - accuracy: 0.8025\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6439 - accuracy: 0.8072\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6342 - accuracy: 0.8098\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6265 - accuracy: 0.8112\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6214 - accuracy: 0.8131\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6172 - accuracy: 0.8136\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6152 - accuracy: 0.8136\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6115 - accuracy: 0.8141\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6090 - accuracy: 0.8153\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6075 - accuracy: 0.8156\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6044 - accuracy: 0.8159\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6027 - accuracy: 0.8167\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6003 - accuracy: 0.8170\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5986 - accuracy: 0.8172\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5969 - accuracy: 0.8176\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5955 - accuracy: 0.8178\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5924 - accuracy: 0.8192\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5905 - accuracy: 0.8192\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5898 - accuracy: 0.8199\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5873 - accuracy: 0.8204\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5853 - accuracy: 0.8209\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5846 - accuracy: 0.8206\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5830 - accuracy: 0.8214\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5818 - accuracy: 0.8219\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5807 - accuracy: 0.8219\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5800 - accuracy: 0.8224\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5778 - accuracy: 0.8236\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5778 - accuracy: 0.8226\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5762 - accuracy: 0.8243\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5755 - accuracy: 0.8236\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5745 - accuracy: 0.8239\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5743 - accuracy: 0.8241\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5735 - accuracy: 0.8240\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5732 - accuracy: 0.8239\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5726 - accuracy: 0.8246\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5710 - accuracy: 0.8242\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5702 - accuracy: 0.8249\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5710 - accuracy: 0.8247\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5702 - accuracy: 0.8242\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5704 - accuracy: 0.8247\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5695 - accuracy: 0.8252\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5700 - accuracy: 0.8250\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5704 - accuracy: 0.8248\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5696 - accuracy: 0.8253\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5690 - accuracy: 0.8254\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5690 - accuracy: 0.8254\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5678 - accuracy: 0.8252\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5685 - accuracy: 0.8257\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5679 - accuracy: 0.8256\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5681 - accuracy: 0.8255\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5684 - accuracy: 0.8253\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5671 - accuracy: 0.8256\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5668 - accuracy: 0.8257\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5671 - accuracy: 0.8250\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5667 - accuracy: 0.8256\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5662 - accuracy: 0.8265\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5661 - accuracy: 0.8262\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5665 - accuracy: 0.8260\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5664 - accuracy: 0.8257\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5659 - accuracy: 0.8264\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5656 - accuracy: 0.8271\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5667 - accuracy: 0.8256\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5657 - accuracy: 0.8263\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5660 - accuracy: 0.8261\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5661 - accuracy: 0.8268\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5654 - accuracy: 0.8259\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5654 - accuracy: 0.8255\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5652 - accuracy: 0.8260\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5656 - accuracy: 0.8261\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5647 - accuracy: 0.8265\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5653 - accuracy: 0.8265\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5633 - accuracy: 0.8270\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5650 - accuracy: 0.8272\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5643 - accuracy: 0.8261\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5653 - accuracy: 0.8261\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5633 - accuracy: 0.8266\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5641 - accuracy: 0.8264\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5639 - accuracy: 0.8266\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5643 - accuracy: 0.8264\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5628 - accuracy: 0.8266\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5643 - accuracy: 0.8265\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5641 - accuracy: 0.8263\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5623 - accuracy: 0.8266\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5635 - accuracy: 0.8261\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5633 - accuracy: 0.8270\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5637 - accuracy: 0.8263\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5627 - accuracy: 0.8271\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5625 - accuracy: 0.8266\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5620 - accuracy: 0.8269\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5637 - accuracy: 0.8265\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5630 - accuracy: 0.8265\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5622 - accuracy: 0.8267\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5629 - accuracy: 0.8269\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5623 - accuracy: 0.8271\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5628 - accuracy: 0.8267\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5626 - accuracy: 0.8273\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5621 - accuracy: 0.8267\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5624 - accuracy: 0.8269\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5619 - accuracy: 0.8276\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 12s 3ms/step - loss: 0.7434 - accuracy: 0.7750\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6558 - accuracy: 0.8030\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6395 - accuracy: 0.8077\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6303 - accuracy: 0.8103\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6237 - accuracy: 0.8122\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6177 - accuracy: 0.8133\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6168 - accuracy: 0.8132\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6122 - accuracy: 0.8143\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6087 - accuracy: 0.8148\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6067 - accuracy: 0.8152\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6032 - accuracy: 0.8162\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6002 - accuracy: 0.8167\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5971 - accuracy: 0.8170\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5940 - accuracy: 0.8175\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5936 - accuracy: 0.8184\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5902 - accuracy: 0.8193\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5884 - accuracy: 0.8200\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5885 - accuracy: 0.8194\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5856 - accuracy: 0.8204\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5851 - accuracy: 0.8206\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5828 - accuracy: 0.8216\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5828 - accuracy: 0.8215\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5821 - accuracy: 0.8211\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5811 - accuracy: 0.8213\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5805 - accuracy: 0.8215\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5794 - accuracy: 0.8216\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5785 - accuracy: 0.8215\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5778 - accuracy: 0.8220\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5765 - accuracy: 0.8227\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5763 - accuracy: 0.8230\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5759 - accuracy: 0.8224\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5756 - accuracy: 0.8231\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5728 - accuracy: 0.8241\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5734 - accuracy: 0.8235\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5739 - accuracy: 0.8234\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5727 - accuracy: 0.8234\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5720 - accuracy: 0.8240\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5708 - accuracy: 0.8241\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5717 - accuracy: 0.8240\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5703 - accuracy: 0.8239\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5701 - accuracy: 0.8247\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5703 - accuracy: 0.8244\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5696 - accuracy: 0.8244\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5697 - accuracy: 0.8244\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5694 - accuracy: 0.8245\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5690 - accuracy: 0.8256\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5686 - accuracy: 0.8252\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5694 - accuracy: 0.8254\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5690 - accuracy: 0.8252\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5686 - accuracy: 0.8248\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5683 - accuracy: 0.8248\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5681 - accuracy: 0.8257\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5676 - accuracy: 0.8253\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5673 - accuracy: 0.8253\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5677 - accuracy: 0.8250\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5667 - accuracy: 0.8254\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5661 - accuracy: 0.8253\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5660 - accuracy: 0.8258\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5669 - accuracy: 0.8246\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5669 - accuracy: 0.8257\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5662 - accuracy: 0.8257\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5664 - accuracy: 0.8258\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5657 - accuracy: 0.8259\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5654 - accuracy: 0.8252\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5659 - accuracy: 0.8252\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5657 - accuracy: 0.8256\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5662 - accuracy: 0.8256\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5656 - accuracy: 0.8259\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5659 - accuracy: 0.8253\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5644 - accuracy: 0.8259\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5654 - accuracy: 0.8265\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5661 - accuracy: 0.8259\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5645 - accuracy: 0.8266\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5656 - accuracy: 0.8258\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5656 - accuracy: 0.8258\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5651 - accuracy: 0.8258\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5644 - accuracy: 0.8258\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5647 - accuracy: 0.8260\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5653 - accuracy: 0.8253\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5644 - accuracy: 0.8259\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5653 - accuracy: 0.8258\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5648 - accuracy: 0.8256\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5646 - accuracy: 0.8260\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5646 - accuracy: 0.8260\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5636 - accuracy: 0.8266\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5654 - accuracy: 0.8258\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5628 - accuracy: 0.8266\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5637 - accuracy: 0.8257\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5627 - accuracy: 0.8266\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5633 - accuracy: 0.8262\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5642 - accuracy: 0.8263\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5635 - accuracy: 0.8268\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5636 - accuracy: 0.8268\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5627 - accuracy: 0.8269\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5636 - accuracy: 0.8264\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5633 - accuracy: 0.8265\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5633 - accuracy: 0.8262\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5630 - accuracy: 0.8262\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5631 - accuracy: 0.8267\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5633 - accuracy: 0.8258\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 12s 3ms/step - loss: 0.7448 - accuracy: 0.7744\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6582 - accuracy: 0.8023\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6427 - accuracy: 0.8079\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6327 - accuracy: 0.8105\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6258 - accuracy: 0.8119\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6210 - accuracy: 0.8130\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6160 - accuracy: 0.8146\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6125 - accuracy: 0.8144\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6098 - accuracy: 0.8153\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6062 - accuracy: 0.8155\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6032 - accuracy: 0.8164\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6005 - accuracy: 0.8163\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5984 - accuracy: 0.8177\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5956 - accuracy: 0.8185\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5929 - accuracy: 0.8192\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5906 - accuracy: 0.8190\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5899 - accuracy: 0.8198\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5882 - accuracy: 0.8202\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5873 - accuracy: 0.8200\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5855 - accuracy: 0.8204\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5840 - accuracy: 0.8209\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5827 - accuracy: 0.8215\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5821 - accuracy: 0.8219\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5808 - accuracy: 0.8216\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5813 - accuracy: 0.8215\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5796 - accuracy: 0.8219\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5784 - accuracy: 0.8226\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5781 - accuracy: 0.8228\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5772 - accuracy: 0.8231\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5758 - accuracy: 0.8232\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5759 - accuracy: 0.8229\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5740 - accuracy: 0.8238\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5756 - accuracy: 0.8227\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5727 - accuracy: 0.8243\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5728 - accuracy: 0.8238\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5726 - accuracy: 0.8240\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5712 - accuracy: 0.8245\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5722 - accuracy: 0.8242\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5710 - accuracy: 0.8247\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5712 - accuracy: 0.8254\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5701 - accuracy: 0.8246\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5699 - accuracy: 0.8247\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5701 - accuracy: 0.8248\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5694 - accuracy: 0.8249\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5699 - accuracy: 0.8249\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5684 - accuracy: 0.8251\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5683 - accuracy: 0.8251\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5685 - accuracy: 0.8252\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5688 - accuracy: 0.8254\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5674 - accuracy: 0.8257\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5677 - accuracy: 0.8251\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5681 - accuracy: 0.8251\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5676 - accuracy: 0.8254\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5673 - accuracy: 0.8251\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5677 - accuracy: 0.8253\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5664 - accuracy: 0.8259\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5667 - accuracy: 0.8256\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5667 - accuracy: 0.8259\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5671 - accuracy: 0.8255\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5663 - accuracy: 0.8253\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5666 - accuracy: 0.8258\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5659 - accuracy: 0.8257\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5656 - accuracy: 0.8254\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5652 - accuracy: 0.8256\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5651 - accuracy: 0.8262\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5648 - accuracy: 0.8262\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5655 - accuracy: 0.8252\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5649 - accuracy: 0.8253\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5656 - accuracy: 0.8256\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5645 - accuracy: 0.8267\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5641 - accuracy: 0.8261\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5638 - accuracy: 0.8263\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5644 - accuracy: 0.8261\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5644 - accuracy: 0.8258\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5651 - accuracy: 0.8259\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5636 - accuracy: 0.8268\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5641 - accuracy: 0.8266\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5638 - accuracy: 0.8264\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5638 - accuracy: 0.8267\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5638 - accuracy: 0.8263\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5633 - accuracy: 0.8263\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5635 - accuracy: 0.8271\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5618 - accuracy: 0.8267\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5627 - accuracy: 0.8262\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5631 - accuracy: 0.8270\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5625 - accuracy: 0.8269\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5632 - accuracy: 0.8264\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5625 - accuracy: 0.8264\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5627 - accuracy: 0.8266\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5620 - accuracy: 0.8268\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5626 - accuracy: 0.8265\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5613 - accuracy: 0.8270\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5621 - accuracy: 0.8262\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5618 - accuracy: 0.8265\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5623 - accuracy: 0.8266\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5611 - accuracy: 0.8266\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5623 - accuracy: 0.8266\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5620 - accuracy: 0.8273\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5613 - accuracy: 0.8274\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5616 - accuracy: 0.8270\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7468 - accuracy: 0.7740\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6574 - accuracy: 0.8026\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6430 - accuracy: 0.8078\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6324 - accuracy: 0.8103\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6244 - accuracy: 0.8123\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6189 - accuracy: 0.8134\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6135 - accuracy: 0.8141\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6100 - accuracy: 0.8149\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6065 - accuracy: 0.8154\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6015 - accuracy: 0.8163\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5983 - accuracy: 0.8170\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5961 - accuracy: 0.8183\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5932 - accuracy: 0.8180\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5918 - accuracy: 0.8190\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5896 - accuracy: 0.8194\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5868 - accuracy: 0.8203\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5850 - accuracy: 0.8206\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5842 - accuracy: 0.8206\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5836 - accuracy: 0.8212\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5810 - accuracy: 0.8223\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5807 - accuracy: 0.8216\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5807 - accuracy: 0.8218\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5792 - accuracy: 0.8222\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5783 - accuracy: 0.8222\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5792 - accuracy: 0.8224\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5774 - accuracy: 0.8229\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5752 - accuracy: 0.8235\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5760 - accuracy: 0.8235\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5757 - accuracy: 0.8227\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5738 - accuracy: 0.8237\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5746 - accuracy: 0.8235\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5733 - accuracy: 0.8244\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5720 - accuracy: 0.8244\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5724 - accuracy: 0.8240\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5712 - accuracy: 0.8243\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5712 - accuracy: 0.8244\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5706 - accuracy: 0.8241\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5694 - accuracy: 0.8247\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5687 - accuracy: 0.8249\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5675 - accuracy: 0.8258\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5680 - accuracy: 0.8251\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5666 - accuracy: 0.8256\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5670 - accuracy: 0.8254\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5667 - accuracy: 0.8260\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5659 - accuracy: 0.8255\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5666 - accuracy: 0.8262\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5657 - accuracy: 0.8260\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5657 - accuracy: 0.8258\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5654 - accuracy: 0.8260\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5648 - accuracy: 0.8262\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5644 - accuracy: 0.8260\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5642 - accuracy: 0.8258\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5643 - accuracy: 0.8260\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5638 - accuracy: 0.8265\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5631 - accuracy: 0.8263\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5622 - accuracy: 0.8270\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5632 - accuracy: 0.8265\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5633 - accuracy: 0.8262\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5623 - accuracy: 0.8261\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5623 - accuracy: 0.8267\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5621 - accuracy: 0.8264\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5624 - accuracy: 0.8265\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5621 - accuracy: 0.8263\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5617 - accuracy: 0.8265\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5620 - accuracy: 0.8266\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5611 - accuracy: 0.8267\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5608 - accuracy: 0.8268\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5616 - accuracy: 0.8274\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5615 - accuracy: 0.8271\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5606 - accuracy: 0.8273\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5602 - accuracy: 0.8267\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5610 - accuracy: 0.8263\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5602 - accuracy: 0.8270\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5611 - accuracy: 0.8272\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5599 - accuracy: 0.8272\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5599 - accuracy: 0.8269\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5596 - accuracy: 0.8271\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5603 - accuracy: 0.8266\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5590 - accuracy: 0.8271\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5599 - accuracy: 0.8272\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5592 - accuracy: 0.8278\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5599 - accuracy: 0.8273\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5594 - accuracy: 0.8271\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5606 - accuracy: 0.8269\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5584 - accuracy: 0.8279\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5588 - accuracy: 0.8277\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5587 - accuracy: 0.8274\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5591 - accuracy: 0.8272\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5584 - accuracy: 0.8277\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5593 - accuracy: 0.8271\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5586 - accuracy: 0.8278\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5584 - accuracy: 0.8273\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5584 - accuracy: 0.8274\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5583 - accuracy: 0.8279\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5595 - accuracy: 0.8275\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5581 - accuracy: 0.8277\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5574 - accuracy: 0.8276\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5572 - accuracy: 0.8277\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5574 - accuracy: 0.8272\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5569 - accuracy: 0.8284\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7389 - accuracy: 0.7765\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6546 - accuracy: 0.8041\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6387 - accuracy: 0.8089\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6300 - accuracy: 0.8111\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6242 - accuracy: 0.8119\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6183 - accuracy: 0.8133\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6150 - accuracy: 0.8136\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6112 - accuracy: 0.8150\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6080 - accuracy: 0.8159\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6053 - accuracy: 0.8166\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6033 - accuracy: 0.8162\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5996 - accuracy: 0.8169\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5967 - accuracy: 0.8175\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5944 - accuracy: 0.8187\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5919 - accuracy: 0.8192\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5892 - accuracy: 0.8200\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5877 - accuracy: 0.8200\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5862 - accuracy: 0.8207\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5844 - accuracy: 0.8206\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5831 - accuracy: 0.8214\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5809 - accuracy: 0.8216\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5805 - accuracy: 0.8221\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5793 - accuracy: 0.8224\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5779 - accuracy: 0.8226\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5773 - accuracy: 0.8225\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5758 - accuracy: 0.8235\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5753 - accuracy: 0.8232\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5744 - accuracy: 0.8232\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5742 - accuracy: 0.8233\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5733 - accuracy: 0.8237\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5731 - accuracy: 0.8238\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5729 - accuracy: 0.8241\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5716 - accuracy: 0.8245\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5704 - accuracy: 0.8247\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5705 - accuracy: 0.8244\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5699 - accuracy: 0.8245\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5696 - accuracy: 0.8238\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5683 - accuracy: 0.8253\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5676 - accuracy: 0.8244\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5684 - accuracy: 0.8243\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5675 - accuracy: 0.8257\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5674 - accuracy: 0.8253\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5672 - accuracy: 0.8247\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5656 - accuracy: 0.8262\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5669 - accuracy: 0.8247\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5665 - accuracy: 0.8253\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5650 - accuracy: 0.8259\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5647 - accuracy: 0.8254\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5649 - accuracy: 0.8256\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5650 - accuracy: 0.8259\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5646 - accuracy: 0.8261\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5651 - accuracy: 0.8255\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5647 - accuracy: 0.8263\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5630 - accuracy: 0.8262\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5647 - accuracy: 0.8254\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5639 - accuracy: 0.8268\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5637 - accuracy: 0.8258\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5629 - accuracy: 0.8258\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5628 - accuracy: 0.8261\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5622 - accuracy: 0.8263\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5622 - accuracy: 0.8263\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5625 - accuracy: 0.8260\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5619 - accuracy: 0.8266\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5625 - accuracy: 0.8263\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5621 - accuracy: 0.8262\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5616 - accuracy: 0.8266\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5609 - accuracy: 0.8266\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5619 - accuracy: 0.8265\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5613 - accuracy: 0.8269\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5612 - accuracy: 0.8268\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5609 - accuracy: 0.8268\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5610 - accuracy: 0.8264\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5614 - accuracy: 0.8263\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5603 - accuracy: 0.8268\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5601 - accuracy: 0.8269\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5608 - accuracy: 0.8266\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5602 - accuracy: 0.8270\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5602 - accuracy: 0.8273\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5607 - accuracy: 0.8264\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5594 - accuracy: 0.8274\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5597 - accuracy: 0.8276\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5609 - accuracy: 0.8266\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5596 - accuracy: 0.8270\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5592 - accuracy: 0.8271\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5587 - accuracy: 0.8272\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5607 - accuracy: 0.8264\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5591 - accuracy: 0.8267\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5590 - accuracy: 0.8269\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5590 - accuracy: 0.8269\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5587 - accuracy: 0.8273\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5597 - accuracy: 0.8266\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5581 - accuracy: 0.8269\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5593 - accuracy: 0.8264\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5583 - accuracy: 0.8271\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5579 - accuracy: 0.8275\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5590 - accuracy: 0.8265\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5594 - accuracy: 0.8266\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5589 - accuracy: 0.8274\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5584 - accuracy: 0.8278\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5584 - accuracy: 0.8272\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7449 - accuracy: 0.7759\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6575 - accuracy: 0.8026\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6412 - accuracy: 0.8082\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6300 - accuracy: 0.8112\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6235 - accuracy: 0.8124\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6198 - accuracy: 0.8134\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6166 - accuracy: 0.8137\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6119 - accuracy: 0.8149\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6089 - accuracy: 0.8151\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6071 - accuracy: 0.8158\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6030 - accuracy: 0.8161\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5998 - accuracy: 0.8165\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5958 - accuracy: 0.8174\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5930 - accuracy: 0.8184\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5910 - accuracy: 0.8193\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5892 - accuracy: 0.8199\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5871 - accuracy: 0.8203\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5855 - accuracy: 0.8209\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5844 - accuracy: 0.8211\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5828 - accuracy: 0.8216\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5817 - accuracy: 0.8217\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5817 - accuracy: 0.8214\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5793 - accuracy: 0.8226\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5777 - accuracy: 0.8231\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5769 - accuracy: 0.8229\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5761 - accuracy: 0.8233\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5752 - accuracy: 0.8227\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5741 - accuracy: 0.8235\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5737 - accuracy: 0.8237\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5730 - accuracy: 0.8234\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5717 - accuracy: 0.8245\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5713 - accuracy: 0.8244\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5700 - accuracy: 0.8249\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5701 - accuracy: 0.8244\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5700 - accuracy: 0.8246\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5700 - accuracy: 0.8240\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5691 - accuracy: 0.8246\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5690 - accuracy: 0.8244\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5690 - accuracy: 0.8248\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5686 - accuracy: 0.8253\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5675 - accuracy: 0.8249\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5673 - accuracy: 0.8249\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5676 - accuracy: 0.8244\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5674 - accuracy: 0.8250\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5684 - accuracy: 0.8246\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5671 - accuracy: 0.8257\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5662 - accuracy: 0.8258\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5662 - accuracy: 0.8253\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5655 - accuracy: 0.8257\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5656 - accuracy: 0.8257\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5658 - accuracy: 0.8256\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5662 - accuracy: 0.8253\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5658 - accuracy: 0.8258\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5656 - accuracy: 0.8257\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5647 - accuracy: 0.8259\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5649 - accuracy: 0.8258\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5648 - accuracy: 0.8262\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5649 - accuracy: 0.8257\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5649 - accuracy: 0.8255\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5644 - accuracy: 0.8254\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5647 - accuracy: 0.8259\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5643 - accuracy: 0.8255\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5634 - accuracy: 0.8258\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5644 - accuracy: 0.8261\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5645 - accuracy: 0.8263\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5639 - accuracy: 0.8261\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5636 - accuracy: 0.8258\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5637 - accuracy: 0.8260\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5631 - accuracy: 0.8259\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5633 - accuracy: 0.8258\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5633 - accuracy: 0.8263\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5630 - accuracy: 0.8261\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5625 - accuracy: 0.8269\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5625 - accuracy: 0.8264\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5621 - accuracy: 0.8265\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5632 - accuracy: 0.8260\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5610 - accuracy: 0.8266\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5631 - accuracy: 0.8260\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5629 - accuracy: 0.8263\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5627 - accuracy: 0.8265\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5622 - accuracy: 0.8264\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5624 - accuracy: 0.8261\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5622 - accuracy: 0.8265\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5622 - accuracy: 0.8268\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5630 - accuracy: 0.8262\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5622 - accuracy: 0.8265\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5620 - accuracy: 0.8271\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5612 - accuracy: 0.8270\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5619 - accuracy: 0.8268\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5612 - accuracy: 0.8269\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5614 - accuracy: 0.8265\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5607 - accuracy: 0.8267\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5611 - accuracy: 0.8266\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5612 - accuracy: 0.8270\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5609 - accuracy: 0.8278\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5610 - accuracy: 0.8272\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5616 - accuracy: 0.8263\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5604 - accuracy: 0.8272\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5609 - accuracy: 0.8272\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5603 - accuracy: 0.8269\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 12s 3ms/step - loss: 0.7431 - accuracy: 0.7749\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6548 - accuracy: 0.8033\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6379 - accuracy: 0.8087\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6294 - accuracy: 0.8105\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6223 - accuracy: 0.8123\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6173 - accuracy: 0.8137\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6133 - accuracy: 0.8147\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6086 - accuracy: 0.8154\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6059 - accuracy: 0.8159\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6009 - accuracy: 0.8166\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5977 - accuracy: 0.8176\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5954 - accuracy: 0.8177\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5908 - accuracy: 0.8193\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5875 - accuracy: 0.8206\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5860 - accuracy: 0.8205\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5848 - accuracy: 0.8203\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5827 - accuracy: 0.8216\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5816 - accuracy: 0.8214\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5801 - accuracy: 0.8217\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5780 - accuracy: 0.8227\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5774 - accuracy: 0.8224\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5760 - accuracy: 0.8228\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5750 - accuracy: 0.8228\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5727 - accuracy: 0.8238\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5723 - accuracy: 0.8241\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5709 - accuracy: 0.8245\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5698 - accuracy: 0.8249\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5697 - accuracy: 0.8239\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5684 - accuracy: 0.8254\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5683 - accuracy: 0.8247\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5675 - accuracy: 0.8254\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5676 - accuracy: 0.8255\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5667 - accuracy: 0.8253\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5651 - accuracy: 0.8256\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5659 - accuracy: 0.8258\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5652 - accuracy: 0.8260\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5653 - accuracy: 0.8249\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5648 - accuracy: 0.8266\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5626 - accuracy: 0.8263\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5634 - accuracy: 0.8265\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5637 - accuracy: 0.8259\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5621 - accuracy: 0.8263\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5632 - accuracy: 0.8266\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5617 - accuracy: 0.8268\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5616 - accuracy: 0.8266\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5613 - accuracy: 0.8269\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5607 - accuracy: 0.8267\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5605 - accuracy: 0.8273\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5597 - accuracy: 0.8273\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5606 - accuracy: 0.8265\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5603 - accuracy: 0.8271\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5598 - accuracy: 0.8277\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5595 - accuracy: 0.8274\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5596 - accuracy: 0.8266\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5590 - accuracy: 0.8271\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5596 - accuracy: 0.8277\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5590 - accuracy: 0.8267\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5599 - accuracy: 0.8271\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5588 - accuracy: 0.8273\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5582 - accuracy: 0.8275\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5591 - accuracy: 0.8275\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5575 - accuracy: 0.8275\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5573 - accuracy: 0.8283\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5572 - accuracy: 0.8275\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5569 - accuracy: 0.8278\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5575 - accuracy: 0.8280\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5575 - accuracy: 0.8276\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5560 - accuracy: 0.8275\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5572 - accuracy: 0.8276\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5579 - accuracy: 0.8274\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5565 - accuracy: 0.8279\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5560 - accuracy: 0.8276\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5563 - accuracy: 0.8277\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5564 - accuracy: 0.8279\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5572 - accuracy: 0.8281\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5557 - accuracy: 0.8286\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5557 - accuracy: 0.8279\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5554 - accuracy: 0.8284\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5558 - accuracy: 0.8278\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5556 - accuracy: 0.8274\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5554 - accuracy: 0.8282\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5553 - accuracy: 0.8273\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5552 - accuracy: 0.8281\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5551 - accuracy: 0.8282\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5559 - accuracy: 0.8279\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5557 - accuracy: 0.8278\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5554 - accuracy: 0.8281\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5555 - accuracy: 0.8285\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5555 - accuracy: 0.8276\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5540 - accuracy: 0.8283\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5552 - accuracy: 0.8288\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5548 - accuracy: 0.8286\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5547 - accuracy: 0.8277\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5533 - accuracy: 0.8285\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5551 - accuracy: 0.8278\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5543 - accuracy: 0.8285\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5541 - accuracy: 0.8286\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5546 - accuracy: 0.8277\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5550 - accuracy: 0.8282\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5538 - accuracy: 0.8284\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7390 - accuracy: 0.7761\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6547 - accuracy: 0.8019\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6361 - accuracy: 0.8077\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6260 - accuracy: 0.8114\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6196 - accuracy: 0.8127\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6139 - accuracy: 0.8141\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6090 - accuracy: 0.8150\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6057 - accuracy: 0.8156\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6016 - accuracy: 0.8163\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5981 - accuracy: 0.8171\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5950 - accuracy: 0.8178\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5908 - accuracy: 0.8180\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5889 - accuracy: 0.8192\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5863 - accuracy: 0.8199\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5846 - accuracy: 0.8205\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5835 - accuracy: 0.8199\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5812 - accuracy: 0.8212\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5800 - accuracy: 0.8219\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5781 - accuracy: 0.8219\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5760 - accuracy: 0.8229\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5754 - accuracy: 0.8230\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5741 - accuracy: 0.8228\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5729 - accuracy: 0.8236\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5720 - accuracy: 0.8235\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5703 - accuracy: 0.8240\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5693 - accuracy: 0.8241\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5693 - accuracy: 0.8236\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5677 - accuracy: 0.8250\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5676 - accuracy: 0.8251\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5670 - accuracy: 0.8253\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5661 - accuracy: 0.8253\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5663 - accuracy: 0.8255\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5661 - accuracy: 0.8249\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5641 - accuracy: 0.8248\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5651 - accuracy: 0.8251\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5644 - accuracy: 0.8256\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5638 - accuracy: 0.8258\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5627 - accuracy: 0.8261\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5625 - accuracy: 0.8259\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5620 - accuracy: 0.8259\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5621 - accuracy: 0.8256\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5619 - accuracy: 0.8262\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5618 - accuracy: 0.8259\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5606 - accuracy: 0.8264\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5610 - accuracy: 0.8258\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5609 - accuracy: 0.8263\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5599 - accuracy: 0.8266\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5602 - accuracy: 0.8265\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5608 - accuracy: 0.8260\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5600 - accuracy: 0.8266\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5595 - accuracy: 0.8270\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5596 - accuracy: 0.8265\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5585 - accuracy: 0.8261\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5587 - accuracy: 0.8271\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5577 - accuracy: 0.8276\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5590 - accuracy: 0.8266\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5594 - accuracy: 0.8264\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5579 - accuracy: 0.8268\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5579 - accuracy: 0.8271\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5576 - accuracy: 0.8274\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5581 - accuracy: 0.8271\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5573 - accuracy: 0.8268\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5575 - accuracy: 0.8269\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5571 - accuracy: 0.8268\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5580 - accuracy: 0.8272\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5565 - accuracy: 0.8274\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5568 - accuracy: 0.8272\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5563 - accuracy: 0.8271\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5563 - accuracy: 0.8272\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5559 - accuracy: 0.8278\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5560 - accuracy: 0.8271\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5553 - accuracy: 0.8278\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5556 - accuracy: 0.8280\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5562 - accuracy: 0.8276\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5553 - accuracy: 0.8273\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5559 - accuracy: 0.8270\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5555 - accuracy: 0.8280\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5554 - accuracy: 0.8276\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5562 - accuracy: 0.8272\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5553 - accuracy: 0.8278\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5551 - accuracy: 0.8274\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5542 - accuracy: 0.8276\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5544 - accuracy: 0.8274\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5551 - accuracy: 0.8271\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5542 - accuracy: 0.8273\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5547 - accuracy: 0.8279\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5549 - accuracy: 0.8279\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5548 - accuracy: 0.8278\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5542 - accuracy: 0.8272\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5542 - accuracy: 0.8276\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5546 - accuracy: 0.8278\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5540 - accuracy: 0.8280\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5530 - accuracy: 0.8282\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5539 - accuracy: 0.8276\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5533 - accuracy: 0.8284\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5533 - accuracy: 0.8282\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5526 - accuracy: 0.8286\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5537 - accuracy: 0.8275\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5526 - accuracy: 0.8284\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5537 - accuracy: 0.8277\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 12s 3ms/step - loss: 0.7428 - accuracy: 0.7753\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6573 - accuracy: 0.8022\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6398 - accuracy: 0.8075\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6280 - accuracy: 0.8111\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6200 - accuracy: 0.8131\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6153 - accuracy: 0.8140\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6114 - accuracy: 0.8145\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6078 - accuracy: 0.8152\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6047 - accuracy: 0.8157\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6016 - accuracy: 0.8165\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5976 - accuracy: 0.8173\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5955 - accuracy: 0.8176\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5926 - accuracy: 0.8185\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5893 - accuracy: 0.8192\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5886 - accuracy: 0.8195\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5859 - accuracy: 0.8202\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5847 - accuracy: 0.8204\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5816 - accuracy: 0.8214\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5805 - accuracy: 0.8221\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5815 - accuracy: 0.8211\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5779 - accuracy: 0.8220\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5771 - accuracy: 0.8216\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5775 - accuracy: 0.8223\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5762 - accuracy: 0.8224\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5752 - accuracy: 0.8227\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5737 - accuracy: 0.8233\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5739 - accuracy: 0.8231\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5733 - accuracy: 0.8229\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5721 - accuracy: 0.8238\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5717 - accuracy: 0.8233\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5710 - accuracy: 0.8244\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5707 - accuracy: 0.8244\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5695 - accuracy: 0.8243\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5695 - accuracy: 0.8240\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5682 - accuracy: 0.8247\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5685 - accuracy: 0.8240\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5684 - accuracy: 0.8246\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5666 - accuracy: 0.8252\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5660 - accuracy: 0.8250\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5661 - accuracy: 0.8252\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5655 - accuracy: 0.8251\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5648 - accuracy: 0.8256\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5645 - accuracy: 0.8253\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5649 - accuracy: 0.8259\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5642 - accuracy: 0.8257\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5632 - accuracy: 0.8259\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5638 - accuracy: 0.8257\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5641 - accuracy: 0.8262\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5634 - accuracy: 0.8252\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5637 - accuracy: 0.8254\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5624 - accuracy: 0.8267\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5631 - accuracy: 0.8260\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5627 - accuracy: 0.8259\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5622 - accuracy: 0.8260\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5611 - accuracy: 0.8265\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5611 - accuracy: 0.8272\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5607 - accuracy: 0.8266\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5607 - accuracy: 0.8264\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5607 - accuracy: 0.8267\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5606 - accuracy: 0.8271\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5615 - accuracy: 0.8259\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5608 - accuracy: 0.8267\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5605 - accuracy: 0.8269\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5604 - accuracy: 0.8268\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5595 - accuracy: 0.8264\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5606 - accuracy: 0.8271\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5600 - accuracy: 0.8272\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5598 - accuracy: 0.8271\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5604 - accuracy: 0.8267\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5593 - accuracy: 0.8271\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5591 - accuracy: 0.8270\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5590 - accuracy: 0.8272\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5597 - accuracy: 0.8267\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5588 - accuracy: 0.8272\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5599 - accuracy: 0.8265\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5602 - accuracy: 0.8274\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5592 - accuracy: 0.8276\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5590 - accuracy: 0.8267\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5583 - accuracy: 0.8271\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5583 - accuracy: 0.8275\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5586 - accuracy: 0.8268\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5580 - accuracy: 0.8268\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5585 - accuracy: 0.8265\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5582 - accuracy: 0.8270\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5584 - accuracy: 0.8279\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5583 - accuracy: 0.8267\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5575 - accuracy: 0.8278\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5583 - accuracy: 0.8274\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5578 - accuracy: 0.8271\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5580 - accuracy: 0.8272\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5578 - accuracy: 0.8274\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5575 - accuracy: 0.8274\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5575 - accuracy: 0.8274\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5577 - accuracy: 0.8273\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5573 - accuracy: 0.8279\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5579 - accuracy: 0.8274\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5582 - accuracy: 0.8276\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5581 - accuracy: 0.8273\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5572 - accuracy: 0.8276\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5579 - accuracy: 0.8268\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7430 - accuracy: 0.7758\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6559 - accuracy: 0.8034\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6395 - accuracy: 0.8073\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6284 - accuracy: 0.8110\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6212 - accuracy: 0.8124\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6141 - accuracy: 0.8136\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6113 - accuracy: 0.8143\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6059 - accuracy: 0.8157\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6022 - accuracy: 0.8159\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5988 - accuracy: 0.8170\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5947 - accuracy: 0.8177\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5923 - accuracy: 0.8180\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5896 - accuracy: 0.8185\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5866 - accuracy: 0.8197\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5845 - accuracy: 0.8203\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5838 - accuracy: 0.8202\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5820 - accuracy: 0.8214\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5816 - accuracy: 0.8203\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5796 - accuracy: 0.8212\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5781 - accuracy: 0.8218\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5778 - accuracy: 0.8224\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5762 - accuracy: 0.8225\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5741 - accuracy: 0.8231\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5731 - accuracy: 0.8236\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5724 - accuracy: 0.8233\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5709 - accuracy: 0.8245\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5698 - accuracy: 0.8247\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5690 - accuracy: 0.8246\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5683 - accuracy: 0.8244\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5667 - accuracy: 0.8248\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5667 - accuracy: 0.8253\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5665 - accuracy: 0.8252\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5655 - accuracy: 0.8257\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5647 - accuracy: 0.8259\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5649 - accuracy: 0.8254\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5643 - accuracy: 0.8256\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5636 - accuracy: 0.8263\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5633 - accuracy: 0.8260\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5625 - accuracy: 0.8259\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5610 - accuracy: 0.8264\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5610 - accuracy: 0.8268\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5605 - accuracy: 0.8272\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5604 - accuracy: 0.8264\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5600 - accuracy: 0.8273\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5595 - accuracy: 0.8270\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5593 - accuracy: 0.8274\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5592 - accuracy: 0.8272\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5575 - accuracy: 0.8272\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5586 - accuracy: 0.8269\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5577 - accuracy: 0.8271\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5579 - accuracy: 0.8270\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5580 - accuracy: 0.8273\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5579 - accuracy: 0.8271\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5570 - accuracy: 0.8280\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5565 - accuracy: 0.8280\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5567 - accuracy: 0.8275\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5578 - accuracy: 0.8274\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5560 - accuracy: 0.8279\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5563 - accuracy: 0.8278\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5561 - accuracy: 0.8272\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5564 - accuracy: 0.8270\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5557 - accuracy: 0.8282\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5557 - accuracy: 0.8274\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5550 - accuracy: 0.8283\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5561 - accuracy: 0.8282\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5559 - accuracy: 0.8277\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5548 - accuracy: 0.8284\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5546 - accuracy: 0.8280\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5560 - accuracy: 0.8274\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5546 - accuracy: 0.8285\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5547 - accuracy: 0.8285\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5536 - accuracy: 0.8282\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5547 - accuracy: 0.8274\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5544 - accuracy: 0.8283\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5542 - accuracy: 0.8281\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5546 - accuracy: 0.8284\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5542 - accuracy: 0.8280\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5543 - accuracy: 0.8279\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5539 - accuracy: 0.8287\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5537 - accuracy: 0.8283\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5544 - accuracy: 0.8274\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5536 - accuracy: 0.8285\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5533 - accuracy: 0.8287\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5543 - accuracy: 0.8284\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5531 - accuracy: 0.8284\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5536 - accuracy: 0.8287\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5525 - accuracy: 0.8290\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5537 - accuracy: 0.8283\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5534 - accuracy: 0.8283\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5533 - accuracy: 0.8289\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5534 - accuracy: 0.8289\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5533 - accuracy: 0.8279\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5525 - accuracy: 0.8288\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5525 - accuracy: 0.8286\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5527 - accuracy: 0.8284\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5533 - accuracy: 0.8282\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5526 - accuracy: 0.8289\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5534 - accuracy: 0.8285\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5522 - accuracy: 0.8293\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5522 - accuracy: 0.8286\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 12s 3ms/step - loss: 0.7413 - accuracy: 0.7756\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6527 - accuracy: 0.8034\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6353 - accuracy: 0.8090\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6250 - accuracy: 0.8117\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6178 - accuracy: 0.8135\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6119 - accuracy: 0.8139\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6064 - accuracy: 0.8157\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6031 - accuracy: 0.8161\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5994 - accuracy: 0.8161\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5965 - accuracy: 0.8169\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5939 - accuracy: 0.8178\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5893 - accuracy: 0.8192\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5876 - accuracy: 0.8193\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5843 - accuracy: 0.8206\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5833 - accuracy: 0.8199\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5811 - accuracy: 0.8211\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5796 - accuracy: 0.8212\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5764 - accuracy: 0.8227\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5764 - accuracy: 0.8226\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5736 - accuracy: 0.8229\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5727 - accuracy: 0.8228\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5710 - accuracy: 0.8235\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5699 - accuracy: 0.8237\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5692 - accuracy: 0.8243\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5689 - accuracy: 0.8251\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5675 - accuracy: 0.8246\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5667 - accuracy: 0.8249\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5662 - accuracy: 0.8250\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5655 - accuracy: 0.8251\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5644 - accuracy: 0.8252\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5642 - accuracy: 0.8253\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5631 - accuracy: 0.8257\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5628 - accuracy: 0.8261\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5624 - accuracy: 0.8263\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5623 - accuracy: 0.8257\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5617 - accuracy: 0.8261\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5614 - accuracy: 0.8269\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5600 - accuracy: 0.8265\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5603 - accuracy: 0.8264\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5598 - accuracy: 0.8266\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5600 - accuracy: 0.8262\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5587 - accuracy: 0.8264\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5588 - accuracy: 0.8268\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5589 - accuracy: 0.8272\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5577 - accuracy: 0.8270\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5579 - accuracy: 0.8267\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5579 - accuracy: 0.8266\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5577 - accuracy: 0.8270\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5563 - accuracy: 0.8273\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5563 - accuracy: 0.8270\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5561 - accuracy: 0.8277\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5557 - accuracy: 0.8281\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5564 - accuracy: 0.8276\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5564 - accuracy: 0.8268\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5567 - accuracy: 0.8265\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5563 - accuracy: 0.8271\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5558 - accuracy: 0.8276\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5551 - accuracy: 0.8273\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5555 - accuracy: 0.8273\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5553 - accuracy: 0.8276\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5543 - accuracy: 0.8271\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5549 - accuracy: 0.8275\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5545 - accuracy: 0.8281\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5547 - accuracy: 0.8278\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5546 - accuracy: 0.8278\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5538 - accuracy: 0.8282\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5547 - accuracy: 0.8270\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5548 - accuracy: 0.8279\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5542 - accuracy: 0.8270\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5532 - accuracy: 0.8277\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5529 - accuracy: 0.8280\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5539 - accuracy: 0.8283\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5530 - accuracy: 0.8284\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5536 - accuracy: 0.8276\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5538 - accuracy: 0.8277\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5533 - accuracy: 0.8278\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5526 - accuracy: 0.8279\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5523 - accuracy: 0.8285\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5520 - accuracy: 0.8281\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5517 - accuracy: 0.8285\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5524 - accuracy: 0.8284\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5525 - accuracy: 0.8282\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5529 - accuracy: 0.8289\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5523 - accuracy: 0.8281\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5532 - accuracy: 0.8281\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5524 - accuracy: 0.8282\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5512 - accuracy: 0.8289\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5517 - accuracy: 0.8288\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5509 - accuracy: 0.8285\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5524 - accuracy: 0.8281\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5516 - accuracy: 0.8283\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5512 - accuracy: 0.8279\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5515 - accuracy: 0.8291\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5523 - accuracy: 0.8283\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5515 - accuracy: 0.8287\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5519 - accuracy: 0.8282\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5512 - accuracy: 0.8287\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5509 - accuracy: 0.8285\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5502 - accuracy: 0.8286\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5508 - accuracy: 0.8285\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 12s 3ms/step - loss: 0.7424 - accuracy: 0.7750\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6545 - accuracy: 0.8028\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6389 - accuracy: 0.8078\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6294 - accuracy: 0.8104\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6199 - accuracy: 0.8129\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6163 - accuracy: 0.8137\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6114 - accuracy: 0.8149\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6063 - accuracy: 0.8157\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.6021 - accuracy: 0.8166\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5989 - accuracy: 0.8168\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5962 - accuracy: 0.8177\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5922 - accuracy: 0.8187\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5895 - accuracy: 0.8195\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5871 - accuracy: 0.8201\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5854 - accuracy: 0.8209\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5843 - accuracy: 0.8206\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5827 - accuracy: 0.8213\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5810 - accuracy: 0.8218\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5799 - accuracy: 0.8218\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5787 - accuracy: 0.8216\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5773 - accuracy: 0.8223\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5757 - accuracy: 0.8229\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5757 - accuracy: 0.8235\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5730 - accuracy: 0.8237\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5718 - accuracy: 0.8242\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5715 - accuracy: 0.8240\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5705 - accuracy: 0.8243\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5694 - accuracy: 0.8250\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5685 - accuracy: 0.8252\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5676 - accuracy: 0.8251\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5681 - accuracy: 0.8247\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5661 - accuracy: 0.8251\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5652 - accuracy: 0.8259\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5653 - accuracy: 0.8259\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5652 - accuracy: 0.8258\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5635 - accuracy: 0.8257\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5627 - accuracy: 0.8265\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5630 - accuracy: 0.8260\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5637 - accuracy: 0.8258\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5615 - accuracy: 0.8263\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5615 - accuracy: 0.8268\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5620 - accuracy: 0.8265\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5610 - accuracy: 0.8268\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5602 - accuracy: 0.8270\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5602 - accuracy: 0.8267\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5600 - accuracy: 0.8268\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5609 - accuracy: 0.8263\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5594 - accuracy: 0.8270\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5599 - accuracy: 0.8272\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5598 - accuracy: 0.8271\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5594 - accuracy: 0.8268\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5589 - accuracy: 0.8273\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5587 - accuracy: 0.8267\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5587 - accuracy: 0.8269\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5581 - accuracy: 0.8274\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5581 - accuracy: 0.8272\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5571 - accuracy: 0.8278\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5579 - accuracy: 0.8273\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5570 - accuracy: 0.8278\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5569 - accuracy: 0.8277\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5572 - accuracy: 0.8281\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5569 - accuracy: 0.8281\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5567 - accuracy: 0.8275\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5559 - accuracy: 0.8276\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5561 - accuracy: 0.8278\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5558 - accuracy: 0.8279\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5565 - accuracy: 0.8282\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5564 - accuracy: 0.8272\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5557 - accuracy: 0.8275\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5555 - accuracy: 0.8283\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5551 - accuracy: 0.8281\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5559 - accuracy: 0.8275\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5559 - accuracy: 0.8272\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5544 - accuracy: 0.8280\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5553 - accuracy: 0.8280\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5551 - accuracy: 0.8280\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5550 - accuracy: 0.8277\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5550 - accuracy: 0.8277\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5549 - accuracy: 0.8280\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5541 - accuracy: 0.8280\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5546 - accuracy: 0.8277\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5542 - accuracy: 0.8276\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5544 - accuracy: 0.8286\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5540 - accuracy: 0.8283\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5541 - accuracy: 0.8286\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5538 - accuracy: 0.8286\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5547 - accuracy: 0.8279\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5544 - accuracy: 0.8286\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5536 - accuracy: 0.8280\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5541 - accuracy: 0.8281\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5537 - accuracy: 0.8283\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5538 - accuracy: 0.8275\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5541 - accuracy: 0.8285\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5537 - accuracy: 0.8284\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5533 - accuracy: 0.8284\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5533 - accuracy: 0.8283\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5533 - accuracy: 0.8288\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5539 - accuracy: 0.8290\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5531 - accuracy: 0.8286\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5525 - accuracy: 0.8288\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "4012/4012 [==============================] - 16s 3ms/step - loss: 0.7144 - accuracy: 0.7839\n",
      "Epoch 2/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.6418 - accuracy: 0.8072\n",
      "Epoch 3/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.6252 - accuracy: 0.8113\n",
      "Epoch 4/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.6169 - accuracy: 0.8135\n",
      "Epoch 5/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.6112 - accuracy: 0.8147\n",
      "Epoch 6/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.6044 - accuracy: 0.8156\n",
      "Epoch 7/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.6015 - accuracy: 0.8163\n",
      "Epoch 8/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5963 - accuracy: 0.8174\n",
      "Epoch 9/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5912 - accuracy: 0.8186\n",
      "Epoch 10/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5875 - accuracy: 0.8198\n",
      "Epoch 11/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5834 - accuracy: 0.8208\n",
      "Epoch 12/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5818 - accuracy: 0.8207\n",
      "Epoch 13/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5794 - accuracy: 0.8216\n",
      "Epoch 14/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5770 - accuracy: 0.8223\n",
      "Epoch 15/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5763 - accuracy: 0.8225\n",
      "Epoch 16/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5750 - accuracy: 0.8230\n",
      "Epoch 17/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5743 - accuracy: 0.8230\n",
      "Epoch 18/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5734 - accuracy: 0.8237\n",
      "Epoch 19/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5718 - accuracy: 0.8238\n",
      "Epoch 20/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5712 - accuracy: 0.8236\n",
      "Epoch 21/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5693 - accuracy: 0.8247\n",
      "Epoch 22/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5688 - accuracy: 0.8248\n",
      "Epoch 23/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5680 - accuracy: 0.8247\n",
      "Epoch 24/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5668 - accuracy: 0.8248\n",
      "Epoch 25/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5667 - accuracy: 0.8249\n",
      "Epoch 26/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5658 - accuracy: 0.8257\n",
      "Epoch 27/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5647 - accuracy: 0.8255\n",
      "Epoch 28/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5646 - accuracy: 0.8256\n",
      "Epoch 29/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5643 - accuracy: 0.8258\n",
      "Epoch 30/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5642 - accuracy: 0.8253\n",
      "Epoch 31/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5639 - accuracy: 0.8259\n",
      "Epoch 32/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5632 - accuracy: 0.8258\n",
      "Epoch 33/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5616 - accuracy: 0.8261\n",
      "Epoch 34/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5627 - accuracy: 0.8264\n",
      "Epoch 35/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5612 - accuracy: 0.8266\n",
      "Epoch 36/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5604 - accuracy: 0.8268\n",
      "Epoch 37/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5603 - accuracy: 0.8269\n",
      "Epoch 38/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5603 - accuracy: 0.8266\n",
      "Epoch 39/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5599 - accuracy: 0.8269\n",
      "Epoch 40/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5597 - accuracy: 0.8268\n",
      "Epoch 41/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5601 - accuracy: 0.8261\n",
      "Epoch 42/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5594 - accuracy: 0.8265\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5588 - accuracy: 0.8269\n",
      "Epoch 44/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5579 - accuracy: 0.8270\n",
      "Epoch 45/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5589 - accuracy: 0.8270\n",
      "Epoch 46/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5577 - accuracy: 0.8276\n",
      "Epoch 47/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5587 - accuracy: 0.8268\n",
      "Epoch 48/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5573 - accuracy: 0.8274\n",
      "Epoch 49/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5573 - accuracy: 0.8272\n",
      "Epoch 50/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5576 - accuracy: 0.8270\n",
      "Epoch 51/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5568 - accuracy: 0.8277\n",
      "Epoch 52/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5577 - accuracy: 0.8274\n",
      "Epoch 53/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5571 - accuracy: 0.8274\n",
      "Epoch 54/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5566 - accuracy: 0.8277\n",
      "Epoch 55/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5571 - accuracy: 0.8274\n",
      "Epoch 56/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5568 - accuracy: 0.8272\n",
      "Epoch 57/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5568 - accuracy: 0.8279\n",
      "Epoch 58/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5562 - accuracy: 0.8275\n",
      "Epoch 59/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5557 - accuracy: 0.8279\n",
      "Epoch 60/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5561 - accuracy: 0.8275\n",
      "Epoch 61/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5561 - accuracy: 0.8278\n",
      "Epoch 62/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5559 - accuracy: 0.8279\n",
      "Epoch 63/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5562 - accuracy: 0.8278\n",
      "Epoch 64/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5562 - accuracy: 0.8276\n",
      "Epoch 65/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5549 - accuracy: 0.8282\n",
      "Epoch 66/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5545 - accuracy: 0.8282\n",
      "Epoch 67/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5550 - accuracy: 0.8280\n",
      "Epoch 68/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5546 - accuracy: 0.8279\n",
      "Epoch 69/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5546 - accuracy: 0.8281\n",
      "Epoch 70/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5542 - accuracy: 0.8283\n",
      "Epoch 71/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5546 - accuracy: 0.8286\n",
      "Epoch 72/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5541 - accuracy: 0.8284\n",
      "Epoch 73/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5555 - accuracy: 0.8273\n",
      "Epoch 74/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5540 - accuracy: 0.8286\n",
      "Epoch 75/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5541 - accuracy: 0.8278\n",
      "Epoch 76/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5533 - accuracy: 0.8290\n",
      "Epoch 77/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5538 - accuracy: 0.8282\n",
      "Epoch 78/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5535 - accuracy: 0.8284\n",
      "Epoch 79/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5535 - accuracy: 0.8286\n",
      "Epoch 80/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5536 - accuracy: 0.8282\n",
      "Epoch 81/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5536 - accuracy: 0.8281\n",
      "Epoch 82/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5535 - accuracy: 0.8287\n",
      "Epoch 83/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5533 - accuracy: 0.8287\n",
      "Epoch 84/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5531 - accuracy: 0.8286\n",
      "Epoch 85/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5532 - accuracy: 0.8284\n",
      "Epoch 86/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5528 - accuracy: 0.8288\n",
      "Epoch 87/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5521 - accuracy: 0.8284\n",
      "Epoch 88/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5528 - accuracy: 0.8281\n",
      "Epoch 89/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5531 - accuracy: 0.8284\n",
      "Epoch 90/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5520 - accuracy: 0.8290\n",
      "Epoch 91/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5531 - accuracy: 0.8285\n",
      "Epoch 92/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5530 - accuracy: 0.8286\n",
      "Epoch 93/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5518 - accuracy: 0.8290\n",
      "Epoch 94/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5517 - accuracy: 0.8288\n",
      "Epoch 95/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5525 - accuracy: 0.8286\n",
      "Epoch 96/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5526 - accuracy: 0.8285\n",
      "Epoch 97/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5513 - accuracy: 0.8291\n",
      "Epoch 98/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5520 - accuracy: 0.8288\n",
      "Epoch 99/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5524 - accuracy: 0.8280\n",
      "Epoch 100/100\n",
      "4012/4012 [==============================] - 13s 3ms/step - loss: 0.5517 - accuracy: 0.8289\n",
      "Best Results with Grid Search:\n",
      "0.8333691706009754\n",
      "{'unit': 90}\n"
     ]
    }
   ],
   "source": [
    "#Perceptron Tuning\n",
    "\n",
    "def create_model(unit):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='tanh'))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=unit, input_shape=(1, 11), activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1, epochs = 100, batch_size = 80)\n",
    "\n",
    "parameters = {\n",
    "    'unit': [10,20,30,40,50,60,70,80,90,100],\n",
    "    #'activation': ['relu','tanh'], \n",
    "    #'solver': ['adam','sgd'], \n",
    "    #'last_act': ['sigmoid','softmax'],\n",
    "    #'epochs': [70,100],\n",
    "    #'batch_size': [5,10] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3) # run 1 job at a time\n",
    "\n",
    "grid_search = grid_search.fit(X_train_L, y_train_L)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7cae93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xaxis_perceptrons = [10,20,30,40,50,60,70,80,90,100]\n",
    "plt.plot(xaxis_perceptrons,means,'.-')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Perceptrons')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"Figures/No.OfPerceptron_LSTM(ConvLSTM).png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2171e49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f190806\\AppData\\Local\\Temp\\2\\ipykernel_7416\\3191982561.py:63: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=1, epochs = 100, batch_size = 80)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 12s 3ms/step - loss: 0.7418 - accuracy: 0.7751\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6552 - accuracy: 0.8029\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6393 - accuracy: 0.8081\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6292 - accuracy: 0.8107\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6219 - accuracy: 0.8125\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6159 - accuracy: 0.8140\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6120 - accuracy: 0.8145\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6078 - accuracy: 0.8150\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6045 - accuracy: 0.8158\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6004 - accuracy: 0.8171\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5990 - accuracy: 0.8166\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5957 - accuracy: 0.8179\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5925 - accuracy: 0.8185\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5883 - accuracy: 0.8202\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5866 - accuracy: 0.8200\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5860 - accuracy: 0.8206\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5831 - accuracy: 0.8212\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5810 - accuracy: 0.8222\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5800 - accuracy: 0.8224\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5781 - accuracy: 0.8227\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5765 - accuracy: 0.8231\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5759 - accuracy: 0.8232\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5735 - accuracy: 0.8237\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5732 - accuracy: 0.8240\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5712 - accuracy: 0.8239\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5715 - accuracy: 0.8243\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5699 - accuracy: 0.8244\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5699 - accuracy: 0.8247\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5692 - accuracy: 0.8252\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5687 - accuracy: 0.8246\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5668 - accuracy: 0.8250\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5672 - accuracy: 0.8261\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5668 - accuracy: 0.8252\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5651 - accuracy: 0.8260\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5665 - accuracy: 0.8250\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5657 - accuracy: 0.8251\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5654 - accuracy: 0.8257\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5652 - accuracy: 0.8260\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5647 - accuracy: 0.8257\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5641 - accuracy: 0.8251\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5636 - accuracy: 0.8257\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5625 - accuracy: 0.8265\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5629 - accuracy: 0.8263\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5620 - accuracy: 0.8265\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5618 - accuracy: 0.8264\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5617 - accuracy: 0.8267\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5616 - accuracy: 0.8268\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5611 - accuracy: 0.8273\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5624 - accuracy: 0.8263\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5619 - accuracy: 0.8265\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5609 - accuracy: 0.8265\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5606 - accuracy: 0.8264\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5604 - accuracy: 0.8271\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5603 - accuracy: 0.8271\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5602 - accuracy: 0.8268\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5595 - accuracy: 0.8274\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5592 - accuracy: 0.8277\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5596 - accuracy: 0.8270\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5592 - accuracy: 0.8272\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5591 - accuracy: 0.8275\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5594 - accuracy: 0.8272\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5597 - accuracy: 0.8263\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5585 - accuracy: 0.8278\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5585 - accuracy: 0.8278\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5577 - accuracy: 0.8273\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5585 - accuracy: 0.8272\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5581 - accuracy: 0.8274\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5581 - accuracy: 0.8273\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5583 - accuracy: 0.8269\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5575 - accuracy: 0.8270\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5570 - accuracy: 0.8284\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5573 - accuracy: 0.8279\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5577 - accuracy: 0.8273\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5565 - accuracy: 0.8276\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5572 - accuracy: 0.8281\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5574 - accuracy: 0.8272\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5573 - accuracy: 0.8275\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5576 - accuracy: 0.8274\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5559 - accuracy: 0.8279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5563 - accuracy: 0.8283\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5560 - accuracy: 0.8275\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5558 - accuracy: 0.8289\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5571 - accuracy: 0.8277\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5563 - accuracy: 0.8279\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5565 - accuracy: 0.8274\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5554 - accuracy: 0.8282\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5555 - accuracy: 0.8282\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5565 - accuracy: 0.8278\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5554 - accuracy: 0.8278\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5555 - accuracy: 0.8278\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5550 - accuracy: 0.8284\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5556 - accuracy: 0.8278\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5547 - accuracy: 0.8286\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5552 - accuracy: 0.8281\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5550 - accuracy: 0.8284\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5556 - accuracy: 0.8280\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5549 - accuracy: 0.8284\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5547 - accuracy: 0.8287\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5547 - accuracy: 0.8280\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5547 - accuracy: 0.8279\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 11s 3ms/step - loss: 0.7425 - accuracy: 0.7749\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6540 - accuracy: 0.8033\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6368 - accuracy: 0.8077\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6262 - accuracy: 0.8109\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6187 - accuracy: 0.8131\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6142 - accuracy: 0.8137\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6104 - accuracy: 0.8143\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6067 - accuracy: 0.8155\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6040 - accuracy: 0.8163\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6024 - accuracy: 0.8155\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5989 - accuracy: 0.8168\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5961 - accuracy: 0.8174\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5932 - accuracy: 0.8175\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5904 - accuracy: 0.8190\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5872 - accuracy: 0.8193\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5847 - accuracy: 0.8210\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5834 - accuracy: 0.8204\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5812 - accuracy: 0.8207\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5789 - accuracy: 0.8221\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5779 - accuracy: 0.8217\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5766 - accuracy: 0.8217\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5749 - accuracy: 0.8229\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5725 - accuracy: 0.8227\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5722 - accuracy: 0.8238\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5705 - accuracy: 0.8239\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5701 - accuracy: 0.8240\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5688 - accuracy: 0.8245\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5687 - accuracy: 0.8246\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5672 - accuracy: 0.8248\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5667 - accuracy: 0.8243\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5664 - accuracy: 0.8251\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5658 - accuracy: 0.8248\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5662 - accuracy: 0.8250\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5645 - accuracy: 0.8256\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5650 - accuracy: 0.8256\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5638 - accuracy: 0.8257\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5636 - accuracy: 0.8253\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5632 - accuracy: 0.8264\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5626 - accuracy: 0.8261\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5627 - accuracy: 0.8258\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5621 - accuracy: 0.8259\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5615 - accuracy: 0.8266\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5620 - accuracy: 0.8261\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5617 - accuracy: 0.8261\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5618 - accuracy: 0.8260\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5605 - accuracy: 0.8268\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5619 - accuracy: 0.8264\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5603 - accuracy: 0.8265\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5606 - accuracy: 0.8263\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5586 - accuracy: 0.8271\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5595 - accuracy: 0.8265\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5593 - accuracy: 0.8270\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5588 - accuracy: 0.8265\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5596 - accuracy: 0.8267\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5588 - accuracy: 0.8264\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5578 - accuracy: 0.8269\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5586 - accuracy: 0.8269\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5572 - accuracy: 0.8275\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5574 - accuracy: 0.8275\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5580 - accuracy: 0.8267\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5586 - accuracy: 0.8266\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5566 - accuracy: 0.8273\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5567 - accuracy: 0.8273\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5571 - accuracy: 0.8275\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5564 - accuracy: 0.8278\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5571 - accuracy: 0.8277\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5554 - accuracy: 0.8275\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5562 - accuracy: 0.8280\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5566 - accuracy: 0.8271\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5570 - accuracy: 0.8271\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5554 - accuracy: 0.8277\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5563 - accuracy: 0.8275\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5567 - accuracy: 0.8274\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5558 - accuracy: 0.8274\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5566 - accuracy: 0.8279\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5552 - accuracy: 0.8276\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5563 - accuracy: 0.8276\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5559 - accuracy: 0.8276\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5548 - accuracy: 0.8278\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5555 - accuracy: 0.8271\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5543 - accuracy: 0.8277\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5534 - accuracy: 0.8281\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5547 - accuracy: 0.8280\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5542 - accuracy: 0.8277\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5550 - accuracy: 0.8274\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5556 - accuracy: 0.8266\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5549 - accuracy: 0.8274\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5541 - accuracy: 0.8282\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5543 - accuracy: 0.8278\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5547 - accuracy: 0.8277\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5540 - accuracy: 0.8283\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5533 - accuracy: 0.8278\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5546 - accuracy: 0.8279\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5539 - accuracy: 0.8279\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5540 - accuracy: 0.8281\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5540 - accuracy: 0.8282\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5533 - accuracy: 0.8280\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5540 - accuracy: 0.8282\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5530 - accuracy: 0.8286\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5542 - accuracy: 0.8278\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 12s 3ms/step - loss: 0.7416 - accuracy: 0.7750\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6559 - accuracy: 0.8027\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6394 - accuracy: 0.8079\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6292 - accuracy: 0.8110\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6225 - accuracy: 0.8122\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6173 - accuracy: 0.8133\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6138 - accuracy: 0.8142\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6094 - accuracy: 0.8148\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6060 - accuracy: 0.8157\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.6033 - accuracy: 0.8161\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5988 - accuracy: 0.8166\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5954 - accuracy: 0.8176\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5938 - accuracy: 0.8189\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5899 - accuracy: 0.8192\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5869 - accuracy: 0.8198\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5861 - accuracy: 0.8202\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5845 - accuracy: 0.8206\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5838 - accuracy: 0.8212\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5820 - accuracy: 0.8212\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5811 - accuracy: 0.8215\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5791 - accuracy: 0.8217\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5776 - accuracy: 0.8225\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5768 - accuracy: 0.8223\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5769 - accuracy: 0.8234\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5742 - accuracy: 0.8235\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5739 - accuracy: 0.8232\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5731 - accuracy: 0.8238\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5721 - accuracy: 0.8236\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5716 - accuracy: 0.8237\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5700 - accuracy: 0.8245\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5693 - accuracy: 0.8248\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5685 - accuracy: 0.8245\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5678 - accuracy: 0.8248\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5680 - accuracy: 0.8246\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5672 - accuracy: 0.8254\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5669 - accuracy: 0.8251\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5661 - accuracy: 0.8246\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5658 - accuracy: 0.8253\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5652 - accuracy: 0.8258\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5648 - accuracy: 0.8260\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5643 - accuracy: 0.8257\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5640 - accuracy: 0.8257\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5642 - accuracy: 0.8258\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5636 - accuracy: 0.8260\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5626 - accuracy: 0.8264\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5622 - accuracy: 0.8262\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5619 - accuracy: 0.8263\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5618 - accuracy: 0.8263\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5620 - accuracy: 0.8260\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5613 - accuracy: 0.8262\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5621 - accuracy: 0.8257\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5610 - accuracy: 0.8264\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5618 - accuracy: 0.8264\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5618 - accuracy: 0.8258\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5615 - accuracy: 0.8266\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5607 - accuracy: 0.8271\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5612 - accuracy: 0.8270\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5602 - accuracy: 0.8263\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5597 - accuracy: 0.8267\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5606 - accuracy: 0.8260\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5599 - accuracy: 0.8262\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5602 - accuracy: 0.8266\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5594 - accuracy: 0.8265\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5586 - accuracy: 0.8269\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5587 - accuracy: 0.8265\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5585 - accuracy: 0.8271\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5581 - accuracy: 0.8277\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 9s 3ms/step - loss: 0.5590 - accuracy: 0.8265\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5587 - accuracy: 0.8264\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5585 - accuracy: 0.8274\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5587 - accuracy: 0.8269\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5580 - accuracy: 0.8277\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5581 - accuracy: 0.8272\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5579 - accuracy: 0.8277\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5563 - accuracy: 0.8282\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5568 - accuracy: 0.8274\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5576 - accuracy: 0.8276\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5565 - accuracy: 0.8271\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5579 - accuracy: 0.8269\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5572 - accuracy: 0.8273\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5574 - accuracy: 0.8277\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5570 - accuracy: 0.8270\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5559 - accuracy: 0.8278\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5565 - accuracy: 0.8280\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5554 - accuracy: 0.8275\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5563 - accuracy: 0.8273\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5567 - accuracy: 0.8268\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5566 - accuracy: 0.8271\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5562 - accuracy: 0.8275\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5564 - accuracy: 0.8278\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5566 - accuracy: 0.8273\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5546 - accuracy: 0.8283\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5558 - accuracy: 0.8277\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5555 - accuracy: 0.8284\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5556 - accuracy: 0.8278\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5559 - accuracy: 0.8276\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5550 - accuracy: 0.8283\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5557 - accuracy: 0.8280\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5547 - accuracy: 0.8273\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 8s 3ms/step - loss: 0.5557 - accuracy: 0.8279\n",
      "3343/3343 [==============================] - 6s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 16s 4ms/step - loss: 0.7377 - accuracy: 0.7762\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6593 - accuracy: 0.8011\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6446 - accuracy: 0.8054\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6361 - accuracy: 0.8077\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6278 - accuracy: 0.8100\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6224 - accuracy: 0.8113\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6181 - accuracy: 0.8122\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6128 - accuracy: 0.8140\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.6103 - accuracy: 0.8139\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.6087 - accuracy: 0.8150\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.6061 - accuracy: 0.8149\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.6038 - accuracy: 0.8154\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.6008 - accuracy: 0.8163\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5988 - accuracy: 0.8168\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5957 - accuracy: 0.8177\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5940 - accuracy: 0.8173\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5909 - accuracy: 0.8182\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5879 - accuracy: 0.8192\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5851 - accuracy: 0.8204\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5827 - accuracy: 0.8202\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5807 - accuracy: 0.8205\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5789 - accuracy: 0.8211\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5776 - accuracy: 0.8221\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5760 - accuracy: 0.8225\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5740 - accuracy: 0.8227\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5728 - accuracy: 0.8227\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5707 - accuracy: 0.8232\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5700 - accuracy: 0.8239\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5691 - accuracy: 0.8240\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5677 - accuracy: 0.8232\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5671 - accuracy: 0.8241\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5657 - accuracy: 0.8251\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5653 - accuracy: 0.8246\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5637 - accuracy: 0.8250\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5632 - accuracy: 0.8259\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5622 - accuracy: 0.8257\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5623 - accuracy: 0.8258\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5617 - accuracy: 0.8259\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5606 - accuracy: 0.8260\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5602 - accuracy: 0.8265\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5607 - accuracy: 0.8261\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5595 - accuracy: 0.8265\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5593 - accuracy: 0.8264\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5598 - accuracy: 0.8264\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5589 - accuracy: 0.8267\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5584 - accuracy: 0.8263\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5578 - accuracy: 0.8270\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5583 - accuracy: 0.8267\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5574 - accuracy: 0.8268\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5577 - accuracy: 0.8266\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5565 - accuracy: 0.8275\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5565 - accuracy: 0.8275\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5552 - accuracy: 0.8279\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5560 - accuracy: 0.8274\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5555 - accuracy: 0.8278\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5551 - accuracy: 0.8276\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5561 - accuracy: 0.8277\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5550 - accuracy: 0.8282\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5540 - accuracy: 0.8279\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5544 - accuracy: 0.8278\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5542 - accuracy: 0.8276\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5540 - accuracy: 0.8273\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5534 - accuracy: 0.8280\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5541 - accuracy: 0.8285\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5534 - accuracy: 0.8279\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5536 - accuracy: 0.8279\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5533 - accuracy: 0.8279\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5538 - accuracy: 0.8276\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5513 - accuracy: 0.8276\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5524 - accuracy: 0.8284\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5526 - accuracy: 0.8282\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5521 - accuracy: 0.8283\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5526 - accuracy: 0.8282\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5516 - accuracy: 0.8288\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5514 - accuracy: 0.8288\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5518 - accuracy: 0.8282\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5519 - accuracy: 0.8280\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5518 - accuracy: 0.8283\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5516 - accuracy: 0.8282\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5507 - accuracy: 0.8293\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5505 - accuracy: 0.8291\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5505 - accuracy: 0.8285\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5513 - accuracy: 0.8287\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5512 - accuracy: 0.8283\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5509 - accuracy: 0.8280\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5497 - accuracy: 0.8289\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5505 - accuracy: 0.8288\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5498 - accuracy: 0.8285\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5495 - accuracy: 0.8288\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5500 - accuracy: 0.8294\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5495 - accuracy: 0.8291\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5489 - accuracy: 0.8293\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5500 - accuracy: 0.8291\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5496 - accuracy: 0.8296\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5490 - accuracy: 0.8292\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5496 - accuracy: 0.8293\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5489 - accuracy: 0.8290\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5486 - accuracy: 0.8290\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5488 - accuracy: 0.8290\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5486 - accuracy: 0.8291\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 16s 4ms/step - loss: 0.7347 - accuracy: 0.7765\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.6568 - accuracy: 0.8016\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.6433 - accuracy: 0.8054\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.6357 - accuracy: 0.8074\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.6295 - accuracy: 0.8090\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.6220 - accuracy: 0.8108\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.6174 - accuracy: 0.8118\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.6135 - accuracy: 0.8136\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.6092 - accuracy: 0.8136\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.6069 - accuracy: 0.8147\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.6028 - accuracy: 0.8157\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.6001 - accuracy: 0.8165\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5982 - accuracy: 0.8163\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5953 - accuracy: 0.8173\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5917 - accuracy: 0.8176\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5895 - accuracy: 0.8177\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5857 - accuracy: 0.8185\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5829 - accuracy: 0.8202\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5811 - accuracy: 0.8203\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5801 - accuracy: 0.8209\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5790 - accuracy: 0.8210\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5766 - accuracy: 0.8220\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5755 - accuracy: 0.8225\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5751 - accuracy: 0.8221\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5750 - accuracy: 0.8213\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5735 - accuracy: 0.8223\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5707 - accuracy: 0.8225\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5700 - accuracy: 0.8238\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5693 - accuracy: 0.8240\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5687 - accuracy: 0.8240\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5675 - accuracy: 0.8242\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5659 - accuracy: 0.8245\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5654 - accuracy: 0.8246\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5644 - accuracy: 0.8248\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5631 - accuracy: 0.8255\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5627 - accuracy: 0.8251\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5626 - accuracy: 0.8256\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5614 - accuracy: 0.8261\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5621 - accuracy: 0.8250\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5609 - accuracy: 0.8261\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5600 - accuracy: 0.8258\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5588 - accuracy: 0.8264\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5589 - accuracy: 0.8262\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5586 - accuracy: 0.8265\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5582 - accuracy: 0.8270\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5575 - accuracy: 0.8268\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5570 - accuracy: 0.8266\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5574 - accuracy: 0.8276\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5561 - accuracy: 0.8267\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5562 - accuracy: 0.8272\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5563 - accuracy: 0.8274\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5559 - accuracy: 0.8273\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5548 - accuracy: 0.8275\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5554 - accuracy: 0.8272\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5544 - accuracy: 0.8277\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5541 - accuracy: 0.8268\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5535 - accuracy: 0.8280\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5547 - accuracy: 0.8275\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5538 - accuracy: 0.8280\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5529 - accuracy: 0.8275\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5534 - accuracy: 0.8282\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5530 - accuracy: 0.8281\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5535 - accuracy: 0.8276\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5528 - accuracy: 0.8286\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5521 - accuracy: 0.8275\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5517 - accuracy: 0.8283\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5525 - accuracy: 0.8280\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5514 - accuracy: 0.8281\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5512 - accuracy: 0.8282\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5511 - accuracy: 0.8283\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5513 - accuracy: 0.8285\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5517 - accuracy: 0.8280\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5501 - accuracy: 0.8285\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5503 - accuracy: 0.8291\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5503 - accuracy: 0.8288\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5498 - accuracy: 0.8283\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5502 - accuracy: 0.8280\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5503 - accuracy: 0.8288\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5499 - accuracy: 0.8286\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5499 - accuracy: 0.8284\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5491 - accuracy: 0.8290\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5502 - accuracy: 0.8284\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5485 - accuracy: 0.8293\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5490 - accuracy: 0.8285\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5479 - accuracy: 0.8290\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5482 - accuracy: 0.8291\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5480 - accuracy: 0.8286\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5482 - accuracy: 0.8290\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5482 - accuracy: 0.8288\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5481 - accuracy: 0.8292\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 12s 4ms/step - loss: 0.5482 - accuracy: 0.8294\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5475 - accuracy: 0.8293\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5481 - accuracy: 0.8296\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5476 - accuracy: 0.8298\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5468 - accuracy: 0.8294\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5472 - accuracy: 0.8290\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5478 - accuracy: 0.8291\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5477 - accuracy: 0.8294\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5468 - accuracy: 0.8291\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5474 - accuracy: 0.8294\n",
      "3343/3343 [==============================] - 7s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 17s 4ms/step - loss: 0.7344 - accuracy: 0.7765\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6593 - accuracy: 0.8009\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6475 - accuracy: 0.8043\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6376 - accuracy: 0.8079\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6282 - accuracy: 0.8099\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6232 - accuracy: 0.8103\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6166 - accuracy: 0.8129\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6151 - accuracy: 0.8125\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6118 - accuracy: 0.8133\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6100 - accuracy: 0.8137\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6067 - accuracy: 0.8148\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6040 - accuracy: 0.8154\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.6015 - accuracy: 0.8156\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5988 - accuracy: 0.8167\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5947 - accuracy: 0.8172\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5929 - accuracy: 0.8179\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5900 - accuracy: 0.8188\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5858 - accuracy: 0.8192\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5844 - accuracy: 0.8197\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5838 - accuracy: 0.8196\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5809 - accuracy: 0.8211\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5802 - accuracy: 0.8208\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5783 - accuracy: 0.8214\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5769 - accuracy: 0.8220\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5754 - accuracy: 0.8223\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5735 - accuracy: 0.8233\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5729 - accuracy: 0.8227\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5714 - accuracy: 0.8227\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5699 - accuracy: 0.8243\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5680 - accuracy: 0.8246\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5682 - accuracy: 0.8236\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5676 - accuracy: 0.8242\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5660 - accuracy: 0.8250\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5654 - accuracy: 0.8244\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5633 - accuracy: 0.8258\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5638 - accuracy: 0.8254\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5634 - accuracy: 0.8247\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5621 - accuracy: 0.8258\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5626 - accuracy: 0.8256\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5624 - accuracy: 0.8259\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5610 - accuracy: 0.8258\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5602 - accuracy: 0.8260\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5606 - accuracy: 0.8261\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5591 - accuracy: 0.8265\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5585 - accuracy: 0.8266\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5591 - accuracy: 0.8263\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5588 - accuracy: 0.8265\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5577 - accuracy: 0.8266\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5572 - accuracy: 0.8270\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5580 - accuracy: 0.8273\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5578 - accuracy: 0.8270\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5569 - accuracy: 0.8269\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5563 - accuracy: 0.8266\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5562 - accuracy: 0.8270\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5570 - accuracy: 0.8276\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5557 - accuracy: 0.8271\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5556 - accuracy: 0.8274\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5556 - accuracy: 0.8268\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5560 - accuracy: 0.8271\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5552 - accuracy: 0.8272\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5548 - accuracy: 0.8275\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5552 - accuracy: 0.8276\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5547 - accuracy: 0.8269\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5544 - accuracy: 0.8275\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5531 - accuracy: 0.8284\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5542 - accuracy: 0.8279\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5526 - accuracy: 0.8284\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5536 - accuracy: 0.8277\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5534 - accuracy: 0.8284\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5538 - accuracy: 0.8274\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5515 - accuracy: 0.8287\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5527 - accuracy: 0.8280\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5529 - accuracy: 0.8283\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5525 - accuracy: 0.8281\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5518 - accuracy: 0.8281\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5522 - accuracy: 0.8277\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5512 - accuracy: 0.8288\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5513 - accuracy: 0.8281\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5524 - accuracy: 0.8283\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5527 - accuracy: 0.8281\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5513 - accuracy: 0.8290\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5515 - accuracy: 0.8280\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5516 - accuracy: 0.8279\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5508 - accuracy: 0.8285\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5496 - accuracy: 0.8289\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5512 - accuracy: 0.8279\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5508 - accuracy: 0.8291\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5498 - accuracy: 0.8290\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5506 - accuracy: 0.8276\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5502 - accuracy: 0.8291\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5500 - accuracy: 0.8283\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5500 - accuracy: 0.8286\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5496 - accuracy: 0.8296\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5500 - accuracy: 0.8288\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5501 - accuracy: 0.8290\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5493 - accuracy: 0.8294\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5493 - accuracy: 0.8291\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5500 - accuracy: 0.8284\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5487 - accuracy: 0.8298\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.5490 - accuracy: 0.8288\n",
      "3343/3343 [==============================] - 8s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 21s 5ms/step - loss: 0.7546 - accuracy: 0.7700\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6630 - accuracy: 0.7996\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6502 - accuracy: 0.8028\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6432 - accuracy: 0.8045\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6366 - accuracy: 0.8072\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6297 - accuracy: 0.8087\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6268 - accuracy: 0.8099\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6215 - accuracy: 0.8118\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6181 - accuracy: 0.8119\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6141 - accuracy: 0.8131\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6120 - accuracy: 0.8131\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6092 - accuracy: 0.8148\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6078 - accuracy: 0.8142\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6047 - accuracy: 0.8157\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6017 - accuracy: 0.8153\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5995 - accuracy: 0.8155\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5961 - accuracy: 0.8167\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5934 - accuracy: 0.8175\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5912 - accuracy: 0.8178\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5887 - accuracy: 0.8180\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5860 - accuracy: 0.8190\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5839 - accuracy: 0.8198\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5836 - accuracy: 0.8194\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5814 - accuracy: 0.8207\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5801 - accuracy: 0.8209\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5794 - accuracy: 0.8212\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5784 - accuracy: 0.8217\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5763 - accuracy: 0.8215\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5752 - accuracy: 0.8220\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5748 - accuracy: 0.8214\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5720 - accuracy: 0.8227\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5721 - accuracy: 0.8232\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5712 - accuracy: 0.8230\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5696 - accuracy: 0.8238\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5692 - accuracy: 0.8238\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5689 - accuracy: 0.8239\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5681 - accuracy: 0.8237\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5669 - accuracy: 0.8241\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5672 - accuracy: 0.8241\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5661 - accuracy: 0.8240\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5654 - accuracy: 0.8244\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5650 - accuracy: 0.8249\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5638 - accuracy: 0.8256\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5637 - accuracy: 0.8251\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5622 - accuracy: 0.8261\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5624 - accuracy: 0.8262\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5630 - accuracy: 0.8251\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5624 - accuracy: 0.8256\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5609 - accuracy: 0.8253\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5615 - accuracy: 0.8252\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5611 - accuracy: 0.8256\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5595 - accuracy: 0.8263\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5596 - accuracy: 0.8262\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5593 - accuracy: 0.8264\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5591 - accuracy: 0.8267\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5588 - accuracy: 0.8263\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5580 - accuracy: 0.8267\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5580 - accuracy: 0.8266\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5581 - accuracy: 0.8266\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5581 - accuracy: 0.8270\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5576 - accuracy: 0.8263\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5576 - accuracy: 0.8267\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5571 - accuracy: 0.8265\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5568 - accuracy: 0.8263\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5579 - accuracy: 0.8264\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5565 - accuracy: 0.8267\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5567 - accuracy: 0.8270\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5554 - accuracy: 0.8270\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5570 - accuracy: 0.8261\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5548 - accuracy: 0.8279\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5556 - accuracy: 0.8275\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5558 - accuracy: 0.8271\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5548 - accuracy: 0.8272\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5547 - accuracy: 0.8274\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5555 - accuracy: 0.8271\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5548 - accuracy: 0.8273\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5553 - accuracy: 0.8274\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5546 - accuracy: 0.8266\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5543 - accuracy: 0.8275\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5535 - accuracy: 0.8278\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5534 - accuracy: 0.8275\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5544 - accuracy: 0.8273\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5541 - accuracy: 0.8272\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5537 - accuracy: 0.8276\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5526 - accuracy: 0.8278\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5537 - accuracy: 0.8279\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5528 - accuracy: 0.8279\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5528 - accuracy: 0.8273\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5527 - accuracy: 0.8278\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5521 - accuracy: 0.8280\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5518 - accuracy: 0.8281\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5519 - accuracy: 0.8273\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5521 - accuracy: 0.8280\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5523 - accuracy: 0.8278\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5537 - accuracy: 0.8274\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5515 - accuracy: 0.8282\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5516 - accuracy: 0.8280\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5520 - accuracy: 0.8277\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5514 - accuracy: 0.8276\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5502 - accuracy: 0.8277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 22s 5ms/step - loss: 0.7513 - accuracy: 0.7692\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6588 - accuracy: 0.7996\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6470 - accuracy: 0.8033\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6402 - accuracy: 0.8051\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6338 - accuracy: 0.8068\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6286 - accuracy: 0.8086\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6241 - accuracy: 0.8112\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6212 - accuracy: 0.8111\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6164 - accuracy: 0.8125\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6136 - accuracy: 0.8131\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6107 - accuracy: 0.8140\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6080 - accuracy: 0.8149\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6057 - accuracy: 0.8151\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6028 - accuracy: 0.8159\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6004 - accuracy: 0.8158\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5997 - accuracy: 0.8153\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5963 - accuracy: 0.8169\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5928 - accuracy: 0.8176\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5907 - accuracy: 0.8174\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5881 - accuracy: 0.8174\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5864 - accuracy: 0.8187\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5857 - accuracy: 0.8195\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5825 - accuracy: 0.8197\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5810 - accuracy: 0.8201\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5790 - accuracy: 0.8207\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5781 - accuracy: 0.8211\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5772 - accuracy: 0.8216\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5759 - accuracy: 0.8220\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5745 - accuracy: 0.8223\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5739 - accuracy: 0.8225\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5715 - accuracy: 0.8225\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5697 - accuracy: 0.8241\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5704 - accuracy: 0.8231\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5685 - accuracy: 0.8243\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5682 - accuracy: 0.8237\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5667 - accuracy: 0.8246\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5656 - accuracy: 0.8244\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5652 - accuracy: 0.8249\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5645 - accuracy: 0.8250\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5640 - accuracy: 0.8249\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5621 - accuracy: 0.8254\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5631 - accuracy: 0.8256\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5619 - accuracy: 0.8256\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5621 - accuracy: 0.8254\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5609 - accuracy: 0.8257\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5606 - accuracy: 0.8255\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5614 - accuracy: 0.8253\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5607 - accuracy: 0.8253\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5595 - accuracy: 0.8258\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5593 - accuracy: 0.8256\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5593 - accuracy: 0.8262\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5583 - accuracy: 0.8267\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5586 - accuracy: 0.8257\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5566 - accuracy: 0.8269\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5577 - accuracy: 0.8266\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5568 - accuracy: 0.8259\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5569 - accuracy: 0.8270\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5574 - accuracy: 0.8261\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5576 - accuracy: 0.8262\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5565 - accuracy: 0.8268\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5554 - accuracy: 0.8275\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5553 - accuracy: 0.8275\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5547 - accuracy: 0.8281\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5544 - accuracy: 0.8272\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5553 - accuracy: 0.8267\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5542 - accuracy: 0.8269\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5545 - accuracy: 0.8272\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5550 - accuracy: 0.8273\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5540 - accuracy: 0.8281\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5533 - accuracy: 0.8275\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5530 - accuracy: 0.8274\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5535 - accuracy: 0.8274\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5530 - accuracy: 0.8275\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5535 - accuracy: 0.8280\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5531 - accuracy: 0.8276\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5531 - accuracy: 0.8277\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5527 - accuracy: 0.8273\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5523 - accuracy: 0.8278\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5522 - accuracy: 0.8276\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5515 - accuracy: 0.8278\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5511 - accuracy: 0.8281\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5513 - accuracy: 0.8278\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5518 - accuracy: 0.8282\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5525 - accuracy: 0.8272\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5512 - accuracy: 0.8284\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5516 - accuracy: 0.8285\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5513 - accuracy: 0.8284\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5527 - accuracy: 0.8276\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5507 - accuracy: 0.8285\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5513 - accuracy: 0.8281\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5503 - accuracy: 0.8277\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5510 - accuracy: 0.8276\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5504 - accuracy: 0.8283\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5504 - accuracy: 0.8282\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5513 - accuracy: 0.8277\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5503 - accuracy: 0.8288\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5501 - accuracy: 0.8277\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5499 - accuracy: 0.8278\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5491 - accuracy: 0.8290\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5496 - accuracy: 0.8284\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 22s 5ms/step - loss: 0.7505 - accuracy: 0.7700\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6618 - accuracy: 0.7980\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6484 - accuracy: 0.8030\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6429 - accuracy: 0.8059\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6387 - accuracy: 0.8056\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6325 - accuracy: 0.8078\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6274 - accuracy: 0.8098\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6226 - accuracy: 0.8113\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6198 - accuracy: 0.8121\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6154 - accuracy: 0.8128\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6131 - accuracy: 0.8131\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6099 - accuracy: 0.8143\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6083 - accuracy: 0.8153\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6049 - accuracy: 0.8148\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6028 - accuracy: 0.8152\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6000 - accuracy: 0.8160\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5972 - accuracy: 0.8164\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5945 - accuracy: 0.8168\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5923 - accuracy: 0.8177\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5895 - accuracy: 0.8185\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5861 - accuracy: 0.8197\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5839 - accuracy: 0.8207\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5827 - accuracy: 0.8194\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5798 - accuracy: 0.8211\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5775 - accuracy: 0.8217\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5765 - accuracy: 0.8221\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5743 - accuracy: 0.8221\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5738 - accuracy: 0.8226\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5724 - accuracy: 0.8228\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5705 - accuracy: 0.8236\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5704 - accuracy: 0.8232\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5691 - accuracy: 0.8236\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5682 - accuracy: 0.8244\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5677 - accuracy: 0.8243\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5659 - accuracy: 0.8238\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5665 - accuracy: 0.8239\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5665 - accuracy: 0.8245\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5641 - accuracy: 0.8246\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5654 - accuracy: 0.8248\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5637 - accuracy: 0.8253\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5631 - accuracy: 0.8251\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5626 - accuracy: 0.8249\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5624 - accuracy: 0.8256\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5626 - accuracy: 0.8247\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5613 - accuracy: 0.8258\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5614 - accuracy: 0.8256\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5603 - accuracy: 0.8262\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5606 - accuracy: 0.8258\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5604 - accuracy: 0.8259\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5589 - accuracy: 0.8267\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5592 - accuracy: 0.8263\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5600 - accuracy: 0.8263\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5586 - accuracy: 0.8267\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5593 - accuracy: 0.8254\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5572 - accuracy: 0.8264\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5581 - accuracy: 0.8260\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5582 - accuracy: 0.8264\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5566 - accuracy: 0.8262\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5575 - accuracy: 0.8264\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5573 - accuracy: 0.8267\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5568 - accuracy: 0.8267\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5556 - accuracy: 0.8267\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5567 - accuracy: 0.8272\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5558 - accuracy: 0.8274\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5570 - accuracy: 0.8270\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5543 - accuracy: 0.8271\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5565 - accuracy: 0.8266\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5558 - accuracy: 0.8265\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5546 - accuracy: 0.8270\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5552 - accuracy: 0.8273\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5544 - accuracy: 0.8267\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5538 - accuracy: 0.8273\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5531 - accuracy: 0.8280\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5552 - accuracy: 0.8268\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5533 - accuracy: 0.8276\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5534 - accuracy: 0.8276\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5550 - accuracy: 0.8269\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5534 - accuracy: 0.8276\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5535 - accuracy: 0.8269\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5538 - accuracy: 0.8273\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5529 - accuracy: 0.8274\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5526 - accuracy: 0.8279\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5532 - accuracy: 0.8279\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5520 - accuracy: 0.8285\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5531 - accuracy: 0.8271\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5523 - accuracy: 0.8276\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5512 - accuracy: 0.8282\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5520 - accuracy: 0.8279\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5520 - accuracy: 0.8279\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5521 - accuracy: 0.8276\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5520 - accuracy: 0.8278\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5512 - accuracy: 0.8279\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5506 - accuracy: 0.8276\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5511 - accuracy: 0.8282\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5514 - accuracy: 0.8282\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5512 - accuracy: 0.8281\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5520 - accuracy: 0.8284\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5519 - accuracy: 0.8280\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5498 - accuracy: 0.8282\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5510 - accuracy: 0.8280\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 27s 6ms/step - loss: 0.7774 - accuracy: 0.7622\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6692 - accuracy: 0.7971\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6575 - accuracy: 0.7999\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6504 - accuracy: 0.8034\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6444 - accuracy: 0.8051\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6405 - accuracy: 0.8070\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6339 - accuracy: 0.8086\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6304 - accuracy: 0.8100\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6254 - accuracy: 0.8118\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6205 - accuracy: 0.8128\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6192 - accuracy: 0.8127\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6162 - accuracy: 0.8126\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6146 - accuracy: 0.8133\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6117 - accuracy: 0.8135\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6094 - accuracy: 0.8148\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6060 - accuracy: 0.8149\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6038 - accuracy: 0.8161\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6020 - accuracy: 0.8157\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5995 - accuracy: 0.8168\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5968 - accuracy: 0.8174\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5938 - accuracy: 0.8187\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5904 - accuracy: 0.8189\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5877 - accuracy: 0.8193\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5854 - accuracy: 0.8191\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5849 - accuracy: 0.8191\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5819 - accuracy: 0.8208\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5805 - accuracy: 0.8212\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5787 - accuracy: 0.8212\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5766 - accuracy: 0.8219\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5759 - accuracy: 0.8221\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5756 - accuracy: 0.8224\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5743 - accuracy: 0.8221\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5727 - accuracy: 0.8233\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5732 - accuracy: 0.8226\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5713 - accuracy: 0.8236\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5706 - accuracy: 0.8237\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5699 - accuracy: 0.8229\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5703 - accuracy: 0.8234\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5695 - accuracy: 0.8227\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5684 - accuracy: 0.8232\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5684 - accuracy: 0.8235\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5665 - accuracy: 0.8248\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5666 - accuracy: 0.8242\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5663 - accuracy: 0.8238\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5646 - accuracy: 0.8250\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5652 - accuracy: 0.8243\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5654 - accuracy: 0.8245\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5651 - accuracy: 0.8248\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5644 - accuracy: 0.8247\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5639 - accuracy: 0.8246\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5641 - accuracy: 0.8242\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5643 - accuracy: 0.8241\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5622 - accuracy: 0.8254\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5614 - accuracy: 0.8256\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5615 - accuracy: 0.8261\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5613 - accuracy: 0.8256\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5603 - accuracy: 0.8257\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5612 - accuracy: 0.8259\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5606 - accuracy: 0.8261\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5606 - accuracy: 0.8256\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5605 - accuracy: 0.8258\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5597 - accuracy: 0.8257\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5595 - accuracy: 0.8259\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5586 - accuracy: 0.8260\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5594 - accuracy: 0.8257\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5582 - accuracy: 0.8266\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5591 - accuracy: 0.8264\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5578 - accuracy: 0.8267\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5597 - accuracy: 0.8256\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5593 - accuracy: 0.8255\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5595 - accuracy: 0.8260\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5581 - accuracy: 0.8263\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5584 - accuracy: 0.8256\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5569 - accuracy: 0.8269\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5575 - accuracy: 0.8265\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5579 - accuracy: 0.8270\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5570 - accuracy: 0.8268\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5583 - accuracy: 0.8262\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5572 - accuracy: 0.8263\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5561 - accuracy: 0.8269\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5558 - accuracy: 0.8267\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5564 - accuracy: 0.8267\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5563 - accuracy: 0.8272\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5567 - accuracy: 0.8270\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5559 - accuracy: 0.8274\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5563 - accuracy: 0.8266\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5554 - accuracy: 0.8272\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5546 - accuracy: 0.8276\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5546 - accuracy: 0.8271\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5547 - accuracy: 0.8269\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5545 - accuracy: 0.8270\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5546 - accuracy: 0.8273\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5554 - accuracy: 0.8271\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5539 - accuracy: 0.8278\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5539 - accuracy: 0.8282\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5542 - accuracy: 0.8279\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5541 - accuracy: 0.8276\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5551 - accuracy: 0.8273\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.5541 - accuracy: 0.8279\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5531 - accuracy: 0.8274\n",
      "3343/3343 [==============================] - 11s 3ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 27s 6ms/step - loss: 0.7809 - accuracy: 0.7595\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6666 - accuracy: 0.7966\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6542 - accuracy: 0.8019\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6484 - accuracy: 0.8037\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6412 - accuracy: 0.8060\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6378 - accuracy: 0.8068\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6327 - accuracy: 0.8091\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6282 - accuracy: 0.8107\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6244 - accuracy: 0.8113\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6204 - accuracy: 0.8121\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6181 - accuracy: 0.8123\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6153 - accuracy: 0.8126\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.6121 - accuracy: 0.8141\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6098 - accuracy: 0.8144\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6063 - accuracy: 0.8152\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6043 - accuracy: 0.8157\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6035 - accuracy: 0.8159\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5998 - accuracy: 0.8174\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5979 - accuracy: 0.8168\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5953 - accuracy: 0.8173\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5928 - accuracy: 0.8187\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.5911 - accuracy: 0.8187\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5885 - accuracy: 0.8187\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5865 - accuracy: 0.8193\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5853 - accuracy: 0.8196\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.5845 - accuracy: 0.8196\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.5824 - accuracy: 0.8203\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5800 - accuracy: 0.8216\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5792 - accuracy: 0.8216\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5778 - accuracy: 0.8211\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.5760 - accuracy: 0.8223\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5744 - accuracy: 0.8223\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5743 - accuracy: 0.8224\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5730 - accuracy: 0.8227\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5712 - accuracy: 0.8231\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5715 - accuracy: 0.8239\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5699 - accuracy: 0.8240\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5699 - accuracy: 0.8231\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5704 - accuracy: 0.8234\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5686 - accuracy: 0.8237\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5668 - accuracy: 0.8244\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5670 - accuracy: 0.8243\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.5655 - accuracy: 0.8251\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5676 - accuracy: 0.8240\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5650 - accuracy: 0.8253\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5647 - accuracy: 0.8251\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5651 - accuracy: 0.8251\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5634 - accuracy: 0.8260\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.5627 - accuracy: 0.8253\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5642 - accuracy: 0.8247\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5631 - accuracy: 0.8253\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5636 - accuracy: 0.8251\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5627 - accuracy: 0.8250\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5623 - accuracy: 0.8255\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5622 - accuracy: 0.8256\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5605 - accuracy: 0.8256\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5610 - accuracy: 0.8261\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5613 - accuracy: 0.8253\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5601 - accuracy: 0.8257\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5598 - accuracy: 0.8256\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5599 - accuracy: 0.8260\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5592 - accuracy: 0.8263\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5597 - accuracy: 0.8262\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5593 - accuracy: 0.8261\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5579 - accuracy: 0.8255\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.5572 - accuracy: 0.8260\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5588 - accuracy: 0.8263\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5586 - accuracy: 0.8256\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.5585 - accuracy: 0.8262\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5572 - accuracy: 0.8263\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5573 - accuracy: 0.8262\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5564 - accuracy: 0.8264\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5566 - accuracy: 0.8275\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5561 - accuracy: 0.8276\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5564 - accuracy: 0.8268\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5567 - accuracy: 0.8265\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5554 - accuracy: 0.8269\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.5566 - accuracy: 0.8278\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5546 - accuracy: 0.8267\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5560 - accuracy: 0.8264\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.5554 - accuracy: 0.8270\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5555 - accuracy: 0.8272\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.5550 - accuracy: 0.8274\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5540 - accuracy: 0.8277\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5549 - accuracy: 0.8273\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5548 - accuracy: 0.8271\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5557 - accuracy: 0.8267\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5534 - accuracy: 0.8277\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.5556 - accuracy: 0.8271\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5546 - accuracy: 0.8272\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5543 - accuracy: 0.8270\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5534 - accuracy: 0.8274\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5545 - accuracy: 0.8274\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5532 - accuracy: 0.8289\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5535 - accuracy: 0.8278\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.5527 - accuracy: 0.8286\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5520 - accuracy: 0.8281\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5521 - accuracy: 0.8280\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5526 - accuracy: 0.8278\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5520 - accuracy: 0.8279\n",
      "3343/3343 [==============================] - 11s 3ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 27s 6ms/step - loss: 0.7902 - accuracy: 0.7573\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6688 - accuracy: 0.7966\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6567 - accuracy: 0.8012\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6509 - accuracy: 0.8042\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6436 - accuracy: 0.8059\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6392 - accuracy: 0.8066\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6342 - accuracy: 0.8093\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6314 - accuracy: 0.8098\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6256 - accuracy: 0.8107\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6230 - accuracy: 0.8119\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6192 - accuracy: 0.8124\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6167 - accuracy: 0.8131\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6144 - accuracy: 0.8138\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6123 - accuracy: 0.8144\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6099 - accuracy: 0.8145\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6073 - accuracy: 0.8159\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6055 - accuracy: 0.8157\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6030 - accuracy: 0.8162\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6011 - accuracy: 0.8166\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5982 - accuracy: 0.8176\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5954 - accuracy: 0.8185\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5941 - accuracy: 0.8181\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5922 - accuracy: 0.8185\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5879 - accuracy: 0.8191\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5864 - accuracy: 0.8192\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5847 - accuracy: 0.8190\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5822 - accuracy: 0.8201\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5801 - accuracy: 0.8213\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5790 - accuracy: 0.8210\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5772 - accuracy: 0.8218\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5771 - accuracy: 0.8220\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5760 - accuracy: 0.8224\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5741 - accuracy: 0.8224\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5737 - accuracy: 0.8222\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5713 - accuracy: 0.8225\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5719 - accuracy: 0.8231\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5712 - accuracy: 0.8227\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5698 - accuracy: 0.8230\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.5693 - accuracy: 0.8229\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5692 - accuracy: 0.8235\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5688 - accuracy: 0.8235\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5688 - accuracy: 0.8233\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5680 - accuracy: 0.8239\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5668 - accuracy: 0.8248\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5662 - accuracy: 0.8240\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5674 - accuracy: 0.8239\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5651 - accuracy: 0.8247\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5656 - accuracy: 0.8251\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5650 - accuracy: 0.8246\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.5651 - accuracy: 0.8249\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5650 - accuracy: 0.8247\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5642 - accuracy: 0.8247\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5635 - accuracy: 0.8246\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5638 - accuracy: 0.8245\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5631 - accuracy: 0.8252\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5639 - accuracy: 0.8245\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5635 - accuracy: 0.8250\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5630 - accuracy: 0.8248\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5600 - accuracy: 0.8255\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5610 - accuracy: 0.8254\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5614 - accuracy: 0.8251\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5610 - accuracy: 0.8256\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5618 - accuracy: 0.8251\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5608 - accuracy: 0.8255\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5603 - accuracy: 0.8261\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5598 - accuracy: 0.8261\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.5594 - accuracy: 0.8263\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5601 - accuracy: 0.8259\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5592 - accuracy: 0.8260\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5594 - accuracy: 0.8259\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5587 - accuracy: 0.8262\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5581 - accuracy: 0.8266\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.5579 - accuracy: 0.8267\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5580 - accuracy: 0.8261\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5578 - accuracy: 0.8273\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5581 - accuracy: 0.8265\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5589 - accuracy: 0.8258\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5579 - accuracy: 0.8260\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5564 - accuracy: 0.8271\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5565 - accuracy: 0.8263\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5576 - accuracy: 0.8273\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5562 - accuracy: 0.8269\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5574 - accuracy: 0.8272\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5568 - accuracy: 0.8266\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5559 - accuracy: 0.8271\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5567 - accuracy: 0.8272\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5564 - accuracy: 0.8271\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5549 - accuracy: 0.8278\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5559 - accuracy: 0.8266\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5553 - accuracy: 0.8272\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5556 - accuracy: 0.8275\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5544 - accuracy: 0.8276\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5569 - accuracy: 0.8264\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5550 - accuracy: 0.8261\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5542 - accuracy: 0.8273\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.5542 - accuracy: 0.8270\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5546 - accuracy: 0.8269\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5540 - accuracy: 0.8273\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5545 - accuracy: 0.8266\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.5548 - accuracy: 0.8271\n",
      "3343/3343 [==============================] - 11s 3ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 33s 8ms/step - loss: 0.7935 - accuracy: 0.7561\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6758 - accuracy: 0.7940\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6646 - accuracy: 0.7980\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6545 - accuracy: 0.8019\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6510 - accuracy: 0.8030\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6468 - accuracy: 0.8046\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6428 - accuracy: 0.8060\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6396 - accuracy: 0.8076\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6358 - accuracy: 0.8084\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6340 - accuracy: 0.8097\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6301 - accuracy: 0.8103\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6255 - accuracy: 0.8117\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6230 - accuracy: 0.8124\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6197 - accuracy: 0.8128\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6162 - accuracy: 0.8133\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6148 - accuracy: 0.8135\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6126 - accuracy: 0.8146\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6104 - accuracy: 0.8151\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6083 - accuracy: 0.8151\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6059 - accuracy: 0.8159\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6021 - accuracy: 0.8168\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6009 - accuracy: 0.8165\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5983 - accuracy: 0.8168\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5961 - accuracy: 0.8183\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5947 - accuracy: 0.8183\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5924 - accuracy: 0.8189\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5907 - accuracy: 0.8197\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5880 - accuracy: 0.8195\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5866 - accuracy: 0.8203\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5841 - accuracy: 0.8207\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5832 - accuracy: 0.8207\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5828 - accuracy: 0.8213\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5818 - accuracy: 0.8206\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5796 - accuracy: 0.8216\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5795 - accuracy: 0.8216\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5777 - accuracy: 0.8224\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5768 - accuracy: 0.8225\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5762 - accuracy: 0.8219\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5753 - accuracy: 0.8230\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5742 - accuracy: 0.8228\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5733 - accuracy: 0.8233\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5732 - accuracy: 0.8225\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5729 - accuracy: 0.8238\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5722 - accuracy: 0.8226\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5710 - accuracy: 0.8234\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5706 - accuracy: 0.8237\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5704 - accuracy: 0.8244\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5692 - accuracy: 0.8244\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5699 - accuracy: 0.8239\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5696 - accuracy: 0.8235\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5675 - accuracy: 0.8250\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5678 - accuracy: 0.8247\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5669 - accuracy: 0.8252\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5675 - accuracy: 0.8245\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5675 - accuracy: 0.8246\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5666 - accuracy: 0.8244\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5660 - accuracy: 0.8252\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5653 - accuracy: 0.8255\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5653 - accuracy: 0.8252\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5647 - accuracy: 0.8254\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5654 - accuracy: 0.8256\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5635 - accuracy: 0.8257\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5641 - accuracy: 0.8255\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5648 - accuracy: 0.8253\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5622 - accuracy: 0.8256\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5628 - accuracy: 0.8256\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5629 - accuracy: 0.8253\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5627 - accuracy: 0.8251\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5631 - accuracy: 0.8259\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5634 - accuracy: 0.8251\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5628 - accuracy: 0.8256\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5619 - accuracy: 0.8263\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5602 - accuracy: 0.8267\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5606 - accuracy: 0.8259\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5623 - accuracy: 0.8257\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5604 - accuracy: 0.8260\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5609 - accuracy: 0.8268\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5609 - accuracy: 0.8262\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5595 - accuracy: 0.8272\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5595 - accuracy: 0.8267\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5596 - accuracy: 0.8269\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5598 - accuracy: 0.8268\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5592 - accuracy: 0.8266\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5606 - accuracy: 0.8267\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5592 - accuracy: 0.8266\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5591 - accuracy: 0.8269\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5587 - accuracy: 0.8276\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5594 - accuracy: 0.8262\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5588 - accuracy: 0.8263\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5581 - accuracy: 0.8272\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5585 - accuracy: 0.8273\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5589 - accuracy: 0.8263\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5601 - accuracy: 0.8263\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5576 - accuracy: 0.8272\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5581 - accuracy: 0.8265\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5583 - accuracy: 0.8270\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5578 - accuracy: 0.8264\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5587 - accuracy: 0.8267\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5576 - accuracy: 0.8270\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5571 - accuracy: 0.8270\n",
      "3343/3343 [==============================] - 12s 3ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 32s 7ms/step - loss: 0.7930 - accuracy: 0.7574\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6719 - accuracy: 0.7946\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6610 - accuracy: 0.7989\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6533 - accuracy: 0.8009\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6468 - accuracy: 0.8043\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6436 - accuracy: 0.8051\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6384 - accuracy: 0.8074\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6363 - accuracy: 0.8079\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6336 - accuracy: 0.8089\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6318 - accuracy: 0.8093\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6267 - accuracy: 0.8105\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6235 - accuracy: 0.8111\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6209 - accuracy: 0.8125\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6175 - accuracy: 0.8134\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6150 - accuracy: 0.8129\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6119 - accuracy: 0.8146\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6104 - accuracy: 0.8147\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6082 - accuracy: 0.8157\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6061 - accuracy: 0.8158\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6054 - accuracy: 0.8158\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6028 - accuracy: 0.8166\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6028 - accuracy: 0.8162\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5999 - accuracy: 0.8175\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5991 - accuracy: 0.8177\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5959 - accuracy: 0.8183\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5948 - accuracy: 0.8176\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5938 - accuracy: 0.8182\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5919 - accuracy: 0.8192\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5897 - accuracy: 0.8193\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5882 - accuracy: 0.8196\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5873 - accuracy: 0.8196\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5852 - accuracy: 0.8204\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5847 - accuracy: 0.8201\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5834 - accuracy: 0.8203\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5841 - accuracy: 0.8211\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5805 - accuracy: 0.8212\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5781 - accuracy: 0.8218\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5772 - accuracy: 0.8228\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5773 - accuracy: 0.8222\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5756 - accuracy: 0.8220\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 21s 8ms/step - loss: 0.5751 - accuracy: 0.8226\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5724 - accuracy: 0.8230\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5735 - accuracy: 0.8229\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5742 - accuracy: 0.8227\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5722 - accuracy: 0.8233\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5723 - accuracy: 0.8232\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5697 - accuracy: 0.8240\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5699 - accuracy: 0.8231\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5683 - accuracy: 0.8247\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5695 - accuracy: 0.8236\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5688 - accuracy: 0.8244\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5689 - accuracy: 0.8244\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5665 - accuracy: 0.8249\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5671 - accuracy: 0.8251\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5659 - accuracy: 0.8246\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5651 - accuracy: 0.8254\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5674 - accuracy: 0.8247\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 21s 8ms/step - loss: 0.5656 - accuracy: 0.8254\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5658 - accuracy: 0.8248\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5660 - accuracy: 0.8244\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5652 - accuracy: 0.8245\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5649 - accuracy: 0.8249\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5647 - accuracy: 0.8250\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5633 - accuracy: 0.8260\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5637 - accuracy: 0.8260\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5628 - accuracy: 0.8251\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5617 - accuracy: 0.8256\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5624 - accuracy: 0.8255\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5617 - accuracy: 0.8261\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5621 - accuracy: 0.8254\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5619 - accuracy: 0.8257\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5604 - accuracy: 0.8265\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5609 - accuracy: 0.8260\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5605 - accuracy: 0.8261\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5605 - accuracy: 0.8264\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5600 - accuracy: 0.8268\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5607 - accuracy: 0.8258\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5607 - accuracy: 0.8267\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5598 - accuracy: 0.8265\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5586 - accuracy: 0.8268\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5600 - accuracy: 0.8265\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5589 - accuracy: 0.8271\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5600 - accuracy: 0.8266\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5587 - accuracy: 0.8266\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5593 - accuracy: 0.8272\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5575 - accuracy: 0.8270\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5577 - accuracy: 0.8269\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5572 - accuracy: 0.8266\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5571 - accuracy: 0.8266\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5576 - accuracy: 0.8268\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5570 - accuracy: 0.8269\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5576 - accuracy: 0.8271\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5582 - accuracy: 0.8269\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5567 - accuracy: 0.8276\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5578 - accuracy: 0.8268\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5571 - accuracy: 0.8277\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5568 - accuracy: 0.8272\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5581 - accuracy: 0.8267\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5561 - accuracy: 0.8276\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5562 - accuracy: 0.8272\n",
      "3343/3343 [==============================] - 12s 3ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 32s 8ms/step - loss: 0.7910 - accuracy: 0.7578\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6764 - accuracy: 0.7936\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6633 - accuracy: 0.7980\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6559 - accuracy: 0.8015\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6508 - accuracy: 0.8035\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6462 - accuracy: 0.8052\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6425 - accuracy: 0.8063\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6402 - accuracy: 0.8068\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6366 - accuracy: 0.8089\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6337 - accuracy: 0.8087\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6304 - accuracy: 0.8099\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6264 - accuracy: 0.8114\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.6237 - accuracy: 0.8109\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6205 - accuracy: 0.8117\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6183 - accuracy: 0.8124\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6173 - accuracy: 0.8127\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6134 - accuracy: 0.8137\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6122 - accuracy: 0.8146\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6100 - accuracy: 0.8151\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6078 - accuracy: 0.8166\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6060 - accuracy: 0.8157\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6049 - accuracy: 0.8166\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6034 - accuracy: 0.8162\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6027 - accuracy: 0.8173\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.6006 - accuracy: 0.8174\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5979 - accuracy: 0.8181\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5974 - accuracy: 0.8175\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5953 - accuracy: 0.8184\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5950 - accuracy: 0.8197\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5915 - accuracy: 0.8199\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5902 - accuracy: 0.8200\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5890 - accuracy: 0.8193\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5884 - accuracy: 0.8198\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5859 - accuracy: 0.8208\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5847 - accuracy: 0.8199\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5841 - accuracy: 0.8215\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5824 - accuracy: 0.8215\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5810 - accuracy: 0.8219\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5801 - accuracy: 0.8220\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5796 - accuracy: 0.8226\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5782 - accuracy: 0.8228\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5785 - accuracy: 0.8225\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5774 - accuracy: 0.8225\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5756 - accuracy: 0.8237\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5744 - accuracy: 0.8230\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5752 - accuracy: 0.8228\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5741 - accuracy: 0.8226\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5730 - accuracy: 0.8233\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5722 - accuracy: 0.8239\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5716 - accuracy: 0.8236\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5710 - accuracy: 0.8242\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5712 - accuracy: 0.8241\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5713 - accuracy: 0.8237\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5692 - accuracy: 0.8243\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5694 - accuracy: 0.8243\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5692 - accuracy: 0.8237\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5682 - accuracy: 0.8238\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5683 - accuracy: 0.8245\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5682 - accuracy: 0.8243\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5669 - accuracy: 0.8243\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5675 - accuracy: 0.8241\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5663 - accuracy: 0.8244\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5661 - accuracy: 0.8252\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5711 - accuracy: 0.8241\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5655 - accuracy: 0.8254\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5662 - accuracy: 0.8249\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5650 - accuracy: 0.8251\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5656 - accuracy: 0.8255\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5643 - accuracy: 0.8256\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5643 - accuracy: 0.8258\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5644 - accuracy: 0.8255\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5636 - accuracy: 0.8254\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5648 - accuracy: 0.8250\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5640 - accuracy: 0.8251\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5625 - accuracy: 0.8264\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5624 - accuracy: 0.8265\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5623 - accuracy: 0.8259\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5631 - accuracy: 0.8263\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5621 - accuracy: 0.8257\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5625 - accuracy: 0.8261\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5614 - accuracy: 0.8254\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5614 - accuracy: 0.8256\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5615 - accuracy: 0.8263\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5610 - accuracy: 0.8266\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5612 - accuracy: 0.8265\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5601 - accuracy: 0.8268\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5612 - accuracy: 0.8260\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5600 - accuracy: 0.8262\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5602 - accuracy: 0.8260\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5603 - accuracy: 0.8266\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 20s 7ms/step - loss: 0.5596 - accuracy: 0.8270\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5598 - accuracy: 0.8268\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5601 - accuracy: 0.8265\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5593 - accuracy: 0.8257\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5600 - accuracy: 0.8266\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5589 - accuracy: 0.8266\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5591 - accuracy: 0.8270\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5597 - accuracy: 0.8265\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5582 - accuracy: 0.8269\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 20s 8ms/step - loss: 0.5593 - accuracy: 0.8264\n",
      "3343/3343 [==============================] - 12s 3ms/step\n",
      "Epoch 1/100\n",
      "4012/4012 [==============================] - 30s 5ms/step - loss: 0.7218 - accuracy: 0.7798\n",
      "Epoch 2/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6532 - accuracy: 0.8023\n",
      "Epoch 3/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6419 - accuracy: 0.8051\n",
      "Epoch 4/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6346 - accuracy: 0.8069\n",
      "Epoch 5/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6258 - accuracy: 0.8092\n",
      "Epoch 6/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6198 - accuracy: 0.8112\n",
      "Epoch 7/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6151 - accuracy: 0.8123\n",
      "Epoch 8/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6099 - accuracy: 0.8140\n",
      "Epoch 9/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6065 - accuracy: 0.8148\n",
      "Epoch 10/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6036 - accuracy: 0.8155\n",
      "Epoch 11/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5998 - accuracy: 0.8166\n",
      "Epoch 12/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5966 - accuracy: 0.8170\n",
      "Epoch 13/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5918 - accuracy: 0.8179\n",
      "Epoch 14/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5875 - accuracy: 0.8192\n",
      "Epoch 15/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5836 - accuracy: 0.8203\n",
      "Epoch 16/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5810 - accuracy: 0.8209\n",
      "Epoch 17/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5776 - accuracy: 0.8223\n",
      "Epoch 18/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5753 - accuracy: 0.8222\n",
      "Epoch 19/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5740 - accuracy: 0.8225\n",
      "Epoch 20/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5717 - accuracy: 0.8237\n",
      "Epoch 21/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5695 - accuracy: 0.8236\n",
      "Epoch 22/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5686 - accuracy: 0.8238\n",
      "Epoch 23/100\n",
      "4012/4012 [==============================] - 21s 5ms/step - loss: 0.5672 - accuracy: 0.8245\n",
      "Epoch 24/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5664 - accuracy: 0.8246\n",
      "Epoch 25/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5643 - accuracy: 0.8253\n",
      "Epoch 26/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5645 - accuracy: 0.8249\n",
      "Epoch 27/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5644 - accuracy: 0.8251\n",
      "Epoch 28/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5639 - accuracy: 0.8251\n",
      "Epoch 29/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5633 - accuracy: 0.8256\n",
      "Epoch 30/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5622 - accuracy: 0.8255\n",
      "Epoch 31/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5606 - accuracy: 0.8260\n",
      "Epoch 32/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5611 - accuracy: 0.8260\n",
      "Epoch 33/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5610 - accuracy: 0.8261\n",
      "Epoch 34/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5597 - accuracy: 0.8264\n",
      "Epoch 35/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5599 - accuracy: 0.8258\n",
      "Epoch 36/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5588 - accuracy: 0.8265\n",
      "Epoch 37/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5591 - accuracy: 0.8262\n",
      "Epoch 38/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5579 - accuracy: 0.8266\n",
      "Epoch 39/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5588 - accuracy: 0.8260\n",
      "Epoch 40/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5582 - accuracy: 0.8265\n",
      "Epoch 41/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5568 - accuracy: 0.8271\n",
      "Epoch 42/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5575 - accuracy: 0.8269\n",
      "Epoch 43/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5572 - accuracy: 0.8271\n",
      "Epoch 44/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5561 - accuracy: 0.8270\n",
      "Epoch 45/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5564 - accuracy: 0.8264\n",
      "Epoch 46/100\n",
      "4012/4012 [==============================] - 21s 5ms/step - loss: 0.5553 - accuracy: 0.8276\n",
      "Epoch 47/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5565 - accuracy: 0.8267\n",
      "Epoch 48/100\n",
      "4012/4012 [==============================] - 23s 6ms/step - loss: 0.5548 - accuracy: 0.8272\n",
      "Epoch 49/100\n",
      "4012/4012 [==============================] - 21s 5ms/step - loss: 0.5539 - accuracy: 0.8276\n",
      "Epoch 50/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5544 - accuracy: 0.8279\n",
      "Epoch 51/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5538 - accuracy: 0.8273\n",
      "Epoch 52/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5549 - accuracy: 0.8270\n",
      "Epoch 53/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5538 - accuracy: 0.8274\n",
      "Epoch 54/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5534 - accuracy: 0.8275\n",
      "Epoch 55/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5535 - accuracy: 0.8270\n",
      "Epoch 56/100\n",
      "4012/4012 [==============================] - 21s 5ms/step - loss: 0.5542 - accuracy: 0.8272\n",
      "Epoch 57/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5528 - accuracy: 0.8276\n",
      "Epoch 58/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5526 - accuracy: 0.8276\n",
      "Epoch 59/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5525 - accuracy: 0.8281\n",
      "Epoch 60/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5522 - accuracy: 0.8277\n",
      "Epoch 61/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5511 - accuracy: 0.8284\n",
      "Epoch 62/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5525 - accuracy: 0.8278\n",
      "Epoch 63/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5515 - accuracy: 0.8277\n",
      "Epoch 64/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5516 - accuracy: 0.8278\n",
      "Epoch 65/100\n",
      "4012/4012 [==============================] - 21s 5ms/step - loss: 0.5523 - accuracy: 0.8283\n",
      "Epoch 66/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5515 - accuracy: 0.8278\n",
      "Epoch 67/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5515 - accuracy: 0.8281\n",
      "Epoch 68/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5516 - accuracy: 0.8281\n",
      "Epoch 69/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5512 - accuracy: 0.8280\n",
      "Epoch 70/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5507 - accuracy: 0.8283\n",
      "Epoch 71/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5507 - accuracy: 0.8284\n",
      "Epoch 72/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5513 - accuracy: 0.8281\n",
      "Epoch 73/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5516 - accuracy: 0.8283\n",
      "Epoch 74/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5506 - accuracy: 0.8285\n",
      "Epoch 75/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5502 - accuracy: 0.8284\n",
      "Epoch 76/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5502 - accuracy: 0.8285\n",
      "Epoch 77/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5497 - accuracy: 0.8283\n",
      "Epoch 78/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5496 - accuracy: 0.8288\n",
      "Epoch 79/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5485 - accuracy: 0.8287\n",
      "Epoch 80/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5494 - accuracy: 0.8286\n",
      "Epoch 81/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5502 - accuracy: 0.8281\n",
      "Epoch 82/100\n",
      "4012/4012 [==============================] - 21s 5ms/step - loss: 0.5492 - accuracy: 0.8283\n",
      "Epoch 83/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5499 - accuracy: 0.8283\n",
      "Epoch 84/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5499 - accuracy: 0.8287\n",
      "Epoch 85/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5488 - accuracy: 0.8289\n",
      "Epoch 86/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5493 - accuracy: 0.8287\n",
      "Epoch 87/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5485 - accuracy: 0.8288\n",
      "Epoch 88/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5481 - accuracy: 0.8285\n",
      "Epoch 89/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5483 - accuracy: 0.8290\n",
      "Epoch 90/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5483 - accuracy: 0.8292\n",
      "Epoch 91/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5482 - accuracy: 0.8291\n",
      "Epoch 92/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5484 - accuracy: 0.8290\n",
      "Epoch 93/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5481 - accuracy: 0.8288\n",
      "Epoch 94/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5480 - accuracy: 0.8285\n",
      "Epoch 95/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5478 - accuracy: 0.8289\n",
      "Epoch 96/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5484 - accuracy: 0.8282\n",
      "Epoch 97/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5492 - accuracy: 0.8288\n",
      "Epoch 98/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5478 - accuracy: 0.8286\n",
      "Epoch 99/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5477 - accuracy: 0.8292\n",
      "Epoch 100/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5483 - accuracy: 0.8297\n",
      "Best Results with Grid Search:\n",
      "0.8337181944249678\n",
      "{'No_Of_layers': 3}\n"
     ]
    }
   ],
   "source": [
    "#Layers Tuning for LSTM Layer\n",
    "\n",
    "def create_model(No_Of_layers):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if No_Of_layers == 1:\n",
    "        model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='tanh'))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=90, input_shape=(1, 11), activation='tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "    elif No_Of_layers == 2:\n",
    "        model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='tanh'))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=90, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=90, input_shape=(1, 11), activation='tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "    elif No_Of_layers == 3:\n",
    "        model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='tanh'))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=90, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=90, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=90, input_shape=(1, 11), activation='tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "    elif No_Of_layers == 4:\n",
    "        model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='tanh'))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=90, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=90, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=90, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=90, input_shape=(1, 11), activation='tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "    elif No_Of_layers == 5:\n",
    "        model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='tanh'))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=90, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=90, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=90, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=90, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=90, input_shape=(1, 11), activation='tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "    \n",
    "    # Add an output layer \n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    #compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1, epochs = 100, batch_size = 80)\n",
    "\n",
    "parameters = {\n",
    "    #'unit': [60],\n",
    "    'No_Of_layers': [1,2,3,4,5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_L, y_train_L)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a861412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xaxis_LSTM_layers =[1,2,3,4,5]\n",
    "plt.plot(xaxis_LSTM_layers,means,'.-')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of LSTM Layers')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"Figures/No.OfLayers_LSTM(ConvLSTM).png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f4d9f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f190806\\AppData\\Local\\Temp\\2\\ipykernel_7416\\451185843.py:26: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=1, epochs = 100, batch_size = 80)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 22s 5ms/step - loss: 0.7508 - accuracy: 0.7698\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6658 - accuracy: 0.7979\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6524 - accuracy: 0.8026\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6448 - accuracy: 0.8052\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6404 - accuracy: 0.8062\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6321 - accuracy: 0.8087\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6269 - accuracy: 0.8101\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6235 - accuracy: 0.8106\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6194 - accuracy: 0.8117\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6161 - accuracy: 0.8133\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6131 - accuracy: 0.8134\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6102 - accuracy: 0.8141\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6075 - accuracy: 0.8147\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6067 - accuracy: 0.8151\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6027 - accuracy: 0.8153\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6012 - accuracy: 0.8161\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5985 - accuracy: 0.8161\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5946 - accuracy: 0.8172\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5913 - accuracy: 0.8177\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5889 - accuracy: 0.8180\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5884 - accuracy: 0.8179\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5853 - accuracy: 0.8186\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5835 - accuracy: 0.8196\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5825 - accuracy: 0.8200\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5808 - accuracy: 0.8200\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5790 - accuracy: 0.8211\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5780 - accuracy: 0.8219\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5758 - accuracy: 0.8214\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5758 - accuracy: 0.8218\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5735 - accuracy: 0.8219\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5725 - accuracy: 0.8233\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5708 - accuracy: 0.8228\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5702 - accuracy: 0.8234\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5689 - accuracy: 0.8231\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5688 - accuracy: 0.8237\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5679 - accuracy: 0.8239\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5666 - accuracy: 0.8244\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5670 - accuracy: 0.8236\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5644 - accuracy: 0.8248\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5640 - accuracy: 0.8246\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5653 - accuracy: 0.8245\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5624 - accuracy: 0.8255\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5632 - accuracy: 0.8250\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5632 - accuracy: 0.8254\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5623 - accuracy: 0.8259\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5626 - accuracy: 0.8261\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5607 - accuracy: 0.8264\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5607 - accuracy: 0.8262\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5599 - accuracy: 0.8269\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5606 - accuracy: 0.8256\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5615 - accuracy: 0.8252\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5595 - accuracy: 0.8260\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5591 - accuracy: 0.8261\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5602 - accuracy: 0.8260\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5585 - accuracy: 0.8261\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5577 - accuracy: 0.8266\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5575 - accuracy: 0.8264\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5580 - accuracy: 0.8265\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5568 - accuracy: 0.8269\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5570 - accuracy: 0.8272\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5573 - accuracy: 0.8269\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5571 - accuracy: 0.8266\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5557 - accuracy: 0.8273\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5567 - accuracy: 0.8264\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5556 - accuracy: 0.8269\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5553 - accuracy: 0.8274\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5560 - accuracy: 0.8267\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5557 - accuracy: 0.8269\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5548 - accuracy: 0.8273\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5553 - accuracy: 0.8268\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5550 - accuracy: 0.8275\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5531 - accuracy: 0.8280\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5550 - accuracy: 0.8270\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5535 - accuracy: 0.8277\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5527 - accuracy: 0.8281\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5542 - accuracy: 0.8271\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5536 - accuracy: 0.8278\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5534 - accuracy: 0.8274\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5541 - accuracy: 0.8274\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5536 - accuracy: 0.8281\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5538 - accuracy: 0.8276\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5531 - accuracy: 0.8279\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5530 - accuracy: 0.8274\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5524 - accuracy: 0.8281\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5531 - accuracy: 0.8277\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5525 - accuracy: 0.8285\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5526 - accuracy: 0.8277\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5520 - accuracy: 0.8283\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5528 - accuracy: 0.8281\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5522 - accuracy: 0.8284\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5520 - accuracy: 0.8280\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5508 - accuracy: 0.8287\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5518 - accuracy: 0.8277\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5513 - accuracy: 0.8282\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5515 - accuracy: 0.8284\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5510 - accuracy: 0.8282\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5513 - accuracy: 0.8284\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5513 - accuracy: 0.8277\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5506 - accuracy: 0.8284\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5502 - accuracy: 0.8285\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 22s 5ms/step - loss: 0.7492 - accuracy: 0.7700\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6613 - accuracy: 0.7988\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6486 - accuracy: 0.8028\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6409 - accuracy: 0.8058\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6341 - accuracy: 0.8067\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6283 - accuracy: 0.8087\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6239 - accuracy: 0.8099\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6195 - accuracy: 0.8114\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6172 - accuracy: 0.8124\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6144 - accuracy: 0.8134\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6112 - accuracy: 0.8136\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6078 - accuracy: 0.8138\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6055 - accuracy: 0.8158\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6021 - accuracy: 0.8161\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5998 - accuracy: 0.8168\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5978 - accuracy: 0.8169\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5945 - accuracy: 0.8169\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5909 - accuracy: 0.8177\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5873 - accuracy: 0.8188\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5849 - accuracy: 0.8195\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5820 - accuracy: 0.8210\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5802 - accuracy: 0.8205\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5790 - accuracy: 0.8209\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5763 - accuracy: 0.8221\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5755 - accuracy: 0.8221\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5721 - accuracy: 0.8231\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5734 - accuracy: 0.8222\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5719 - accuracy: 0.8230\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5694 - accuracy: 0.8234\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5693 - accuracy: 0.8238\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5688 - accuracy: 0.8236\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5668 - accuracy: 0.8249\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5661 - accuracy: 0.8242\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5649 - accuracy: 0.8246\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5656 - accuracy: 0.8248\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5653 - accuracy: 0.8241\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5629 - accuracy: 0.8255\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5639 - accuracy: 0.8251\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5624 - accuracy: 0.8253\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5626 - accuracy: 0.8251\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5617 - accuracy: 0.8263\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5626 - accuracy: 0.8254\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5605 - accuracy: 0.8254\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5600 - accuracy: 0.8267\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5591 - accuracy: 0.8261\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5601 - accuracy: 0.8258\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5592 - accuracy: 0.8263\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5600 - accuracy: 0.8262\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5597 - accuracy: 0.8257\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5577 - accuracy: 0.8270\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5581 - accuracy: 0.8269\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5566 - accuracy: 0.8271\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5566 - accuracy: 0.8267\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5561 - accuracy: 0.8269\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5565 - accuracy: 0.8270\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5570 - accuracy: 0.8268\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5562 - accuracy: 0.8268\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5556 - accuracy: 0.8272\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5559 - accuracy: 0.8268\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5553 - accuracy: 0.8271\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5554 - accuracy: 0.8273\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5550 - accuracy: 0.8268\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5549 - accuracy: 0.8273\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5551 - accuracy: 0.8268\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5537 - accuracy: 0.8278\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5546 - accuracy: 0.8275\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5527 - accuracy: 0.8279\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5536 - accuracy: 0.8274\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5535 - accuracy: 0.8277\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5530 - accuracy: 0.8275\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5536 - accuracy: 0.8271\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5534 - accuracy: 0.8276\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5528 - accuracy: 0.8281\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5526 - accuracy: 0.8282\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5526 - accuracy: 0.8279\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5519 - accuracy: 0.8275\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5516 - accuracy: 0.8279\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5517 - accuracy: 0.8284\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5513 - accuracy: 0.8278\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5507 - accuracy: 0.8280\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5512 - accuracy: 0.8278\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5514 - accuracy: 0.8277\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5511 - accuracy: 0.8290\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5503 - accuracy: 0.8282\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5506 - accuracy: 0.8284\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5512 - accuracy: 0.8278\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5507 - accuracy: 0.8278\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5510 - accuracy: 0.8284\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5503 - accuracy: 0.8280\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5510 - accuracy: 0.8282\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5497 - accuracy: 0.8280\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5504 - accuracy: 0.8279\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5499 - accuracy: 0.8279\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5503 - accuracy: 0.8288\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5493 - accuracy: 0.8284\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5494 - accuracy: 0.8288\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5486 - accuracy: 0.8282\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5498 - accuracy: 0.8281\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5492 - accuracy: 0.8285\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5491 - accuracy: 0.8289\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 22s 5ms/step - loss: 0.7494 - accuracy: 0.7701\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6609 - accuracy: 0.7998\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6491 - accuracy: 0.8029\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6418 - accuracy: 0.8052\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6380 - accuracy: 0.8059\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6316 - accuracy: 0.8072\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6265 - accuracy: 0.8089\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6221 - accuracy: 0.8102\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6205 - accuracy: 0.8118\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6166 - accuracy: 0.8120\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6138 - accuracy: 0.8136\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.6114 - accuracy: 0.8137\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6099 - accuracy: 0.8139\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6063 - accuracy: 0.8151\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6039 - accuracy: 0.8159\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6018 - accuracy: 0.8153\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5989 - accuracy: 0.8160\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5963 - accuracy: 0.8164\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5936 - accuracy: 0.8175\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5916 - accuracy: 0.8178\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5895 - accuracy: 0.8177\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5871 - accuracy: 0.8190\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5853 - accuracy: 0.8197\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5820 - accuracy: 0.8205\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5805 - accuracy: 0.8208\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5790 - accuracy: 0.8216\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5773 - accuracy: 0.8217\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5768 - accuracy: 0.8217\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5738 - accuracy: 0.8220\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5730 - accuracy: 0.8231\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5724 - accuracy: 0.8233\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5706 - accuracy: 0.8238\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5706 - accuracy: 0.8232\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5700 - accuracy: 0.8238\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5683 - accuracy: 0.8245\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5682 - accuracy: 0.8241\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5676 - accuracy: 0.8247\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5657 - accuracy: 0.8250\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5671 - accuracy: 0.8242\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5653 - accuracy: 0.8248\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5651 - accuracy: 0.8245\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5642 - accuracy: 0.8258\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5642 - accuracy: 0.8250\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5637 - accuracy: 0.8255\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5624 - accuracy: 0.8253\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5623 - accuracy: 0.8257\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5628 - accuracy: 0.8260\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5635 - accuracy: 0.8250\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5615 - accuracy: 0.8255\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5612 - accuracy: 0.8256\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5608 - accuracy: 0.8257\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5602 - accuracy: 0.8259\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5609 - accuracy: 0.8262\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5598 - accuracy: 0.8259\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5597 - accuracy: 0.8257\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5584 - accuracy: 0.8264\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5592 - accuracy: 0.8263\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5592 - accuracy: 0.8267\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5588 - accuracy: 0.8266\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5587 - accuracy: 0.8262\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5582 - accuracy: 0.8270\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5571 - accuracy: 0.8272\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5580 - accuracy: 0.8263\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5575 - accuracy: 0.8266\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5574 - accuracy: 0.8272\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5568 - accuracy: 0.8270\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5563 - accuracy: 0.8272\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5562 - accuracy: 0.8265\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5560 - accuracy: 0.8268\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5570 - accuracy: 0.8265\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5556 - accuracy: 0.8274\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5556 - accuracy: 0.8270\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5561 - accuracy: 0.8274\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5558 - accuracy: 0.8271\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5553 - accuracy: 0.8272\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5549 - accuracy: 0.8277\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5553 - accuracy: 0.8270\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5542 - accuracy: 0.8272\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5546 - accuracy: 0.8276\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5531 - accuracy: 0.8277\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5533 - accuracy: 0.8279\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5542 - accuracy: 0.8271\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5548 - accuracy: 0.8276\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5544 - accuracy: 0.8271\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5528 - accuracy: 0.8283\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5536 - accuracy: 0.8272\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5534 - accuracy: 0.8278\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5529 - accuracy: 0.8274\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5530 - accuracy: 0.8273\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5535 - accuracy: 0.8279\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5539 - accuracy: 0.8270\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5524 - accuracy: 0.8277\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5526 - accuracy: 0.8279\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5522 - accuracy: 0.8281\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5532 - accuracy: 0.8275\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5518 - accuracy: 0.8277\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5528 - accuracy: 0.8279\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5523 - accuracy: 0.8281\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5512 - accuracy: 0.8287\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5533 - accuracy: 0.8274\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 23s 6ms/step - loss: 0.7585 - accuracy: 0.7686\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6724 - accuracy: 0.7973\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6604 - accuracy: 0.8014\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6536 - accuracy: 0.8034\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6484 - accuracy: 0.8049\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6425 - accuracy: 0.8063\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6372 - accuracy: 0.8074\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6328 - accuracy: 0.8081\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6273 - accuracy: 0.8088\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6213 - accuracy: 0.8113\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6176 - accuracy: 0.8122\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6158 - accuracy: 0.8123\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6129 - accuracy: 0.8133\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6100 - accuracy: 0.8137\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6072 - accuracy: 0.8137\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6047 - accuracy: 0.8149\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6020 - accuracy: 0.8153\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5980 - accuracy: 0.8170\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5952 - accuracy: 0.8172\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5927 - accuracy: 0.8179\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5909 - accuracy: 0.8180\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5870 - accuracy: 0.8191\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5865 - accuracy: 0.8195\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5836 - accuracy: 0.8200\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5824 - accuracy: 0.8197\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5815 - accuracy: 0.8204\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5791 - accuracy: 0.8210\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5784 - accuracy: 0.8212\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5772 - accuracy: 0.8218\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5770 - accuracy: 0.8218\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5753 - accuracy: 0.8218\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5751 - accuracy: 0.8227\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5750 - accuracy: 0.8221\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5733 - accuracy: 0.8230\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5730 - accuracy: 0.8229\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5716 - accuracy: 0.8226\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5707 - accuracy: 0.8228\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5714 - accuracy: 0.8232\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5705 - accuracy: 0.8228\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.5702 - accuracy: 0.8232\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5706 - accuracy: 0.8238\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5697 - accuracy: 0.8233\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5689 - accuracy: 0.8242\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5676 - accuracy: 0.8235\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5674 - accuracy: 0.8233\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5660 - accuracy: 0.8249\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5668 - accuracy: 0.8246\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5653 - accuracy: 0.8239\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5662 - accuracy: 0.8245\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5669 - accuracy: 0.8243\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5661 - accuracy: 0.8238\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5659 - accuracy: 0.8244\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5661 - accuracy: 0.8243\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5638 - accuracy: 0.8253\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5645 - accuracy: 0.8248\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5652 - accuracy: 0.8240\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5648 - accuracy: 0.8245\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5638 - accuracy: 0.8245\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5639 - accuracy: 0.8245\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5638 - accuracy: 0.8248\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5637 - accuracy: 0.8243\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5622 - accuracy: 0.8261\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5626 - accuracy: 0.8253\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5624 - accuracy: 0.8250\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5624 - accuracy: 0.8258\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5615 - accuracy: 0.8251\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5603 - accuracy: 0.8257\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5619 - accuracy: 0.8253\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5613 - accuracy: 0.8254\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5618 - accuracy: 0.8254\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5612 - accuracy: 0.8252\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5603 - accuracy: 0.8257\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5596 - accuracy: 0.8258\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5605 - accuracy: 0.8252\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5605 - accuracy: 0.8251\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5602 - accuracy: 0.8253\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5596 - accuracy: 0.8253\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5592 - accuracy: 0.8259\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5595 - accuracy: 0.8260\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5584 - accuracy: 0.8266\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5581 - accuracy: 0.8272\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5588 - accuracy: 0.8264\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5577 - accuracy: 0.8262\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5576 - accuracy: 0.8266\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5580 - accuracy: 0.8268\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5579 - accuracy: 0.8262\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5574 - accuracy: 0.8263\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5572 - accuracy: 0.8267\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5585 - accuracy: 0.8256\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5574 - accuracy: 0.8266\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5573 - accuracy: 0.8266\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5572 - accuracy: 0.8265\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5565 - accuracy: 0.8266\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5564 - accuracy: 0.8268\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5566 - accuracy: 0.8269\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5554 - accuracy: 0.8271\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5573 - accuracy: 0.8265\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5568 - accuracy: 0.8262\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5571 - accuracy: 0.8262\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 14s 5ms/step - loss: 0.5561 - accuracy: 0.8270\n",
      "3343/3343 [==============================] - 10s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 23s 6ms/step - loss: 0.7576 - accuracy: 0.7686\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6685 - accuracy: 0.7978\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6562 - accuracy: 0.8022\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6482 - accuracy: 0.8038\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6423 - accuracy: 0.8056\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6378 - accuracy: 0.8069\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6307 - accuracy: 0.8083\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6248 - accuracy: 0.8105\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6204 - accuracy: 0.8110\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6170 - accuracy: 0.8118\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6143 - accuracy: 0.8130\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6119 - accuracy: 0.8129\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6098 - accuracy: 0.8137\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6062 - accuracy: 0.8148\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6038 - accuracy: 0.8156\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5993 - accuracy: 0.8162\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5964 - accuracy: 0.8168\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5934 - accuracy: 0.8166\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5905 - accuracy: 0.8181\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5873 - accuracy: 0.8190\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5855 - accuracy: 0.8187\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5821 - accuracy: 0.8203\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5821 - accuracy: 0.8201\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5799 - accuracy: 0.8209\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5786 - accuracy: 0.8211\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5767 - accuracy: 0.8211\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5766 - accuracy: 0.8213\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5759 - accuracy: 0.8211\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5736 - accuracy: 0.8225\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5744 - accuracy: 0.8220\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5731 - accuracy: 0.8226\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5724 - accuracy: 0.8228\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5709 - accuracy: 0.8231\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5706 - accuracy: 0.8229\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5700 - accuracy: 0.8241\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5698 - accuracy: 0.8238\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5695 - accuracy: 0.8235\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5694 - accuracy: 0.8232\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5673 - accuracy: 0.8242\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5671 - accuracy: 0.8241\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5661 - accuracy: 0.8243\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5675 - accuracy: 0.8243\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5647 - accuracy: 0.8246\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5644 - accuracy: 0.8249\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5656 - accuracy: 0.8245\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5648 - accuracy: 0.8247\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5640 - accuracy: 0.8251\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5632 - accuracy: 0.8246\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5626 - accuracy: 0.8244\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5633 - accuracy: 0.8255\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5632 - accuracy: 0.8256\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5626 - accuracy: 0.8248\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5628 - accuracy: 0.8244\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5627 - accuracy: 0.8256\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5620 - accuracy: 0.8248\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5607 - accuracy: 0.8268\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5613 - accuracy: 0.8253\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5608 - accuracy: 0.8256\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5609 - accuracy: 0.8254\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5612 - accuracy: 0.8251\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5604 - accuracy: 0.8255\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5603 - accuracy: 0.8260\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5607 - accuracy: 0.8260\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5583 - accuracy: 0.8267\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5610 - accuracy: 0.8256\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5594 - accuracy: 0.8262\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5579 - accuracy: 0.8268\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5590 - accuracy: 0.8258\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5585 - accuracy: 0.8267\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5585 - accuracy: 0.8262\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5590 - accuracy: 0.8263\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5587 - accuracy: 0.8263\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5577 - accuracy: 0.8266\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5580 - accuracy: 0.8264\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5580 - accuracy: 0.8258\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5570 - accuracy: 0.8268\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5569 - accuracy: 0.8268\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5558 - accuracy: 0.8269\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5561 - accuracy: 0.8273\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5564 - accuracy: 0.8269\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5557 - accuracy: 0.8275\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5566 - accuracy: 0.8265\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5566 - accuracy: 0.8267\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5567 - accuracy: 0.8264\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5561 - accuracy: 0.8266\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5553 - accuracy: 0.8267\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5577 - accuracy: 0.8264\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5553 - accuracy: 0.8278\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5556 - accuracy: 0.8273\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5547 - accuracy: 0.8264\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5544 - accuracy: 0.8268\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5548 - accuracy: 0.8269\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5542 - accuracy: 0.8273\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5547 - accuracy: 0.8274\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5548 - accuracy: 0.8269\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5546 - accuracy: 0.8276\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5537 - accuracy: 0.8276\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5540 - accuracy: 0.8275\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5535 - accuracy: 0.8279\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5539 - accuracy: 0.8269\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 23s 6ms/step - loss: 0.7613 - accuracy: 0.7670\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6716 - accuracy: 0.7981\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6584 - accuracy: 0.8016\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6522 - accuracy: 0.8037\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6468 - accuracy: 0.8047\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6417 - accuracy: 0.8059\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6343 - accuracy: 0.8085\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6300 - accuracy: 0.8093\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6242 - accuracy: 0.8110\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6206 - accuracy: 0.8116\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6184 - accuracy: 0.8121\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6154 - accuracy: 0.8122\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6114 - accuracy: 0.8143\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6092 - accuracy: 0.8136\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6056 - accuracy: 0.8153\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6035 - accuracy: 0.8146\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 15s 5ms/step - loss: 0.6005 - accuracy: 0.8163\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5968 - accuracy: 0.8166\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5939 - accuracy: 0.8177\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5909 - accuracy: 0.8179\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5887 - accuracy: 0.8185\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5865 - accuracy: 0.8187\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5839 - accuracy: 0.8201\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5815 - accuracy: 0.8205\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5798 - accuracy: 0.8210\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5806 - accuracy: 0.8202\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5778 - accuracy: 0.8221\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5777 - accuracy: 0.8218\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5775 - accuracy: 0.8218\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5754 - accuracy: 0.8224\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5745 - accuracy: 0.8225\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5739 - accuracy: 0.8231\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5743 - accuracy: 0.8216\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5728 - accuracy: 0.8228\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5719 - accuracy: 0.8229\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5709 - accuracy: 0.8230\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5712 - accuracy: 0.8234\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5707 - accuracy: 0.8233\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5701 - accuracy: 0.8233\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5689 - accuracy: 0.8234\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5691 - accuracy: 0.8237\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5689 - accuracy: 0.8242\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5672 - accuracy: 0.8242\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5673 - accuracy: 0.8241\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5675 - accuracy: 0.8240\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5658 - accuracy: 0.8252\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5651 - accuracy: 0.8252\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5658 - accuracy: 0.8245\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5651 - accuracy: 0.8248\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5645 - accuracy: 0.8251\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5649 - accuracy: 0.8245\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5636 - accuracy: 0.8249\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5643 - accuracy: 0.8252\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5648 - accuracy: 0.8244\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5638 - accuracy: 0.8250\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5635 - accuracy: 0.8254\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5627 - accuracy: 0.8254\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5623 - accuracy: 0.8254\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5636 - accuracy: 0.8250\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5628 - accuracy: 0.8258\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5625 - accuracy: 0.8249\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5624 - accuracy: 0.8256\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5617 - accuracy: 0.8259\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5613 - accuracy: 0.8255\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5615 - accuracy: 0.8252\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5621 - accuracy: 0.8258\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5611 - accuracy: 0.8249\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5600 - accuracy: 0.8256\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5608 - accuracy: 0.8260\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5598 - accuracy: 0.8265\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5605 - accuracy: 0.8268\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5599 - accuracy: 0.8253\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5604 - accuracy: 0.8261\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5602 - accuracy: 0.8256\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5593 - accuracy: 0.8265\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5595 - accuracy: 0.8259\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5588 - accuracy: 0.8258\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5598 - accuracy: 0.8261\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5582 - accuracy: 0.8269\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5589 - accuracy: 0.8265\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5573 - accuracy: 0.8269\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5587 - accuracy: 0.8260\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5576 - accuracy: 0.8263\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5587 - accuracy: 0.8258\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5575 - accuracy: 0.8271\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5562 - accuracy: 0.8272\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5583 - accuracy: 0.8262\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5572 - accuracy: 0.8266\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5562 - accuracy: 0.8270\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5574 - accuracy: 0.8266\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5568 - accuracy: 0.8272\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5570 - accuracy: 0.8263\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5575 - accuracy: 0.8270\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5564 - accuracy: 0.8270\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5546 - accuracy: 0.8271\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5549 - accuracy: 0.8271\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5562 - accuracy: 0.8276\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5556 - accuracy: 0.8279\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5555 - accuracy: 0.8271\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5554 - accuracy: 0.8270\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 24s 6ms/step - loss: 0.7713 - accuracy: 0.7643\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6802 - accuracy: 0.7942\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6646 - accuracy: 0.7996\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6555 - accuracy: 0.8027\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6497 - accuracy: 0.8033\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6434 - accuracy: 0.8054\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6393 - accuracy: 0.8061\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6338 - accuracy: 0.8079\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6303 - accuracy: 0.8079\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6271 - accuracy: 0.8091\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6240 - accuracy: 0.8103\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6214 - accuracy: 0.8108\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6187 - accuracy: 0.8118\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6155 - accuracy: 0.8121\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6135 - accuracy: 0.8126\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6123 - accuracy: 0.8127\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6112 - accuracy: 0.8138\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6103 - accuracy: 0.8138\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6084 - accuracy: 0.8142\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6064 - accuracy: 0.8153\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6054 - accuracy: 0.8155\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6032 - accuracy: 0.8149\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6021 - accuracy: 0.8159\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5996 - accuracy: 0.8164\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5993 - accuracy: 0.8158\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5966 - accuracy: 0.8170\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5963 - accuracy: 0.8172\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5950 - accuracy: 0.8169\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5919 - accuracy: 0.8185\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5907 - accuracy: 0.8182\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5900 - accuracy: 0.8186\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5895 - accuracy: 0.8179\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5877 - accuracy: 0.8188\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5868 - accuracy: 0.8189\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5845 - accuracy: 0.8204\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5838 - accuracy: 0.8209\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5849 - accuracy: 0.8194\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5828 - accuracy: 0.8201\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5816 - accuracy: 0.8208\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5827 - accuracy: 0.8201\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5806 - accuracy: 0.8210\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5798 - accuracy: 0.8219\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5790 - accuracy: 0.8213\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5789 - accuracy: 0.8220\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5789 - accuracy: 0.8210\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5779 - accuracy: 0.8220\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5782 - accuracy: 0.8220\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5780 - accuracy: 0.8218\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5781 - accuracy: 0.8223\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5765 - accuracy: 0.8213\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5768 - accuracy: 0.8219\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5764 - accuracy: 0.8224\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5747 - accuracy: 0.8231\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5765 - accuracy: 0.8220\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5754 - accuracy: 0.8233\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5761 - accuracy: 0.8227\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5733 - accuracy: 0.8232\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5738 - accuracy: 0.8227\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5745 - accuracy: 0.8228\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5739 - accuracy: 0.8229\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5719 - accuracy: 0.8233\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5730 - accuracy: 0.8235\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5734 - accuracy: 0.8223\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5731 - accuracy: 0.8233\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5719 - accuracy: 0.8230\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5725 - accuracy: 0.8226\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5728 - accuracy: 0.8228\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5717 - accuracy: 0.8228\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5713 - accuracy: 0.8231\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5717 - accuracy: 0.8234\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5711 - accuracy: 0.8240\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5720 - accuracy: 0.8238\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5712 - accuracy: 0.8243\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5711 - accuracy: 0.8240\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5708 - accuracy: 0.8245\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5708 - accuracy: 0.8240\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5697 - accuracy: 0.8237\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5710 - accuracy: 0.8233\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5692 - accuracy: 0.8239\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5690 - accuracy: 0.8241\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5714 - accuracy: 0.8229\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5695 - accuracy: 0.8240\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5685 - accuracy: 0.8239\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5700 - accuracy: 0.8232\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5702 - accuracy: 0.8242\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5691 - accuracy: 0.8238\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5689 - accuracy: 0.8242\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5693 - accuracy: 0.8237\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5686 - accuracy: 0.8237\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5690 - accuracy: 0.8241\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5667 - accuracy: 0.8242\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5680 - accuracy: 0.8247\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5693 - accuracy: 0.8233\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5680 - accuracy: 0.8239\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5670 - accuracy: 0.8248\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5681 - accuracy: 0.8243\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5676 - accuracy: 0.8242\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5651 - accuracy: 0.8250\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5677 - accuracy: 0.8240\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5672 - accuracy: 0.8249\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 24s 6ms/step - loss: 0.7689 - accuracy: 0.7644\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6789 - accuracy: 0.7944\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6635 - accuracy: 0.7983\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6544 - accuracy: 0.8018\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6473 - accuracy: 0.8039\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6437 - accuracy: 0.8049\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6379 - accuracy: 0.8073\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6353 - accuracy: 0.8072\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6297 - accuracy: 0.8095\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6269 - accuracy: 0.8099\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6248 - accuracy: 0.8106\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6210 - accuracy: 0.8123\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6198 - accuracy: 0.8112\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6171 - accuracy: 0.8132\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6153 - accuracy: 0.8133\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6122 - accuracy: 0.8141\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6111 - accuracy: 0.8148\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6093 - accuracy: 0.8150\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6073 - accuracy: 0.8149\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6052 - accuracy: 0.8159\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6055 - accuracy: 0.8155\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6034 - accuracy: 0.8161\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6027 - accuracy: 0.8159\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6014 - accuracy: 0.8158\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5991 - accuracy: 0.8171\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5980 - accuracy: 0.8168\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5951 - accuracy: 0.8176\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5947 - accuracy: 0.8181\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5950 - accuracy: 0.8171\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5925 - accuracy: 0.8185\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5940 - accuracy: 0.8180\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5900 - accuracy: 0.8189\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5895 - accuracy: 0.8196\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5898 - accuracy: 0.8186\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5884 - accuracy: 0.8197\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5882 - accuracy: 0.8186\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5865 - accuracy: 0.8187\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5865 - accuracy: 0.8195\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5859 - accuracy: 0.8195\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5854 - accuracy: 0.8196\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5848 - accuracy: 0.8199\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5829 - accuracy: 0.8205\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5841 - accuracy: 0.8201\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5821 - accuracy: 0.8207\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5818 - accuracy: 0.8208\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5822 - accuracy: 0.8207\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5799 - accuracy: 0.8214\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5812 - accuracy: 0.8215\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5810 - accuracy: 0.8208\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5790 - accuracy: 0.8209\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5810 - accuracy: 0.8212\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5787 - accuracy: 0.8222\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5788 - accuracy: 0.8220\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5780 - accuracy: 0.8226\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5789 - accuracy: 0.8214\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5789 - accuracy: 0.8220\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5765 - accuracy: 0.8227\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5774 - accuracy: 0.8220\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5755 - accuracy: 0.8225\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5775 - accuracy: 0.8221\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5762 - accuracy: 0.8224\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5762 - accuracy: 0.8226\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5767 - accuracy: 0.8222\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5744 - accuracy: 0.8222\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5743 - accuracy: 0.8225\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5748 - accuracy: 0.8222\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5756 - accuracy: 0.8218\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5749 - accuracy: 0.8223\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5755 - accuracy: 0.8225\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5748 - accuracy: 0.8227\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5735 - accuracy: 0.8230\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5740 - accuracy: 0.8224\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5746 - accuracy: 0.8222\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5737 - accuracy: 0.8219\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5736 - accuracy: 0.8222\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5732 - accuracy: 0.8236\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5734 - accuracy: 0.8233\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5723 - accuracy: 0.8231\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5735 - accuracy: 0.8222\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5726 - accuracy: 0.8239\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5731 - accuracy: 0.8235\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5733 - accuracy: 0.8233\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5734 - accuracy: 0.8229\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5722 - accuracy: 0.8235\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5739 - accuracy: 0.8232\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5726 - accuracy: 0.8236\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5715 - accuracy: 0.8230\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5722 - accuracy: 0.8237\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5722 - accuracy: 0.8228\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5709 - accuracy: 0.8238\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5716 - accuracy: 0.8228\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5718 - accuracy: 0.8236\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5720 - accuracy: 0.8234\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5713 - accuracy: 0.8236\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5712 - accuracy: 0.8231\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5709 - accuracy: 0.8234\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5732 - accuracy: 0.8230\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5722 - accuracy: 0.8232\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5700 - accuracy: 0.8234\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5701 - accuracy: 0.8236\n",
      "3343/3343 [==============================] - 10s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 24s 6ms/step - loss: 0.7738 - accuracy: 0.7638\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6830 - accuracy: 0.7935\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6665 - accuracy: 0.7981\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6559 - accuracy: 0.8022\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6520 - accuracy: 0.8029\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6460 - accuracy: 0.8047\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6410 - accuracy: 0.8058\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.6372 - accuracy: 0.8073\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6313 - accuracy: 0.8094\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6297 - accuracy: 0.8100\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6268 - accuracy: 0.8099\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6252 - accuracy: 0.8098\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6221 - accuracy: 0.8116\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6193 - accuracy: 0.8123\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6191 - accuracy: 0.8121\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6165 - accuracy: 0.8124\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6144 - accuracy: 0.8139\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6133 - accuracy: 0.8140\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6126 - accuracy: 0.8141\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6116 - accuracy: 0.8140\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6086 - accuracy: 0.8155\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6079 - accuracy: 0.8158\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6070 - accuracy: 0.8157\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6057 - accuracy: 0.8159\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6053 - accuracy: 0.8160\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6028 - accuracy: 0.8178\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6040 - accuracy: 0.8163\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6039 - accuracy: 0.8161\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6012 - accuracy: 0.8172\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6013 - accuracy: 0.8177\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5994 - accuracy: 0.8174\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5996 - accuracy: 0.8176\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5980 - accuracy: 0.8177\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5959 - accuracy: 0.8185\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5955 - accuracy: 0.8177\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5951 - accuracy: 0.8185\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5944 - accuracy: 0.8191\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5940 - accuracy: 0.8189\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5927 - accuracy: 0.8188\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5922 - accuracy: 0.8185\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5927 - accuracy: 0.8184\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5908 - accuracy: 0.8191\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5895 - accuracy: 0.8194\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5890 - accuracy: 0.8187\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5886 - accuracy: 0.8193\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5870 - accuracy: 0.8212\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5869 - accuracy: 0.8201\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5867 - accuracy: 0.8205\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5877 - accuracy: 0.8199\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5855 - accuracy: 0.8200\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5841 - accuracy: 0.8204\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5848 - accuracy: 0.8207\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5830 - accuracy: 0.8213\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5815 - accuracy: 0.8217\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5833 - accuracy: 0.8210\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5825 - accuracy: 0.8214\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5807 - accuracy: 0.8211\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5808 - accuracy: 0.8218\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5796 - accuracy: 0.8227\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5815 - accuracy: 0.8218\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5808 - accuracy: 0.8221\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5799 - accuracy: 0.8223\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5795 - accuracy: 0.8219\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5797 - accuracy: 0.8225\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5791 - accuracy: 0.8224\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5797 - accuracy: 0.8221\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5795 - accuracy: 0.8225\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5776 - accuracy: 0.8224\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5788 - accuracy: 0.8224\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5786 - accuracy: 0.8220\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5788 - accuracy: 0.8226\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5785 - accuracy: 0.8218\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5787 - accuracy: 0.8224\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5776 - accuracy: 0.8229\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5769 - accuracy: 0.8228\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5770 - accuracy: 0.8228\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5770 - accuracy: 0.8222\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5764 - accuracy: 0.8232\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5758 - accuracy: 0.8229\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5760 - accuracy: 0.8229\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5760 - accuracy: 0.8236\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5753 - accuracy: 0.8235\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5754 - accuracy: 0.8236\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5750 - accuracy: 0.8226\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5755 - accuracy: 0.8230\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5757 - accuracy: 0.8232\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5776 - accuracy: 0.8223\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5744 - accuracy: 0.8235\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5762 - accuracy: 0.8232\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5754 - accuracy: 0.8237\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5756 - accuracy: 0.8239\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5740 - accuracy: 0.8240\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5741 - accuracy: 0.8236\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5741 - accuracy: 0.8232\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5746 - accuracy: 0.8235\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5755 - accuracy: 0.8226\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5746 - accuracy: 0.8233\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5735 - accuracy: 0.8234\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5758 - accuracy: 0.8232\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 15s 6ms/step - loss: 0.5742 - accuracy: 0.8230\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 24s 6ms/step - loss: 0.7737 - accuracy: 0.7626\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6906 - accuracy: 0.7907\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6722 - accuracy: 0.7959\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6628 - accuracy: 0.7992\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6579 - accuracy: 0.8001\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6510 - accuracy: 0.8034\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6493 - accuracy: 0.8034\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6447 - accuracy: 0.8057\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6402 - accuracy: 0.8073\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6384 - accuracy: 0.8081\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6374 - accuracy: 0.8083\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6339 - accuracy: 0.8091\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6327 - accuracy: 0.8103\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6309 - accuracy: 0.8100\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6293 - accuracy: 0.8105\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6284 - accuracy: 0.8114\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6271 - accuracy: 0.8123\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6245 - accuracy: 0.8125\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6242 - accuracy: 0.8121\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6233 - accuracy: 0.8127\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6203 - accuracy: 0.8137\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6224 - accuracy: 0.8126\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6197 - accuracy: 0.8129\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6194 - accuracy: 0.8126\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6188 - accuracy: 0.8133\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6159 - accuracy: 0.8145\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6167 - accuracy: 0.8137\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6140 - accuracy: 0.8147\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6135 - accuracy: 0.8154\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6137 - accuracy: 0.8146\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6131 - accuracy: 0.8140\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6120 - accuracy: 0.8143\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6111 - accuracy: 0.8143\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6104 - accuracy: 0.8150\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6082 - accuracy: 0.8159\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6081 - accuracy: 0.8155\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6072 - accuracy: 0.8147\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6072 - accuracy: 0.8163\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6066 - accuracy: 0.8166\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6058 - accuracy: 0.8159\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6038 - accuracy: 0.8161\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6042 - accuracy: 0.8159\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6040 - accuracy: 0.8165\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6024 - accuracy: 0.8164\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6024 - accuracy: 0.8163\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6009 - accuracy: 0.8177\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6017 - accuracy: 0.8174\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6012 - accuracy: 0.8173\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6011 - accuracy: 0.8170\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5981 - accuracy: 0.8184\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6007 - accuracy: 0.8169\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5991 - accuracy: 0.8178\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5969 - accuracy: 0.8185\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5970 - accuracy: 0.8189\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5967 - accuracy: 0.8189\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6005 - accuracy: 0.8172\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5987 - accuracy: 0.8167\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5975 - accuracy: 0.8182\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5960 - accuracy: 0.8189\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5954 - accuracy: 0.8186\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5954 - accuracy: 0.8186\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5958 - accuracy: 0.8190\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5945 - accuracy: 0.8188\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5936 - accuracy: 0.8188\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5957 - accuracy: 0.8186\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5921 - accuracy: 0.8198\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5951 - accuracy: 0.8186\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5919 - accuracy: 0.8192\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5930 - accuracy: 0.8196\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5941 - accuracy: 0.8188\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5917 - accuracy: 0.8195\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5915 - accuracy: 0.8203\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5924 - accuracy: 0.8194\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5926 - accuracy: 0.8192\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5907 - accuracy: 0.8195\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5898 - accuracy: 0.8203\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5894 - accuracy: 0.8202\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5931 - accuracy: 0.8190\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5895 - accuracy: 0.8207\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5934 - accuracy: 0.8188\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5898 - accuracy: 0.8202\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5899 - accuracy: 0.8207\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5914 - accuracy: 0.8203\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5892 - accuracy: 0.8207\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5903 - accuracy: 0.8190\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5901 - accuracy: 0.8198\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5893 - accuracy: 0.8207\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5894 - accuracy: 0.8197\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5898 - accuracy: 0.8208\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5899 - accuracy: 0.8196\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5899 - accuracy: 0.8197\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5890 - accuracy: 0.8209\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5906 - accuracy: 0.8200\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5895 - accuracy: 0.8206\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5877 - accuracy: 0.8214\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5876 - accuracy: 0.8208\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5872 - accuracy: 0.8214\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5874 - accuracy: 0.8205\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5891 - accuracy: 0.8206\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5885 - accuracy: 0.8204\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 25s 6ms/step - loss: 0.7679 - accuracy: 0.7635\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6851 - accuracy: 0.7909\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6689 - accuracy: 0.7966\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6590 - accuracy: 0.7987\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6536 - accuracy: 0.8020\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6495 - accuracy: 0.8025\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6446 - accuracy: 0.8043\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6412 - accuracy: 0.8051\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6378 - accuracy: 0.8060\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6359 - accuracy: 0.8076\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6332 - accuracy: 0.8091\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6309 - accuracy: 0.8091\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6295 - accuracy: 0.8098\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6270 - accuracy: 0.8101\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6261 - accuracy: 0.8103\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6241 - accuracy: 0.8114\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6240 - accuracy: 0.8113\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6225 - accuracy: 0.8114\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6209 - accuracy: 0.8121\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6190 - accuracy: 0.8124\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6189 - accuracy: 0.8125\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6180 - accuracy: 0.8134\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6176 - accuracy: 0.8133\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6159 - accuracy: 0.8133\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6157 - accuracy: 0.8131\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6144 - accuracy: 0.8143\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6130 - accuracy: 0.8137\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6117 - accuracy: 0.8147\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6118 - accuracy: 0.8136\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6120 - accuracy: 0.8143\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6112 - accuracy: 0.8144\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6087 - accuracy: 0.8148\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6098 - accuracy: 0.8147\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6083 - accuracy: 0.8149\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6064 - accuracy: 0.8156\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6050 - accuracy: 0.8159\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6047 - accuracy: 0.8155\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6027 - accuracy: 0.8162\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6041 - accuracy: 0.8160\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6027 - accuracy: 0.8163\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6015 - accuracy: 0.8173\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6014 - accuracy: 0.8171\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6008 - accuracy: 0.8174\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6026 - accuracy: 0.8161\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6009 - accuracy: 0.8166\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6022 - accuracy: 0.8162\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5993 - accuracy: 0.8174\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6004 - accuracy: 0.8172\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6008 - accuracy: 0.8170\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5978 - accuracy: 0.8177\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5980 - accuracy: 0.8176\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5988 - accuracy: 0.8175\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5979 - accuracy: 0.8171\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5991 - accuracy: 0.8171\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5968 - accuracy: 0.8178\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5981 - accuracy: 0.8176\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5979 - accuracy: 0.8162\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5970 - accuracy: 0.8183\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5980 - accuracy: 0.8175\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5964 - accuracy: 0.8176\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5965 - accuracy: 0.8173\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5967 - accuracy: 0.8171\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5949 - accuracy: 0.8179\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5965 - accuracy: 0.8182\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5947 - accuracy: 0.8179\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5928 - accuracy: 0.8190\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5964 - accuracy: 0.8181\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5955 - accuracy: 0.8178\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5926 - accuracy: 0.8191\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5943 - accuracy: 0.8190\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5932 - accuracy: 0.8192\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5921 - accuracy: 0.8190\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5937 - accuracy: 0.8189\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5921 - accuracy: 0.8194\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5949 - accuracy: 0.8185\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5935 - accuracy: 0.8189\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5923 - accuracy: 0.8195\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5933 - accuracy: 0.8194\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5945 - accuracy: 0.8177\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5946 - accuracy: 0.8188\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5920 - accuracy: 0.8190\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5923 - accuracy: 0.8191\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5908 - accuracy: 0.8202\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5926 - accuracy: 0.8194\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5933 - accuracy: 0.8194\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5902 - accuracy: 0.8196\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5935 - accuracy: 0.8194\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5907 - accuracy: 0.8196\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5958 - accuracy: 0.8184\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5917 - accuracy: 0.8193\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5905 - accuracy: 0.8195\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5897 - accuracy: 0.8198\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5911 - accuracy: 0.8202\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5892 - accuracy: 0.8204\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5910 - accuracy: 0.8191\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5909 - accuracy: 0.8199\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5916 - accuracy: 0.8195\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5909 - accuracy: 0.8200\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5897 - accuracy: 0.8198\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5916 - accuracy: 0.8193\n",
      "3343/3343 [==============================] - 10s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 24s 6ms/step - loss: 0.7706 - accuracy: 0.7639\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6874 - accuracy: 0.7913\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6711 - accuracy: 0.7957\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6607 - accuracy: 0.7994\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6562 - accuracy: 0.8014\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6525 - accuracy: 0.8028\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6472 - accuracy: 0.8044\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6443 - accuracy: 0.8046\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6410 - accuracy: 0.8067\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6366 - accuracy: 0.8082\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6352 - accuracy: 0.8085\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6338 - accuracy: 0.8092\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6320 - accuracy: 0.8091\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6294 - accuracy: 0.8105\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6284 - accuracy: 0.8098\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6270 - accuracy: 0.8099\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6235 - accuracy: 0.8120\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6230 - accuracy: 0.8116\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6213 - accuracy: 0.8125\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6204 - accuracy: 0.8124\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6207 - accuracy: 0.8128\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6180 - accuracy: 0.8135\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6184 - accuracy: 0.8133\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6167 - accuracy: 0.8136\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6148 - accuracy: 0.8134\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6143 - accuracy: 0.8140\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6148 - accuracy: 0.8143\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6125 - accuracy: 0.8153\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6139 - accuracy: 0.8130\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6110 - accuracy: 0.8149\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6116 - accuracy: 0.8143\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6119 - accuracy: 0.8138\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6114 - accuracy: 0.8155\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6103 - accuracy: 0.8155\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6111 - accuracy: 0.8159\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6084 - accuracy: 0.8159\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6096 - accuracy: 0.8150\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6103 - accuracy: 0.8149\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6095 - accuracy: 0.8153\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6085 - accuracy: 0.8161\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6092 - accuracy: 0.8156\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6076 - accuracy: 0.8169\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6063 - accuracy: 0.8158\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6054 - accuracy: 0.8169\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6065 - accuracy: 0.8165\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6063 - accuracy: 0.8164\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6065 - accuracy: 0.8162\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6039 - accuracy: 0.8173\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6056 - accuracy: 0.8164\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6042 - accuracy: 0.8159\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6028 - accuracy: 0.8164\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6032 - accuracy: 0.8168\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6043 - accuracy: 0.8174\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6030 - accuracy: 0.8173\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6022 - accuracy: 0.8167\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6008 - accuracy: 0.8168\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6009 - accuracy: 0.8163\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5998 - accuracy: 0.8181\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6015 - accuracy: 0.8165\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5999 - accuracy: 0.8171\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6006 - accuracy: 0.8176\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6019 - accuracy: 0.8171\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5997 - accuracy: 0.8173\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5998 - accuracy: 0.8169\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5999 - accuracy: 0.8176\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5994 - accuracy: 0.8179\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5990 - accuracy: 0.8177\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5999 - accuracy: 0.8170\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6009 - accuracy: 0.8181\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6003 - accuracy: 0.8174\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5972 - accuracy: 0.8182\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5984 - accuracy: 0.8186\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5987 - accuracy: 0.8181\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5967 - accuracy: 0.8192\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5961 - accuracy: 0.8185\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5971 - accuracy: 0.8190\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5978 - accuracy: 0.8183\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5986 - accuracy: 0.8185\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5964 - accuracy: 0.8189\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5979 - accuracy: 0.8181\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5974 - accuracy: 0.8178\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5952 - accuracy: 0.8188\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5963 - accuracy: 0.8176\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5956 - accuracy: 0.8185\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5939 - accuracy: 0.8204\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5972 - accuracy: 0.8192\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5948 - accuracy: 0.8194\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5943 - accuracy: 0.8192\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5930 - accuracy: 0.8193\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5911 - accuracy: 0.8202\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5956 - accuracy: 0.8190\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5955 - accuracy: 0.8183\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5949 - accuracy: 0.8193\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5920 - accuracy: 0.8202\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5943 - accuracy: 0.8198\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5942 - accuracy: 0.8186\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5918 - accuracy: 0.8196\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.5948 - accuracy: 0.8190\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5972 - accuracy: 0.8181\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.5948 - accuracy: 0.8192\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 25s 6ms/step - loss: 0.7711 - accuracy: 0.7628\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6932 - accuracy: 0.7874\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6754 - accuracy: 0.7940\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6668 - accuracy: 0.7960\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6627 - accuracy: 0.7977\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6575 - accuracy: 0.8006\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6550 - accuracy: 0.8006\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6506 - accuracy: 0.8030\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6487 - accuracy: 0.8041\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6449 - accuracy: 0.8051\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6437 - accuracy: 0.8066\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6422 - accuracy: 0.8070\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6400 - accuracy: 0.8073\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6385 - accuracy: 0.8082\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6381 - accuracy: 0.8077\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6357 - accuracy: 0.8092\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6349 - accuracy: 0.8091\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6328 - accuracy: 0.8093\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6321 - accuracy: 0.8103\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6319 - accuracy: 0.8103\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6300 - accuracy: 0.8105\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6294 - accuracy: 0.8109\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6279 - accuracy: 0.8118\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6272 - accuracy: 0.8111\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6268 - accuracy: 0.8118\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6251 - accuracy: 0.8111\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6264 - accuracy: 0.8108\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6223 - accuracy: 0.8116\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6264 - accuracy: 0.8108\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6284 - accuracy: 0.8104\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6245 - accuracy: 0.8111\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6209 - accuracy: 0.8118\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6227 - accuracy: 0.8127\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.6219 - accuracy: 0.8130\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6225 - accuracy: 0.8125\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6202 - accuracy: 0.8128\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6223 - accuracy: 0.8123\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.6207 - accuracy: 0.8127\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6196 - accuracy: 0.8124\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6184 - accuracy: 0.8123\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6203 - accuracy: 0.8122\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6185 - accuracy: 0.8129\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.6194 - accuracy: 0.8112\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6169 - accuracy: 0.8120\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6163 - accuracy: 0.8138\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6174 - accuracy: 0.8126\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6148 - accuracy: 0.8135\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6149 - accuracy: 0.8139\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6136 - accuracy: 0.8145\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6128 - accuracy: 0.8138\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6160 - accuracy: 0.8143\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6147 - accuracy: 0.8139\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6154 - accuracy: 0.8138\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6155 - accuracy: 0.8146\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6137 - accuracy: 0.8138\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6152 - accuracy: 0.8135\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6125 - accuracy: 0.8139\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6147 - accuracy: 0.8137\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6139 - accuracy: 0.8142\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6131 - accuracy: 0.8134\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6149 - accuracy: 0.8135\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6110 - accuracy: 0.8152\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6138 - accuracy: 0.8143\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6114 - accuracy: 0.8154\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6121 - accuracy: 0.8146\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6111 - accuracy: 0.8144\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.6126 - accuracy: 0.8140\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6104 - accuracy: 0.8144\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6113 - accuracy: 0.8149\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6116 - accuracy: 0.8141\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6123 - accuracy: 0.8141\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6092 - accuracy: 0.8154\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6124 - accuracy: 0.8140\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6100 - accuracy: 0.8151\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6078 - accuracy: 0.8163\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6105 - accuracy: 0.8154\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6117 - accuracy: 0.8147\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6098 - accuracy: 0.8159\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6117 - accuracy: 0.8146\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6120 - accuracy: 0.8146\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6105 - accuracy: 0.8143\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6082 - accuracy: 0.8151\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6113 - accuracy: 0.8146\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6067 - accuracy: 0.8164\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6101 - accuracy: 0.8154\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6100 - accuracy: 0.8146\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6105 - accuracy: 0.8140\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6096 - accuracy: 0.8148\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6079 - accuracy: 0.8159\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6086 - accuracy: 0.8153\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6093 - accuracy: 0.8149\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6084 - accuracy: 0.8158\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6087 - accuracy: 0.8158\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6109 - accuracy: 0.8152\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6091 - accuracy: 0.8147\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6101 - accuracy: 0.8150\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6102 - accuracy: 0.8161\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6105 - accuracy: 0.8160\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6108 - accuracy: 0.8159\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6114 - accuracy: 0.8152\n",
      "3343/3343 [==============================] - 10s 3ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 25s 6ms/step - loss: 0.7687 - accuracy: 0.7635\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6916 - accuracy: 0.7889\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6742 - accuracy: 0.7936\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6646 - accuracy: 0.7975\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6587 - accuracy: 0.7990\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6546 - accuracy: 0.8006\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6511 - accuracy: 0.8027\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6483 - accuracy: 0.8035\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6441 - accuracy: 0.8056\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6428 - accuracy: 0.8054\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6416 - accuracy: 0.8060\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6389 - accuracy: 0.8076\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6368 - accuracy: 0.8081\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6371 - accuracy: 0.8077\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6350 - accuracy: 0.8088\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6350 - accuracy: 0.8090\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6338 - accuracy: 0.8087\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6315 - accuracy: 0.8094\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6318 - accuracy: 0.8094\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6306 - accuracy: 0.8101\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6309 - accuracy: 0.8098\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6287 - accuracy: 0.8108\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6274 - accuracy: 0.8106\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6270 - accuracy: 0.8109\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6265 - accuracy: 0.8109\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6272 - accuracy: 0.8105\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6239 - accuracy: 0.8118\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6254 - accuracy: 0.8112\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6242 - accuracy: 0.8116\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6229 - accuracy: 0.8123\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6238 - accuracy: 0.8118\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6239 - accuracy: 0.8112\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6229 - accuracy: 0.8117\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6217 - accuracy: 0.8122\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6242 - accuracy: 0.8118\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6222 - accuracy: 0.8121\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6229 - accuracy: 0.8123\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6193 - accuracy: 0.8123\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6206 - accuracy: 0.8123\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6205 - accuracy: 0.8120\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.6203 - accuracy: 0.8123\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6172 - accuracy: 0.8131\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6203 - accuracy: 0.8126\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6173 - accuracy: 0.8134\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6195 - accuracy: 0.8126\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6176 - accuracy: 0.8142\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6200 - accuracy: 0.8128\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6176 - accuracy: 0.8129\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6180 - accuracy: 0.8128\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6164 - accuracy: 0.8139\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6246 - accuracy: 0.8117\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6179 - accuracy: 0.8138\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6208 - accuracy: 0.8130\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6189 - accuracy: 0.8127\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6162 - accuracy: 0.8134\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6169 - accuracy: 0.8126\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6169 - accuracy: 0.8139\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6201 - accuracy: 0.8131\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6162 - accuracy: 0.8139\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6170 - accuracy: 0.8127\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6183 - accuracy: 0.8132\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6173 - accuracy: 0.8132\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6148 - accuracy: 0.8129\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6175 - accuracy: 0.8130\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6157 - accuracy: 0.8139\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6142 - accuracy: 0.8140\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6154 - accuracy: 0.8140\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6151 - accuracy: 0.8137\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6121 - accuracy: 0.8149\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6193 - accuracy: 0.8132\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6146 - accuracy: 0.8137\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6136 - accuracy: 0.8152\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6145 - accuracy: 0.8131\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6138 - accuracy: 0.8141\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6133 - accuracy: 0.8144\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6123 - accuracy: 0.8141\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6103 - accuracy: 0.8151\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6124 - accuracy: 0.8144\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6119 - accuracy: 0.8146\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6137 - accuracy: 0.8140\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.6139 - accuracy: 0.8134\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6152 - accuracy: 0.8142\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6132 - accuracy: 0.8141\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6129 - accuracy: 0.8147\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6101 - accuracy: 0.8154\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.6147 - accuracy: 0.8138\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6132 - accuracy: 0.8142\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6124 - accuracy: 0.8136\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6109 - accuracy: 0.8150\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6101 - accuracy: 0.8137\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6120 - accuracy: 0.8134\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6114 - accuracy: 0.8139\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6185 - accuracy: 0.8133\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6114 - accuracy: 0.8147\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6118 - accuracy: 0.8149\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.6106 - accuracy: 0.8149\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6115 - accuracy: 0.8143\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6144 - accuracy: 0.8133\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.6124 - accuracy: 0.8137\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6188 - accuracy: 0.8128\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 25s 6ms/step - loss: 0.7717 - accuracy: 0.7637\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6917 - accuracy: 0.7892\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6761 - accuracy: 0.7929\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6671 - accuracy: 0.7962\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6601 - accuracy: 0.7984\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6555 - accuracy: 0.8008\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6540 - accuracy: 0.8015\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6502 - accuracy: 0.8035\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6449 - accuracy: 0.8054\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6421 - accuracy: 0.8067\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6403 - accuracy: 0.8073\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6404 - accuracy: 0.8069\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6390 - accuracy: 0.8071\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6363 - accuracy: 0.8091\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6353 - accuracy: 0.8097\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6348 - accuracy: 0.8090\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6343 - accuracy: 0.8087\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6320 - accuracy: 0.8099\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6314 - accuracy: 0.8105\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6309 - accuracy: 0.8100\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6292 - accuracy: 0.8100\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6274 - accuracy: 0.8109\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6307 - accuracy: 0.8092\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6268 - accuracy: 0.8109\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6254 - accuracy: 0.8122\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6285 - accuracy: 0.8096\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6258 - accuracy: 0.8104\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6252 - accuracy: 0.8112\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6267 - accuracy: 0.8107\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6244 - accuracy: 0.8114\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6234 - accuracy: 0.8122\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6208 - accuracy: 0.8120\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6224 - accuracy: 0.8117\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6204 - accuracy: 0.8133\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6206 - accuracy: 0.8132\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6207 - accuracy: 0.8134\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6197 - accuracy: 0.8121\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6217 - accuracy: 0.8132\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6195 - accuracy: 0.8131\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6196 - accuracy: 0.8126\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6162 - accuracy: 0.8137\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6187 - accuracy: 0.8133\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6166 - accuracy: 0.8138\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6170 - accuracy: 0.8134\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6160 - accuracy: 0.8140\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6156 - accuracy: 0.8139\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6152 - accuracy: 0.8142\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6187 - accuracy: 0.8137\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 16s 6ms/step - loss: 0.6158 - accuracy: 0.8143\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6167 - accuracy: 0.8142\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6171 - accuracy: 0.8139\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6146 - accuracy: 0.8149\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6159 - accuracy: 0.8143\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6169 - accuracy: 0.8137\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6148 - accuracy: 0.8142\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6144 - accuracy: 0.8130\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6117 - accuracy: 0.8152\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6127 - accuracy: 0.8140\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6132 - accuracy: 0.8146\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6129 - accuracy: 0.8145\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6133 - accuracy: 0.8145\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6119 - accuracy: 0.8154\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6106 - accuracy: 0.8154\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6125 - accuracy: 0.8146\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6122 - accuracy: 0.8142\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6134 - accuracy: 0.8143\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6139 - accuracy: 0.8147\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6110 - accuracy: 0.8147\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6157 - accuracy: 0.8127\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6131 - accuracy: 0.8144\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6146 - accuracy: 0.8149\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6152 - accuracy: 0.8141\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6111 - accuracy: 0.8149\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6126 - accuracy: 0.8139\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6114 - accuracy: 0.8144\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6100 - accuracy: 0.8149\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6128 - accuracy: 0.8144\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6121 - accuracy: 0.8148\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6096 - accuracy: 0.8157\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6104 - accuracy: 0.8157\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6094 - accuracy: 0.8164\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6114 - accuracy: 0.8153\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6087 - accuracy: 0.8167\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6103 - accuracy: 0.8151\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6114 - accuracy: 0.8150\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6106 - accuracy: 0.8155\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6109 - accuracy: 0.8156\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6133 - accuracy: 0.8153\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6098 - accuracy: 0.8160\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6124 - accuracy: 0.8145\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6090 - accuracy: 0.8172\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6119 - accuracy: 0.8162\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6117 - accuracy: 0.8149\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6145 - accuracy: 0.8136\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6108 - accuracy: 0.8150\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6108 - accuracy: 0.8159\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6099 - accuracy: 0.8156\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6165 - accuracy: 0.8145\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6093 - accuracy: 0.8168\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6113 - accuracy: 0.8152\n",
      "3343/3343 [==============================] - 10s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 25s 6ms/step - loss: 0.7774 - accuracy: 0.7602\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6948 - accuracy: 0.7871\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6779 - accuracy: 0.7933\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6707 - accuracy: 0.7946\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6639 - accuracy: 0.7968\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6596 - accuracy: 0.7992\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6580 - accuracy: 0.7999\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6540 - accuracy: 0.8016\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6518 - accuracy: 0.8022\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6487 - accuracy: 0.8036\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6471 - accuracy: 0.8050\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6471 - accuracy: 0.8042\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6447 - accuracy: 0.8057\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6414 - accuracy: 0.8078\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6419 - accuracy: 0.8070\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6403 - accuracy: 0.8076\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6402 - accuracy: 0.8072\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6389 - accuracy: 0.8072\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6381 - accuracy: 0.8074\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6367 - accuracy: 0.8095\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6353 - accuracy: 0.8090\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6363 - accuracy: 0.8086\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6353 - accuracy: 0.8094\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6361 - accuracy: 0.8081\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6370 - accuracy: 0.8087\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6326 - accuracy: 0.8093\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6346 - accuracy: 0.8088\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6351 - accuracy: 0.8071\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6364 - accuracy: 0.8078\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6340 - accuracy: 0.8089\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6328 - accuracy: 0.8086\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6323 - accuracy: 0.8093\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6331 - accuracy: 0.8100\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6349 - accuracy: 0.8084\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6327 - accuracy: 0.8093\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6338 - accuracy: 0.8080\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6301 - accuracy: 0.8099\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6418 - accuracy: 0.8064\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6299 - accuracy: 0.8106\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6296 - accuracy: 0.8099\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6353 - accuracy: 0.8083\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6296 - accuracy: 0.8097\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6315 - accuracy: 0.8094\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6278 - accuracy: 0.8110\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6298 - accuracy: 0.8095\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6282 - accuracy: 0.8109\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6293 - accuracy: 0.8105\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6310 - accuracy: 0.8110\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6333 - accuracy: 0.8102\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6313 - accuracy: 0.8096\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6314 - accuracy: 0.8096\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6407 - accuracy: 0.8070\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6321 - accuracy: 0.8100\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6325 - accuracy: 0.8100\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6311 - accuracy: 0.8107\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6308 - accuracy: 0.8103\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6315 - accuracy: 0.8105\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6304 - accuracy: 0.8106\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6322 - accuracy: 0.8104\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6322 - accuracy: 0.8103\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6412 - accuracy: 0.8070\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6367 - accuracy: 0.8083\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6321 - accuracy: 0.8097\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6336 - accuracy: 0.8091\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6287 - accuracy: 0.8111\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6336 - accuracy: 0.8098\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6319 - accuracy: 0.8094\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6386 - accuracy: 0.8069\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6301 - accuracy: 0.8115\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6267 - accuracy: 0.8112\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6319 - accuracy: 0.8108\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6308 - accuracy: 0.8099\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6335 - accuracy: 0.8098\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6352 - accuracy: 0.8102\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6323 - accuracy: 0.8108\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6347 - accuracy: 0.8095\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6353 - accuracy: 0.8102\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6358 - accuracy: 0.8102\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6309 - accuracy: 0.8104\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6363 - accuracy: 0.8087\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6340 - accuracy: 0.8094\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6284 - accuracy: 0.8113\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6246 - accuracy: 0.8117\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6296 - accuracy: 0.8117\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6358 - accuracy: 0.8093\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6312 - accuracy: 0.8095\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6328 - accuracy: 0.8093\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6339 - accuracy: 0.8097\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6299 - accuracy: 0.8101\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6315 - accuracy: 0.8107\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6375 - accuracy: 0.8095\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6334 - accuracy: 0.8084\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6342 - accuracy: 0.8088\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6386 - accuracy: 0.8080\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6352 - accuracy: 0.8089\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6340 - accuracy: 0.8098\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6313 - accuracy: 0.8108\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6305 - accuracy: 0.8116\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6359 - accuracy: 0.8095\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6352 - accuracy: 0.8092\n",
      "3343/3343 [==============================] - 10s 2ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 26s 7ms/step - loss: 0.7723 - accuracy: 0.7622\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6913 - accuracy: 0.7880\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6770 - accuracy: 0.7917\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6655 - accuracy: 0.7965\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6603 - accuracy: 0.7982\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6579 - accuracy: 0.8003\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6544 - accuracy: 0.8014\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6515 - accuracy: 0.8017\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6500 - accuracy: 0.8022\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6467 - accuracy: 0.8049\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6454 - accuracy: 0.8045\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6427 - accuracy: 0.8053\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6435 - accuracy: 0.8064\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6393 - accuracy: 0.8071\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6424 - accuracy: 0.8058\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6385 - accuracy: 0.8067\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6387 - accuracy: 0.8071\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6376 - accuracy: 0.8074\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6355 - accuracy: 0.8076\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6356 - accuracy: 0.8080\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6355 - accuracy: 0.8092\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6357 - accuracy: 0.8088\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6330 - accuracy: 0.8088\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6370 - accuracy: 0.8082\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6316 - accuracy: 0.8087\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6304 - accuracy: 0.8097\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6319 - accuracy: 0.8083\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6308 - accuracy: 0.8095\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6325 - accuracy: 0.8087\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6283 - accuracy: 0.8108\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6314 - accuracy: 0.8091\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6306 - accuracy: 0.8088\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6309 - accuracy: 0.8096\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6327 - accuracy: 0.8083\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6287 - accuracy: 0.8095\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6332 - accuracy: 0.8092\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6292 - accuracy: 0.8101\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6575 - accuracy: 0.7987\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6375 - accuracy: 0.8060\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6351 - accuracy: 0.8080\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6314 - accuracy: 0.8084\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6331 - accuracy: 0.8085\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6305 - accuracy: 0.8097\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6291 - accuracy: 0.8102\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6322 - accuracy: 0.8073\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6315 - accuracy: 0.8084\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6307 - accuracy: 0.8080\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 17s 7ms/step - loss: 0.6345 - accuracy: 0.8075\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6303 - accuracy: 0.8097\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6293 - accuracy: 0.8092\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6263 - accuracy: 0.8099\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6304 - accuracy: 0.8098\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6293 - accuracy: 0.8093\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6267 - accuracy: 0.8104\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6302 - accuracy: 0.8091\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6292 - accuracy: 0.8106\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6267 - accuracy: 0.8103\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6300 - accuracy: 0.8093\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6286 - accuracy: 0.8101\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6304 - accuracy: 0.8101\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6333 - accuracy: 0.8101\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6302 - accuracy: 0.8105\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6273 - accuracy: 0.8102\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6236 - accuracy: 0.8110\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6254 - accuracy: 0.8105\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6245 - accuracy: 0.8116\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6297 - accuracy: 0.8085\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6283 - accuracy: 0.8102\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6239 - accuracy: 0.8116\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6248 - accuracy: 0.8101\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6281 - accuracy: 0.8103\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6276 - accuracy: 0.8108\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6270 - accuracy: 0.8102\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6288 - accuracy: 0.8099\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6227 - accuracy: 0.8107\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6244 - accuracy: 0.8114\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6258 - accuracy: 0.8110\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6262 - accuracy: 0.8108\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6268 - accuracy: 0.8099\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6270 - accuracy: 0.8102\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6263 - accuracy: 0.8108\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6248 - accuracy: 0.8111\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6334 - accuracy: 0.8094\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6263 - accuracy: 0.8119\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6243 - accuracy: 0.8124\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6286 - accuracy: 0.8110\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6244 - accuracy: 0.8124\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6254 - accuracy: 0.8107\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6316 - accuracy: 0.8107\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6256 - accuracy: 0.8105\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6255 - accuracy: 0.8109\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6349 - accuracy: 0.8096\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6292 - accuracy: 0.8095\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6413 - accuracy: 0.8041\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6382 - accuracy: 0.8090\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6366 - accuracy: 0.8101\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6285 - accuracy: 0.8121\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6267 - accuracy: 0.8107\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6343 - accuracy: 0.8106\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6300 - accuracy: 0.8104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 10s 3ms/step\n",
      "Epoch 1/100\n",
      "2675/2675 [==============================] - 26s 7ms/step - loss: 0.7730 - accuracy: 0.7602\n",
      "Epoch 2/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6964 - accuracy: 0.7865\n",
      "Epoch 3/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6789 - accuracy: 0.7920\n",
      "Epoch 4/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6705 - accuracy: 0.7952\n",
      "Epoch 5/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6639 - accuracy: 0.7971\n",
      "Epoch 6/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6604 - accuracy: 0.7986\n",
      "Epoch 7/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6555 - accuracy: 0.8008\n",
      "Epoch 8/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6532 - accuracy: 0.8012\n",
      "Epoch 9/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6518 - accuracy: 0.8024\n",
      "Epoch 10/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6485 - accuracy: 0.8042\n",
      "Epoch 11/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6460 - accuracy: 0.8052\n",
      "Epoch 12/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6463 - accuracy: 0.8057\n",
      "Epoch 13/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6425 - accuracy: 0.8069\n",
      "Epoch 14/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6428 - accuracy: 0.8058\n",
      "Epoch 15/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6405 - accuracy: 0.8075\n",
      "Epoch 16/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6404 - accuracy: 0.8076\n",
      "Epoch 17/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6435 - accuracy: 0.8060\n",
      "Epoch 18/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6389 - accuracy: 0.8082\n",
      "Epoch 19/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6387 - accuracy: 0.8082\n",
      "Epoch 20/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6380 - accuracy: 0.8079\n",
      "Epoch 21/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6381 - accuracy: 0.8078\n",
      "Epoch 22/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6427 - accuracy: 0.8069\n",
      "Epoch 23/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6357 - accuracy: 0.8098\n",
      "Epoch 24/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6389 - accuracy: 0.8079\n",
      "Epoch 25/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6356 - accuracy: 0.8095\n",
      "Epoch 26/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6378 - accuracy: 0.8081\n",
      "Epoch 27/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6361 - accuracy: 0.8086\n",
      "Epoch 28/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6369 - accuracy: 0.8087\n",
      "Epoch 29/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6363 - accuracy: 0.8084\n",
      "Epoch 30/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6342 - accuracy: 0.8091\n",
      "Epoch 31/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6319 - accuracy: 0.8104\n",
      "Epoch 32/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6342 - accuracy: 0.8085\n",
      "Epoch 33/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6333 - accuracy: 0.8088\n",
      "Epoch 34/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6322 - accuracy: 0.8087\n",
      "Epoch 35/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6379 - accuracy: 0.8076\n",
      "Epoch 36/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6322 - accuracy: 0.8103\n",
      "Epoch 37/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6340 - accuracy: 0.8095\n",
      "Epoch 38/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6353 - accuracy: 0.8096\n",
      "Epoch 39/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6324 - accuracy: 0.8100\n",
      "Epoch 40/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6421 - accuracy: 0.8065\n",
      "Epoch 41/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6367 - accuracy: 0.8087\n",
      "Epoch 42/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6320 - accuracy: 0.8109\n",
      "Epoch 43/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6371 - accuracy: 0.8088\n",
      "Epoch 44/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6333 - accuracy: 0.8090\n",
      "Epoch 45/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6366 - accuracy: 0.8088\n",
      "Epoch 46/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6371 - accuracy: 0.8089\n",
      "Epoch 47/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6387 - accuracy: 0.8080\n",
      "Epoch 48/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6342 - accuracy: 0.8088\n",
      "Epoch 49/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6336 - accuracy: 0.8084\n",
      "Epoch 50/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6332 - accuracy: 0.8105\n",
      "Epoch 51/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6312 - accuracy: 0.8102\n",
      "Epoch 52/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6398 - accuracy: 0.8095\n",
      "Epoch 53/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6428 - accuracy: 0.8093\n",
      "Epoch 54/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6365 - accuracy: 0.8083\n",
      "Epoch 55/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6350 - accuracy: 0.8099\n",
      "Epoch 56/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6374 - accuracy: 0.8083\n",
      "Epoch 57/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6364 - accuracy: 0.8098\n",
      "Epoch 58/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6344 - accuracy: 0.8088\n",
      "Epoch 59/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6423 - accuracy: 0.8075\n",
      "Epoch 60/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6387 - accuracy: 0.8103\n",
      "Epoch 61/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6375 - accuracy: 0.8087\n",
      "Epoch 62/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6324 - accuracy: 0.8090\n",
      "Epoch 63/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6387 - accuracy: 0.8095\n",
      "Epoch 64/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6344 - accuracy: 0.8105\n",
      "Epoch 65/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6347 - accuracy: 0.8097\n",
      "Epoch 66/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6369 - accuracy: 0.8101\n",
      "Epoch 67/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6415 - accuracy: 0.8080\n",
      "Epoch 68/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6429 - accuracy: 0.8075\n",
      "Epoch 69/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6448 - accuracy: 0.8060\n",
      "Epoch 70/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6398 - accuracy: 0.8075\n",
      "Epoch 71/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6364 - accuracy: 0.8073\n",
      "Epoch 72/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6343 - accuracy: 0.8089\n",
      "Epoch 73/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6381 - accuracy: 0.8087\n",
      "Epoch 74/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6350 - accuracy: 0.8093\n",
      "Epoch 75/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6355 - accuracy: 0.8095\n",
      "Epoch 76/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6314 - accuracy: 0.8097\n",
      "Epoch 77/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6342 - accuracy: 0.8098\n",
      "Epoch 78/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6370 - accuracy: 0.8084\n",
      "Epoch 79/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6444 - accuracy: 0.8078\n",
      "Epoch 80/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6456 - accuracy: 0.8038\n",
      "Epoch 81/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6594 - accuracy: 0.7986\n",
      "Epoch 82/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6397 - accuracy: 0.8078\n",
      "Epoch 83/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6382 - accuracy: 0.8067\n",
      "Epoch 84/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6322 - accuracy: 0.8100\n",
      "Epoch 85/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6361 - accuracy: 0.8085\n",
      "Epoch 86/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6320 - accuracy: 0.8097\n",
      "Epoch 87/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6390 - accuracy: 0.8072\n",
      "Epoch 88/100\n",
      "2675/2675 [==============================] - 19s 7ms/step - loss: 0.6409 - accuracy: 0.8080\n",
      "Epoch 89/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6350 - accuracy: 0.8085\n",
      "Epoch 90/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6359 - accuracy: 0.8083\n",
      "Epoch 91/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6335 - accuracy: 0.8088\n",
      "Epoch 92/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6333 - accuracy: 0.8090\n",
      "Epoch 93/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6365 - accuracy: 0.8086\n",
      "Epoch 94/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6353 - accuracy: 0.8103\n",
      "Epoch 95/100\n",
      "2675/2675 [==============================] - 17s 6ms/step - loss: 0.6385 - accuracy: 0.8088\n",
      "Epoch 96/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6353 - accuracy: 0.8092\n",
      "Epoch 97/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6353 - accuracy: 0.8079\n",
      "Epoch 98/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6464 - accuracy: 0.8066\n",
      "Epoch 99/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6377 - accuracy: 0.8078\n",
      "Epoch 100/100\n",
      "2675/2675 [==============================] - 18s 7ms/step - loss: 0.6432 - accuracy: 0.8056\n",
      "3343/3343 [==============================] - 10s 3ms/step\n",
      "Epoch 1/100\n",
      "4012/4012 [==============================] - 29s 5ms/step - loss: 0.7216 - accuracy: 0.7803\n",
      "Epoch 2/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6519 - accuracy: 0.8023\n",
      "Epoch 3/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6416 - accuracy: 0.8054\n",
      "Epoch 4/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6333 - accuracy: 0.8073\n",
      "Epoch 5/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6261 - accuracy: 0.8099\n",
      "Epoch 6/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6199 - accuracy: 0.8119\n",
      "Epoch 7/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6157 - accuracy: 0.8133\n",
      "Epoch 8/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6117 - accuracy: 0.8135\n",
      "Epoch 9/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6086 - accuracy: 0.8145\n",
      "Epoch 10/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6037 - accuracy: 0.8157\n",
      "Epoch 11/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.6019 - accuracy: 0.8158\n",
      "Epoch 12/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5988 - accuracy: 0.8170\n",
      "Epoch 13/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5962 - accuracy: 0.8170\n",
      "Epoch 14/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5919 - accuracy: 0.8182\n",
      "Epoch 15/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5900 - accuracy: 0.8181\n",
      "Epoch 16/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5858 - accuracy: 0.8193\n",
      "Epoch 17/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5830 - accuracy: 0.8201\n",
      "Epoch 18/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5804 - accuracy: 0.8209\n",
      "Epoch 19/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5790 - accuracy: 0.8211\n",
      "Epoch 20/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5776 - accuracy: 0.8214\n",
      "Epoch 21/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5761 - accuracy: 0.8221\n",
      "Epoch 22/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5739 - accuracy: 0.8225\n",
      "Epoch 23/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5720 - accuracy: 0.8234\n",
      "Epoch 24/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5714 - accuracy: 0.8231\n",
      "Epoch 25/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5698 - accuracy: 0.8233\n",
      "Epoch 26/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5685 - accuracy: 0.8242\n",
      "Epoch 27/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5673 - accuracy: 0.8244\n",
      "Epoch 28/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5667 - accuracy: 0.8243\n",
      "Epoch 29/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5651 - accuracy: 0.8246\n",
      "Epoch 30/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5647 - accuracy: 0.8250\n",
      "Epoch 31/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5635 - accuracy: 0.8242\n",
      "Epoch 32/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5641 - accuracy: 0.8250\n",
      "Epoch 33/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5618 - accuracy: 0.8251\n",
      "Epoch 34/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5624 - accuracy: 0.8255\n",
      "Epoch 35/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5611 - accuracy: 0.8262\n",
      "Epoch 36/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5604 - accuracy: 0.8258\n",
      "Epoch 37/100\n",
      "4012/4012 [==============================] - 21s 5ms/step - loss: 0.5613 - accuracy: 0.8253\n",
      "Epoch 38/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5596 - accuracy: 0.8260\n",
      "Epoch 39/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5604 - accuracy: 0.8263\n",
      "Epoch 40/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5585 - accuracy: 0.8262\n",
      "Epoch 41/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5594 - accuracy: 0.8258\n",
      "Epoch 42/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5590 - accuracy: 0.8257\n",
      "Epoch 43/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5586 - accuracy: 0.8262\n",
      "Epoch 44/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5582 - accuracy: 0.8264\n",
      "Epoch 45/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5580 - accuracy: 0.8265\n",
      "Epoch 46/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5573 - accuracy: 0.8270\n",
      "Epoch 47/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5567 - accuracy: 0.8268\n",
      "Epoch 48/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5568 - accuracy: 0.8272\n",
      "Epoch 49/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5578 - accuracy: 0.8266\n",
      "Epoch 50/100\n",
      "4012/4012 [==============================] - 22s 6ms/step - loss: 0.5561 - accuracy: 0.8268\n",
      "Epoch 51/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5560 - accuracy: 0.8267\n",
      "Epoch 52/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5553 - accuracy: 0.8267\n",
      "Epoch 53/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5552 - accuracy: 0.8276\n",
      "Epoch 54/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5558 - accuracy: 0.8266\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5547 - accuracy: 0.8275\n",
      "Epoch 56/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5548 - accuracy: 0.8270\n",
      "Epoch 57/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5532 - accuracy: 0.8278\n",
      "Epoch 58/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5533 - accuracy: 0.8280\n",
      "Epoch 59/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5546 - accuracy: 0.8273\n",
      "Epoch 60/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5539 - accuracy: 0.8280\n",
      "Epoch 61/100\n",
      "4012/4012 [==============================] - 22s 6ms/step - loss: 0.5536 - accuracy: 0.8273\n",
      "Epoch 62/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5541 - accuracy: 0.8272\n",
      "Epoch 63/100\n",
      "4012/4012 [==============================] - 22s 6ms/step - loss: 0.5542 - accuracy: 0.8269\n",
      "Epoch 64/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5534 - accuracy: 0.8274\n",
      "Epoch 65/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5535 - accuracy: 0.8274\n",
      "Epoch 66/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5531 - accuracy: 0.8278\n",
      "Epoch 67/100\n",
      "4012/4012 [==============================] - 22s 6ms/step - loss: 0.5531 - accuracy: 0.8276\n",
      "Epoch 68/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5519 - accuracy: 0.8278\n",
      "Epoch 69/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5522 - accuracy: 0.8274\n",
      "Epoch 70/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5525 - accuracy: 0.8272\n",
      "Epoch 71/100\n",
      "4012/4012 [==============================] - 22s 6ms/step - loss: 0.5525 - accuracy: 0.8274\n",
      "Epoch 72/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5523 - accuracy: 0.8278\n",
      "Epoch 73/100\n",
      "4012/4012 [==============================] - 22s 6ms/step - loss: 0.5523 - accuracy: 0.8278\n",
      "Epoch 74/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5519 - accuracy: 0.8276\n",
      "Epoch 75/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5519 - accuracy: 0.8275\n",
      "Epoch 76/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5509 - accuracy: 0.8283\n",
      "Epoch 77/100\n",
      "4012/4012 [==============================] - 22s 6ms/step - loss: 0.5520 - accuracy: 0.8284\n",
      "Epoch 78/100\n",
      "4012/4012 [==============================] - 21s 5ms/step - loss: 0.5509 - accuracy: 0.8281\n",
      "Epoch 79/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5506 - accuracy: 0.8280\n",
      "Epoch 80/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5506 - accuracy: 0.8285\n",
      "Epoch 81/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5514 - accuracy: 0.8279\n",
      "Epoch 82/100\n",
      "4012/4012 [==============================] - 22s 6ms/step - loss: 0.5508 - accuracy: 0.8285\n",
      "Epoch 83/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5501 - accuracy: 0.8286\n",
      "Epoch 84/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5510 - accuracy: 0.8282\n",
      "Epoch 85/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5506 - accuracy: 0.8284\n",
      "Epoch 86/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5498 - accuracy: 0.8281\n",
      "Epoch 87/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5500 - accuracy: 0.8287\n",
      "Epoch 88/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5499 - accuracy: 0.8281\n",
      "Epoch 89/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5502 - accuracy: 0.8281\n",
      "Epoch 90/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5493 - accuracy: 0.8286\n",
      "Epoch 91/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5500 - accuracy: 0.8286\n",
      "Epoch 92/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5493 - accuracy: 0.8286\n",
      "Epoch 93/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5487 - accuracy: 0.8288\n",
      "Epoch 94/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5501 - accuracy: 0.8284\n",
      "Epoch 95/100\n",
      "4012/4012 [==============================] - 22s 6ms/step - loss: 0.5488 - accuracy: 0.8291\n",
      "Epoch 96/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5489 - accuracy: 0.8291\n",
      "Epoch 97/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5483 - accuracy: 0.8288\n",
      "Epoch 98/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5489 - accuracy: 0.8293\n",
      "Epoch 99/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5485 - accuracy: 0.8282\n",
      "Epoch 100/100\n",
      "4012/4012 [==============================] - 22s 5ms/step - loss: 0.5481 - accuracy: 0.8288\n",
      "Best Results with Grid Search:\n",
      "0.8324529830629958\n",
      "{'No_Of_layers': 0}\n"
     ]
    }
   ],
   "source": [
    "#Layers Tuning for Dense Layer\n",
    "\n",
    "def create_model(No_Of_layers):\n",
    "    model = Sequential()\n",
    "    # Add an input layer\n",
    "    model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='tanh'))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=90, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=90, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=90, input_shape=(1, 11), activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    for i in range(No_Of_layers):\n",
    "        model.add(Dense(units=90, activation='tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "    # Add an output layer \n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    #compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1, epochs = 100, batch_size = 80)\n",
    "\n",
    "parameters = {\n",
    "    #'unit': [95],\n",
    "    'No_Of_layers': [0,1,2,3,4,5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_L, y_train_L)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef1a7d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xaxis_layers = [0,1,2,3,4,5]\n",
    "plt.plot(xaxis_layers,means,'.-')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Dense Layers')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"Figures/No.OfLayers_Dense(ConvLSTM).png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perceptron Tuning for Dense Layer\n",
    "\n",
    "def create_model(unit):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=60, input_shape=(1, 11), return_sequences = True, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=60, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0, epochs = 35, batch_size = 64)\n",
    "\n",
    "parameters = {\n",
    "    'unit': [10,20,30,40,50,60,70,80,90,100],\n",
    "    #'activation': ['relu','tanh'], \n",
    "    #'solver': ['adam','sgd'], \n",
    "    #'last_act': ['sigmoid','softmax'],\n",
    "    #'epochs': [70,100],\n",
    "    #'batch_size': [5,10] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_L, y_train_L)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1c023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis_perceptrons = [10,20,30,40,50,60,70,80,90,100]\n",
    "plt.plot(xaxis_perceptrons,means,'.-')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Perceptrons in Dense layer')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"Figures/No.OfPerceptron_Dense(ConvLSTM).png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8dfed7f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f190806\\AppData\\Local\\Temp\\2\\ipykernel_7416\\2398920301.py:19: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=0, batch_size = 80)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 10s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "Best Results with Grid Search:\n",
      "0.8330326119135543\n",
      "{'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "#Epochs Tuning\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='tanh'))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=90, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=90, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=90, input_shape=(1, 11), activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    #compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0, batch_size = 80)\n",
    "\n",
    "parameters = {\n",
    "    #'unit': [95],\n",
    "    'epochs': [30,40,50,60,70,80,90,100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_L, y_train_L)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7eb183ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xaxis_epochs = [30,40,50,60,70,80,90,100]\n",
    "plt.plot(xaxis_epochs,means,'.-')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"Figures/No.OfEpochs(ConvLSTM).png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d9b29af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f190806\\AppData\\Local\\Temp\\2\\ipykernel_6204\\304852220.py:19: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=0, epochs = 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343/3343 [==============================] - 10s 2ms/step\n",
      "3343/3343 [==============================] - 10s 2ms/step\n",
      "3343/3343 [==============================] - 10s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 10s 2ms/step\n",
      "3343/3343 [==============================] - 10s 2ms/step\n",
      "3343/3343 [==============================] - 10s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "3343/3343 [==============================] - 9s 2ms/step\n",
      "0.8326773555212764\n",
      "{'batch_size': 60}\n"
     ]
    }
   ],
   "source": [
    "#Batch Size Tuning\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='tanh'))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=90, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=90, input_shape=(1, 11), return_sequences = True, activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=90, input_shape=(1, 11), activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    #compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0, epochs = 100)\n",
    "\n",
    "parameters = {\n",
    "    #'unit': [95],\n",
    "    'batch_size': [30,40,50,60,70,80,90,100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_L, y_train_L)\n",
    "\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ace23eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xaxis_batch = [30,40,50,60,70,80,90,100]\n",
    "plt.plot(xaxis_batch,means,'.-')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Batch SIze')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"Figures/No.OfBatch(ConvLSTM).png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30221e68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f190806\\AppData\\Local\\Temp\\3/ipykernel_7264/2890131643.py:18: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "#Tuning with Grid Seaerch CV\n",
    "\n",
    "def create_model(nb_filters, unit, solver, dropout, activation):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=nb_filters, kernel_size=3, padding='same', activation=activation))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(units=unit, input_shape=(1, 11), return_sequences = True, activation=activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(units=unit, input_shape=(1, 11), return_sequences = True, activation=activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(units=unit, input_shape=(1, 11), activation=activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=solver, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "parameters = {\n",
    "    'nb_filters' : [175,300],\n",
    "    'unit': [80,90],\n",
    "    'dropout': [0.1,0.2],\n",
    "    'activation': ['relu','tanh'],  \n",
    "    'solver': ['adam','Adamax'],\n",
    "    'epochs': [80,100],\n",
    "    'batch_size': [60,90]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_L, y_train_L)\n",
    "\n",
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Results with Grid Search:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test_L)\n",
    "\n",
    "print('\\nAccuracy Score  on test data: ' + str(accuracy_score(y_test_L, y_pred)))\n",
    "print(confusion_matrix(y_test_L,y_pred))\n",
    "print(classification_report(y_test_L,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f4a6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f768c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6fc93f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "2507/2507 - 21s - loss: 0.7727 - accuracy: 0.7633 - val_loss: 0.6668 - val_accuracy: 0.8000 - 21s/epoch - 8ms/step\n",
      "Epoch 2/70\n",
      "2507/2507 - 19s - loss: 0.6910 - accuracy: 0.7916 - val_loss: 0.6436 - val_accuracy: 0.8077 - 19s/epoch - 8ms/step\n",
      "Epoch 3/70\n",
      "2507/2507 - 17s - loss: 0.6761 - accuracy: 0.7958 - val_loss: 0.6371 - val_accuracy: 0.8066 - 17s/epoch - 7ms/step\n",
      "Epoch 4/70\n",
      "2507/2507 - 18s - loss: 0.6686 - accuracy: 0.7982 - val_loss: 0.6406 - val_accuracy: 0.8077 - 18s/epoch - 7ms/step\n",
      "Epoch 5/70\n",
      "2507/2507 - 17s - loss: 0.6633 - accuracy: 0.7989 - val_loss: 0.6283 - val_accuracy: 0.8108 - 17s/epoch - 7ms/step\n",
      "Epoch 6/70\n",
      "2507/2507 - 18s - loss: 0.6595 - accuracy: 0.8007 - val_loss: 0.6425 - val_accuracy: 0.8051 - 18s/epoch - 7ms/step\n",
      "Epoch 7/70\n",
      "2507/2507 - 19s - loss: 0.6576 - accuracy: 0.8007 - val_loss: 0.6249 - val_accuracy: 0.8114 - 19s/epoch - 7ms/step\n",
      "Epoch 8/70\n",
      "2507/2507 - 19s - loss: 0.6536 - accuracy: 0.8021 - val_loss: 0.6206 - val_accuracy: 0.8112 - 19s/epoch - 8ms/step\n",
      "Epoch 9/70\n",
      "2507/2507 - 18s - loss: 0.6518 - accuracy: 0.8026 - val_loss: 0.6314 - val_accuracy: 0.8051 - 18s/epoch - 7ms/step\n",
      "Epoch 10/70\n",
      "2507/2507 - 17s - loss: 0.6496 - accuracy: 0.8031 - val_loss: 0.6252 - val_accuracy: 0.8102 - 17s/epoch - 7ms/step\n",
      "Epoch 11/70\n",
      "2507/2507 - 17s - loss: 0.6465 - accuracy: 0.8047 - val_loss: 0.6200 - val_accuracy: 0.8087 - 17s/epoch - 7ms/step\n",
      "Epoch 12/70\n",
      "2507/2507 - 18s - loss: 0.6458 - accuracy: 0.8046 - val_loss: 0.6167 - val_accuracy: 0.8121 - 18s/epoch - 7ms/step\n",
      "Epoch 13/70\n",
      "2507/2507 - 19s - loss: 0.6453 - accuracy: 0.8051 - val_loss: 0.6163 - val_accuracy: 0.8116 - 19s/epoch - 8ms/step\n",
      "Epoch 14/70\n",
      "2507/2507 - 17s - loss: 0.6434 - accuracy: 0.8061 - val_loss: 0.6138 - val_accuracy: 0.8159 - 17s/epoch - 7ms/step\n",
      "Epoch 15/70\n",
      "2507/2507 - 17s - loss: 0.6422 - accuracy: 0.8055 - val_loss: 0.6546 - val_accuracy: 0.7968 - 17s/epoch - 7ms/step\n",
      "Epoch 16/70\n",
      "2507/2507 - 17s - loss: 0.6421 - accuracy: 0.8058 - val_loss: 0.6131 - val_accuracy: 0.8159 - 17s/epoch - 7ms/step\n",
      "Epoch 17/70\n",
      "2507/2507 - 17s - loss: 0.6407 - accuracy: 0.8061 - val_loss: 0.6147 - val_accuracy: 0.8114 - 17s/epoch - 7ms/step\n",
      "Epoch 18/70\n",
      "2507/2507 - 17s - loss: 0.6397 - accuracy: 0.8063 - val_loss: 0.6197 - val_accuracy: 0.8111 - 17s/epoch - 7ms/step\n",
      "Epoch 19/70\n",
      "2507/2507 - 17s - loss: 0.6378 - accuracy: 0.8077 - val_loss: 0.6091 - val_accuracy: 0.8144 - 17s/epoch - 7ms/step\n",
      "Epoch 20/70\n",
      "2507/2507 - 18s - loss: 0.6378 - accuracy: 0.8072 - val_loss: 0.6145 - val_accuracy: 0.8116 - 18s/epoch - 7ms/step\n",
      "Epoch 21/70\n",
      "2507/2507 - 18s - loss: 0.6386 - accuracy: 0.8067 - val_loss: 0.6088 - val_accuracy: 0.8134 - 18s/epoch - 7ms/step\n",
      "Epoch 22/70\n",
      "2507/2507 - 18s - loss: 0.6377 - accuracy: 0.8075 - val_loss: 0.6070 - val_accuracy: 0.8180 - 18s/epoch - 7ms/step\n",
      "Epoch 23/70\n",
      "2507/2507 - 18s - loss: 0.6366 - accuracy: 0.8074 - val_loss: 0.6117 - val_accuracy: 0.8138 - 18s/epoch - 7ms/step\n",
      "Epoch 24/70\n",
      "2507/2507 - 29s - loss: 0.6356 - accuracy: 0.8072 - val_loss: 0.6135 - val_accuracy: 0.8117 - 29s/epoch - 12ms/step\n",
      "Epoch 25/70\n",
      "2507/2507 - 17s - loss: 0.6354 - accuracy: 0.8073 - val_loss: 0.6105 - val_accuracy: 0.8099 - 17s/epoch - 7ms/step\n",
      "Epoch 26/70\n",
      "2507/2507 - 17s - loss: 0.6344 - accuracy: 0.8076 - val_loss: 0.6110 - val_accuracy: 0.8158 - 17s/epoch - 7ms/step\n",
      "Epoch 27/70\n",
      "2507/2507 - 16s - loss: 0.6350 - accuracy: 0.8081 - val_loss: 0.6098 - val_accuracy: 0.8126 - 16s/epoch - 6ms/step\n",
      "Epoch 28/70\n",
      "2507/2507 - 16s - loss: 0.6337 - accuracy: 0.8082 - val_loss: 0.6124 - val_accuracy: 0.8133 - 16s/epoch - 7ms/step\n",
      "Epoch 29/70\n",
      "2507/2507 - 16s - loss: 0.6343 - accuracy: 0.8081 - val_loss: 0.6148 - val_accuracy: 0.8104 - 16s/epoch - 7ms/step\n",
      "Epoch 30/70\n",
      "2507/2507 - 16s - loss: 0.6332 - accuracy: 0.8085 - val_loss: 0.6317 - val_accuracy: 0.8005 - 16s/epoch - 7ms/step\n",
      "Epoch 31/70\n",
      "2507/2507 - 16s - loss: 0.6323 - accuracy: 0.8079 - val_loss: 0.6067 - val_accuracy: 0.8135 - 16s/epoch - 7ms/step\n",
      "Epoch 32/70\n",
      "2507/2507 - 16s - loss: 0.6327 - accuracy: 0.8077 - val_loss: 0.6225 - val_accuracy: 0.8077 - 16s/epoch - 7ms/step\n",
      "Epoch 33/70\n",
      "2507/2507 - 16s - loss: 0.6320 - accuracy: 0.8082 - val_loss: 0.6165 - val_accuracy: 0.8108 - 16s/epoch - 7ms/step\n",
      "Epoch 34/70\n",
      "2507/2507 - 17s - loss: 0.6322 - accuracy: 0.8083 - val_loss: 0.6082 - val_accuracy: 0.8142 - 17s/epoch - 7ms/step\n",
      "Epoch 35/70\n",
      "2507/2507 - 16s - loss: 0.6312 - accuracy: 0.8084 - val_loss: 0.6100 - val_accuracy: 0.8132 - 16s/epoch - 7ms/step\n",
      "Epoch 36/70\n",
      "2507/2507 - 17s - loss: 0.6310 - accuracy: 0.8088 - val_loss: 0.6034 - val_accuracy: 0.8175 - 17s/epoch - 7ms/step\n",
      "Epoch 37/70\n",
      "2507/2507 - 17s - loss: 0.6314 - accuracy: 0.8091 - val_loss: 0.6078 - val_accuracy: 0.8133 - 17s/epoch - 7ms/step\n",
      "Epoch 38/70\n",
      "2507/2507 - 17s - loss: 0.6312 - accuracy: 0.8084 - val_loss: 0.6080 - val_accuracy: 0.8159 - 17s/epoch - 7ms/step\n",
      "Epoch 39/70\n",
      "2507/2507 - 17s - loss: 0.6312 - accuracy: 0.8085 - val_loss: 0.6149 - val_accuracy: 0.8106 - 17s/epoch - 7ms/step\n",
      "Epoch 40/70\n",
      "2507/2507 - 17s - loss: 0.6306 - accuracy: 0.8091 - val_loss: 0.6118 - val_accuracy: 0.8110 - 17s/epoch - 7ms/step\n",
      "Epoch 41/70\n",
      "2507/2507 - 17s - loss: 0.6301 - accuracy: 0.8088 - val_loss: 0.6113 - val_accuracy: 0.8138 - 17s/epoch - 7ms/step\n",
      "Epoch 42/70\n",
      "2507/2507 - 17s - loss: 0.6294 - accuracy: 0.8089 - val_loss: 0.6147 - val_accuracy: 0.8104 - 17s/epoch - 7ms/step\n",
      "Epoch 43/70\n",
      "2507/2507 - 17s - loss: 0.6295 - accuracy: 0.8089 - val_loss: 0.6119 - val_accuracy: 0.8098 - 17s/epoch - 7ms/step\n",
      "Epoch 44/70\n",
      "2507/2507 - 17s - loss: 0.6292 - accuracy: 0.8086 - val_loss: 0.6007 - val_accuracy: 0.8184 - 17s/epoch - 7ms/step\n",
      "Epoch 45/70\n",
      "2507/2507 - 17s - loss: 0.6281 - accuracy: 0.8093 - val_loss: 0.6062 - val_accuracy: 0.8134 - 17s/epoch - 7ms/step\n",
      "Epoch 46/70\n",
      "2507/2507 - 17s - loss: 0.6285 - accuracy: 0.8093 - val_loss: 0.6143 - val_accuracy: 0.8100 - 17s/epoch - 7ms/step\n",
      "Epoch 47/70\n",
      "2507/2507 - 17s - loss: 0.6283 - accuracy: 0.8091 - val_loss: 0.6024 - val_accuracy: 0.8162 - 17s/epoch - 7ms/step\n",
      "Epoch 48/70\n",
      "2507/2507 - 17s - loss: 0.6289 - accuracy: 0.8091 - val_loss: 0.6065 - val_accuracy: 0.8133 - 17s/epoch - 7ms/step\n",
      "Epoch 49/70\n",
      "2507/2507 - 17s - loss: 0.6292 - accuracy: 0.8084 - val_loss: 0.6042 - val_accuracy: 0.8153 - 17s/epoch - 7ms/step\n",
      "Epoch 50/70\n",
      "2507/2507 - 17s - loss: 0.6289 - accuracy: 0.8088 - val_loss: 0.6321 - val_accuracy: 0.8052 - 17s/epoch - 7ms/step\n",
      "Epoch 51/70\n",
      "2507/2507 - 17s - loss: 0.6277 - accuracy: 0.8095 - val_loss: 0.6100 - val_accuracy: 0.8140 - 17s/epoch - 7ms/step\n",
      "Epoch 52/70\n",
      "2507/2507 - 17s - loss: 0.6288 - accuracy: 0.8085 - val_loss: 0.6020 - val_accuracy: 0.8158 - 17s/epoch - 7ms/step\n",
      "Epoch 53/70\n",
      "2507/2507 - 17s - loss: 0.6277 - accuracy: 0.8102 - val_loss: 0.6082 - val_accuracy: 0.8113 - 17s/epoch - 7ms/step\n",
      "Epoch 54/70\n",
      "2507/2507 - 17s - loss: 0.6283 - accuracy: 0.8086 - val_loss: 0.6077 - val_accuracy: 0.8128 - 17s/epoch - 7ms/step\n",
      "Epoch 55/70\n",
      "2507/2507 - 17s - loss: 0.6288 - accuracy: 0.8085 - val_loss: 0.6150 - val_accuracy: 0.8145 - 17s/epoch - 7ms/step\n",
      "Epoch 56/70\n",
      "2507/2507 - 17s - loss: 0.6273 - accuracy: 0.8096 - val_loss: 0.6137 - val_accuracy: 0.8099 - 17s/epoch - 7ms/step\n",
      "Epoch 57/70\n",
      "2507/2507 - 17s - loss: 0.6280 - accuracy: 0.8086 - val_loss: 0.6123 - val_accuracy: 0.8125 - 17s/epoch - 7ms/step\n",
      "Epoch 58/70\n",
      "2507/2507 - 17s - loss: 0.6282 - accuracy: 0.8085 - val_loss: 0.6122 - val_accuracy: 0.8102 - 17s/epoch - 7ms/step\n",
      "Epoch 59/70\n",
      "2507/2507 - 17s - loss: 0.6272 - accuracy: 0.8087 - val_loss: 0.6063 - val_accuracy: 0.8130 - 17s/epoch - 7ms/step\n",
      "Epoch 60/70\n",
      "2507/2507 - 17s - loss: 0.6283 - accuracy: 0.8086 - val_loss: 0.6029 - val_accuracy: 0.8154 - 17s/epoch - 7ms/step\n",
      "Epoch 61/70\n",
      "2507/2507 - 17s - loss: 0.6275 - accuracy: 0.8099 - val_loss: 0.6056 - val_accuracy: 0.8147 - 17s/epoch - 7ms/step\n",
      "Epoch 62/70\n",
      "2507/2507 - 17s - loss: 0.6278 - accuracy: 0.8094 - val_loss: 0.6090 - val_accuracy: 0.8084 - 17s/epoch - 7ms/step\n",
      "Epoch 63/70\n",
      "2507/2507 - 17s - loss: 0.6273 - accuracy: 0.8085 - val_loss: 0.6032 - val_accuracy: 0.8144 - 17s/epoch - 7ms/step\n",
      "Epoch 64/70\n",
      "2507/2507 - 17s - loss: 0.6258 - accuracy: 0.8096 - val_loss: 0.6060 - val_accuracy: 0.8154 - 17s/epoch - 7ms/step\n",
      "Epoch 65/70\n",
      "2507/2507 - 17s - loss: 0.6273 - accuracy: 0.8089 - val_loss: 0.6154 - val_accuracy: 0.8126 - 17s/epoch - 7ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/70\n",
      "2507/2507 - 17s - loss: 0.6270 - accuracy: 0.8093 - val_loss: 0.6034 - val_accuracy: 0.8139 - 17s/epoch - 7ms/step\n",
      "Epoch 67/70\n",
      "2507/2507 - 17s - loss: 0.6268 - accuracy: 0.8093 - val_loss: 0.6076 - val_accuracy: 0.8118 - 17s/epoch - 7ms/step\n",
      "Epoch 68/70\n",
      "2507/2507 - 17s - loss: 0.6272 - accuracy: 0.8096 - val_loss: 0.6079 - val_accuracy: 0.8132 - 17s/epoch - 7ms/step\n",
      "Epoch 69/70\n",
      "2507/2507 - 17s - loss: 0.6264 - accuracy: 0.8095 - val_loss: 0.6081 - val_accuracy: 0.8128 - 17s/epoch - 7ms/step\n",
      "Epoch 70/70\n",
      "2507/2507 - 17s - loss: 0.6266 - accuracy: 0.8091 - val_loss: 0.5954 - val_accuracy: 0.8162 - 17s/epoch - 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29743f988e0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_filter = 250\n",
    "filter_length = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=nb_filter, kernel_size=filter_length, padding='same', activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(17))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.fit(trainX, trainY, epochs=70, batch_size=128, verbose=2, validation_data=(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0f46021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2507/2507 [==============================] - 7s 2ms/step - loss: 0.5954 - accuracy: 0.8162\n",
      "Loss:0.5954145789146423\n",
      "Accuracy:0.8161522746086121\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(testX, testY)\n",
    "print(\"Loss:\" + str(loss))\n",
    "print(\"Accuracy:\" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8ff3778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 1, 250)            8500      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 1, 250)            0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 1, 250)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 1, 250)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 17)                18224     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 17)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               2304      \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               12900     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                6464      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,912\n",
      "Trainable params: 48,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82860045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
